<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhisheng的博客</title>
  
  <subtitle>坑要一个个填，路要一步步走！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.54tianzhisheng.cn/"/>
  <updated>2021-07-03T12:24:34.986Z</updated>
  <id>http://www.54tianzhisheng.cn/</id>
  
  <author>
    <name>zhisheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于 Flink 的动态欺诈检测系统(下)</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/</id>
    <published>2021-07-02T16:00:00.000Z</published>
    <updated>2021-07-03T12:24:34.986Z</updated>
    
    <content type="html"><![CDATA[<p>如何实现呢？</p><a id="more"></a><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>在本系列的前两篇文章中，我们描述了如何基于动态更新配置（欺诈检测规则）来实现灵活的数据流分区，以及如何利用 Flink 的 Broadcast 机制在运行时在相关算子之间分配处理配置。</p><p>直接跟上我们上次讨论端到端解决方案的地方，在本篇文章中，我们将描述如何使用 Flink 的 “瑞士军刀” —— Process Function 来创建一个量身定制的实现，以满足你的流业务逻辑需求。我们的讨论将在欺诈检测引擎的背景下继续进行，我们还将演示如何在 DataStream API 提供的窗口不能满足你的要求的情况下，通过自定义窗口来实现你自己的需求。特别的是，我们将研究在设计需要对单个事件进行低延迟响应的解决方案时可以做出权衡。</p><p>本文将描述一些可以独立应用的高级概念，建议你先阅读本系列第一篇和第二篇文章，并阅读其代码实现，以便更容易理解本文。</p><h3 id="ProcessFunction-当作-Window"><a href="#ProcessFunction-当作-Window" class="headerlink" title="ProcessFunction 当作 Window"></a>ProcessFunction 当作 Window</h3><h4 id="低延迟"><a href="#低延迟" class="headerlink" title="低延迟"></a>低延迟</h4><p>首先来看下我们将要支持的欺诈检测规则类型：</p><blockquote><p>“每当同一付款人在 24 小时内支付给同一受益人的款项总额超过 20 万美元时，就会触发警报。”</p></blockquote><p>换句话说，假设现在有一个按照付款人和受益人组成 key 分区的交易数据流，对于每条到来的交易数据流，我们都会统计两个特定参与者之间前 24 小时到现在的付款总额是否超过预定义的阈值。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/time-windows.png" alt=""></p><p>欺诈检测系统的常见关键要求之一是响应时间短。欺诈行为越早被检测到，阻止就会越及时，带来的负面影响就会越小。这一要求在金融领域尤为突出，因为用于评估欺诈检测系统的任何时间都是用户需要等待响应所花费的时间。处理的迅速性通常成为各种支付系统之间的竞争优势，产生告警的时间限制可能低至 300-500 毫秒。这是从欺诈检测系统接收到金融交易事件的那一刻起，直到下游系统发出告警为止的所有延迟时间限制。</p><p>你可能知道，Flink 已经提供了强大的 Window API，这些 API 可以适用于广泛的场景。但是你查看 Flink 所有支持的窗口类型，你会发现没有一个能完全符合我们这个场景的要求 —— 低延迟的计算每条交易数据。Flink 自带的窗口没有可以表达 “从当前事件返回 x 分钟/小时/天” 的语义。在 Window API 中，事件会落到由窗口分配器定义的窗口中，但是他们本身不能单独控制 Window 的创建和计算。如上所述，我们的欺诈检测引擎的目标是在收到新事件后立即对之前的相关数据进行计算。在这种场景下，利用 Flink 自带的 Window API 不清楚是否可行。Window API 提供了一些用于自定义的 Trigger、Evictor 和 Window Assigner，或许它们可能会帮助到我们获得所需的结果。但是，通常情况下很难做到这一点，此外，这种方法不提供对广播状态的访问，这是然后广播状态是实现业务规则动态配置所必须的。</p><p>1) 除了会话窗口，它们仅限于基于会话间隙的分配</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/evaluation-delays.png" alt=""></p><p>我们以使用 Flink 的 Window API 中的滑动窗口为例。使用滑动步长为 S 的滑动窗口转化为等于 S/2 的评估延迟的预期值。这意味着你需要定义 600～1000 毫秒的滑动窗口来满足 300～500 毫秒延迟的低延迟要求。Flink 要为每个滑动窗口存储单独的窗口状态，这会导致作业状态非常大，在任何中等高负载的情况下，这种方案都不可行。为了满足需求，我们需要创建自定的低延迟窗口实现，幸运的是，Flink 为我们提供了这样做所需的所有工具，ProcessFunction 是 Flink API 中一个低级但功能强大的类。它有一个简单的约定：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeProcessFunction</span> <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>&lt;<span class="title">KeyType</span>, <span class="title">InputType</span>, <span class="title">OutputType</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(InputType event, Context ctx, Collector&lt;OutputType&gt; out)</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;OutputType&gt; out)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>processElement()：接收输入数据，你可以通过调用 out.collect() 为下一个算子生成一个或者多个输出事件来对每个输入作出反应，你可以将数据传递到侧输出或完全忽略特定的输入数据</li><li>onTimer()：当之前注册的定时器触发时，Flink 会调用 onTimer()，支持事件时间和处理时间定时器</li><li>open()：相当于一个构造函数，它在 TaskManager 的 JVM 内部调用，用于初始化，例如注册 Flink 管理内存，可以在该方法初始化那些没有序列化的字段或者无法从 JobManager JVM 中传递过来的字段。</li></ul><p>最重要的是，ProcessFunction 还可以访问由 Flink 处理的容错状态。这种组合，再加上 Flink 的消息处理能力和低延迟的保证，使得构建具有几乎任意复杂业务逻辑的弹性事件驱动应用程序成为可能。这包括创建和处理带有状态的自定义窗口。</p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p><strong>状态的清除</strong></p><p>为了能够处理时间窗口，我们需要在程序内部跟踪属于该窗口的数据。为了确保这些数据是容错的，并且能够在分布式系统中发生故障的情况下恢复，我们应该将其存储在 Flink 管理的状态中。随着时间的推移，我们不需要保留所有以前的交易数据。根据欺诈检测样例规则，所有早于 24 小时的交易数据都变得无关紧要。我们正在查看一个不断移动的数据窗口，其中过期的数据需要不断移出范围（换句话说，从状态中清除）。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/window-clean-up.png" alt=""></p><p>我们将使用 MapState 来存储窗口的各个事件。为了有效清理超出范围的事件，我们将使用事件时间戳作为 MapState 的 key。</p><p>在一般情况下，我们必须考虑这样一个事实，即可能存在具有完全相同时间戳的不同事件，因此我们将存储集合而不是每个键（时间戳）的单条数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MapState&lt;Long, Set&lt;Transaction&gt;&gt; windowState;</span><br></pre></td></tr></table></figure><p>注意⚠️：</p><p>当在 KeyedProcessFunction 中使用任何 Flink 管理的状态时，state.value() 调用返回的数据会自动由当前处理的事件的 key 确定范围 - 参见下图。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/keyed-state-scoping.png" alt=""></p><p>如果使用 MapState，则适用相同的原则，不同之处在于返回的是 Map 而不是 MyObject。如果你被迫执行类似 <code>mapState.value().get(inputEvent.getKey())</code> 之类的操作，你可能应该使用 ValueState 而不是 MapState。因为我们想为每个事件 key 存储多个值，所以在我们的例子中，MapState 是正确的选择。</p><p>如本系列的第一篇博客所述，我们将根据主动欺诈检测规则中指定的 key 分配数据。多个不同的规则可以基于相同的分组 key。这意味着我们的警报功能可能会接收由相同 key（例如 {payerId=25;beneficiaryId=12}）限定的交易，但注定要根据不同的规则进行计算，这意味着时间窗口的长度可能不同。这就提出了一个问题，即我们如何才能最好地在 KeyedProcessFunction 中存储容错窗口状态。一种方法是为每个规则创建和管理单独的 MapState。然而，这种方法会很浪费——我们会单独保存重叠时间窗口的状态，因此不必要地存储重复的数据。更好的方法是始终存储刚好足够的数据，以便能够估计由相同 key 限定的所有当前活动规则。为了实现这一点，每当添加新规则时，我们将确定其时间窗口是否具有最大跨度，并将其存储在特殊保留的 WIDEST_RULE_KEY 下的广播状态。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(Rule rule, Context ctx, Collector&lt;Alert&gt; out)</span></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  updateWidestWindowRule(rule, broadcastState);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateWidestWindowRule</span><span class="params">(Rule rule, BroadcastState&lt;Integer, Rule&gt; broadcastState)</span></span>&#123;</span><br><span class="line">  Rule widestWindowRule = broadcastState.get(WIDEST_RULE_KEY);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (widestWindowRule == <span class="keyword">null</span>) &#123;</span><br><span class="line">    broadcastState.put(WIDEST_RULE_KEY, rule);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (widestWindowRule.getWindowMillis() &lt; rule.getWindowMillis()) &#123;</span><br><span class="line">    broadcastState.put(WIDEST_RULE_KEY, rule);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在让我们更详细地看一下主要方法 processElement() 的实现。</p><p>在上一篇博文中，我们描述了 DynamicKeyFunction 如何允许我们根据规则定义中的 groupingKeyNames 参数执行动态数据分区。随后的描述主要围绕 DynamicAlertFunction，它利用了剩余的规则设置。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/sample-rule-definition.png" alt=""></p><p>如博文系列的前几部分所述，我们的警报处理函数接收 <code>Keyed&lt;Transaction, String, Integer&gt;</code> 类型的事件，其中 Transaction 是主要的“包装”事件，String 是 key<br>（payer #x - beneficiary #y)，Integer 是导致调度此事件的规则的 ID。此规则之前存储在广播状态中，必须通过 ID 从该状态中检索。下面是实现代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicAlertFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">KeyedBroadcastProcessFunction</span>&lt;</span></span><br><span class="line"><span class="class">        <span class="title">String</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;, <span class="title">Rule</span>, <span class="title">Alert</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">transient</span> MapState&lt;Long, Set&lt;Transaction&gt;&gt; windowState;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      Keyed&lt;Transaction, String, Integer&gt; value, ReadOnlyContext ctx, Collector&lt;Alert&gt; out)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add Transaction to state</span></span><br><span class="line">    <span class="keyword">long</span> currentEventTime = value.getWrapped().getEventTime();                            <span class="comment">// &lt;--- (1)</span></span><br><span class="line">    addToStateValuesSet(windowState, currentEventTime, value.getWrapped());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Calculate the aggregate value</span></span><br><span class="line">    Rule rule = ctx.getBroadcastState(Descriptors.rulesDescriptor).get(value.getId());    <span class="comment">// &lt;--- (2)</span></span><br><span class="line">    Long windowStartTimestampForEvent = rule.getWindowStartTimestampFor(currentEventTime);<span class="comment">// &lt;--- (3)</span></span><br><span class="line"></span><br><span class="line">    SimpleAccumulator&lt;BigDecimal&gt; aggregator = RuleHelper.getAggregator(rule);            <span class="comment">// &lt;--- (4)</span></span><br><span class="line">    <span class="keyword">for</span> (Long stateEventTime : windowState.keys()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (isStateValueInWindow(stateEventTime, windowStartForEvent, currentEventTime)) &#123;</span><br><span class="line">        aggregateValuesInState(stateEventTime, aggregator, rule);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Evaluate the rule and trigger an alert if violated</span></span><br><span class="line">    BigDecimal aggregateResult = aggregator.getLocalValue();                              <span class="comment">// &lt;--- (5)</span></span><br><span class="line">    <span class="keyword">boolean</span> isRuleViolated = rule.apply(aggregateResult);</span><br><span class="line">    <span class="keyword">if</span> (isRuleViolated) &#123;</span><br><span class="line">      <span class="keyword">long</span> decisionTime = System.currentTimeMillis();</span><br><span class="line">      out.collect(<span class="keyword">new</span> Alert&lt;&gt;(rule.getRuleId(),</span><br><span class="line">                              rule,</span><br><span class="line">                              value.getKey(),</span><br><span class="line">                              decisionTime,</span><br><span class="line">                              value.getWrapped(),</span><br><span class="line">                              aggregateResult));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Register timers to ensure state cleanup</span></span><br><span class="line">    <span class="keyword">long</span> cleanupTime = (currentEventTime / <span class="number">1000</span>) * <span class="number">1000</span>;                                  <span class="comment">// &lt;--- (6)</span></span><br><span class="line">    ctx.timerService().registerEventTimeTimer(cleanupTime);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>以下是步骤的详细信息：</p><p>1）我们首先将每个新事件添加到我们的窗口状态：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> &lt;K, V&gt; <span class="function">Set&lt;V&gt; <span class="title">addToStateValuesSet</span><span class="params">(MapState&lt;K, Set&lt;V&gt;&gt; mapState, K key, V value)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Set&lt;V&gt; valuesSet = mapState.get(key);</span><br><span class="line">    <span class="keyword">if</span> (valuesSet != <span class="keyword">null</span>) &#123;</span><br><span class="line">      valuesSet.add(value);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      valuesSet = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">      valuesSet.add(value);</span><br><span class="line">    &#125;</span><br><span class="line">    mapState.put(key, valuesSet);</span><br><span class="line">    <span class="keyword">return</span> valuesSet;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2）接下来，我们检索先前广播的规则，需要根据该规则计算传入的交易数据。</p><p>3) getWindowStartTimestampFor 确定，给定规则中定义的窗口跨度和当前事件时间戳，然后计算窗口应该跨度多久。</p><p>4) 通过迭代所有窗口状态并应用聚合函数来计算聚合值。它可以是平均值、最大值、最小值，或者如本文开头的示例规则中的总和。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isStateValueInWindow</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Long stateEventTime, Long windowStartForEvent, <span class="keyword">long</span> currentEventTime)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> stateEventTime &gt;= windowStartForEvent &amp;&amp; stateEventTime &lt;= currentEventTime;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">aggregateValuesInState</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Long stateEventTime, SimpleAccumulator&lt;BigDecimal&gt; aggregator, Rule rule)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  Set&lt;Transaction&gt; inWindow = windowState.get(stateEventTime);</span><br><span class="line">  <span class="keyword">for</span> (Transaction event : inWindow) &#123;</span><br><span class="line">    BigDecimal aggregatedValue =</span><br><span class="line">        FieldsExtractor.getBigDecimalByName(rule.getAggregateFieldName(), event);</span><br><span class="line">    aggregator.add(aggregatedValue);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5) 有了聚合值，我们可以将其与规则定义中指定的阈值进行比较，并在必要时发出警报。</p><p>6) 最后，我们使用 <code>ctx.timerService().registerEventTimeTimer()</code> 注册一个清理计时器。当它要移出范围时，此计时器将负责删除当前数据。</p><p>7) onTimer 方法会触发窗口状态的清理。</p><p>如前所述，我们总是在状态中保留尽可能多的事件，以计算具有最宽窗口跨度的活动规则。这意味着在清理过程中，我们只需要删除这个最宽窗口范围之外的状态。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/widest-window.png" alt=""></p><p>这是清理程序的实现方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timestamp, <span class="keyword">final</span> OnTimerContext ctx, <span class="keyword">final</span> Collector&lt;Alert&gt; out)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">  Rule widestWindowRule = ctx.getBroadcastState(Descriptors.rulesDescriptor).get(WIDEST_RULE_KEY);</span><br><span class="line"></span><br><span class="line">  Optional&lt;Long&gt; cleanupEventTimeWindow =</span><br><span class="line">      Optional.ofNullable(widestWindowRule).map(Rule::getWindowMillis);</span><br><span class="line">  Optional&lt;Long&gt; cleanupEventTimeThreshold =</span><br><span class="line">      cleanupEventTimeWindow.map(window -&gt; timestamp - window);</span><br><span class="line">  <span class="comment">// Remove events that are older than (timestamp - widestWindowSpan)ms</span></span><br><span class="line">  cleanupEventTimeThreshold.ifPresent(<span class="keyword">this</span>::evictOutOfScopeElementsFromWindow);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">evictOutOfScopeElementsFromWindow</span><span class="params">(Long threshold)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    Iterator&lt;Long&gt; keys = windowState.keys().iterator();</span><br><span class="line">    <span class="keyword">while</span> (keys.hasNext()) &#123;</span><br><span class="line">      Long stateEventTime = keys.next();</span><br><span class="line">      <span class="keyword">if</span> (stateEventTime &lt; threshold) &#123;</span><br><span class="line">        keys.remove();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(ex);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上是实现细节的描述。我们的方法会在新交易数据到达时立即触发对时间窗口的计算。因此，它满足了我们的主要要求——发出警报的低延迟。完整的实现请看 github 上的项目代码 <a href="https://github.com/afedulov/fraud-detection-demo">https://github.com/afedulov/fraud-detection-demo</a>。</p><h3 id="完善和优化"><a href="#完善和优化" class="headerlink" title="完善和优化"></a>完善和优化</h3><p>上面描述的方法的优缺点是什么？</p><p><strong>优点</strong>：</p><ul><li>低延迟能力</li><li>具有潜在用例特定优化的定制解决方案</li><li>高效的状态重用（具有相同 key 的规则共享状态）</li></ul><p><strong>缺点</strong>：</p><ul><li>无法利用现有 Window API 中潜在的未来优化</li><li>无延迟事件处理，可在 Window API 中开箱即用</li><li>二次计算复杂度和潜在的大状态</li></ul><p>现在让我们看看后两个缺点，看看我们是否可以解决它们。</p><h4 id="延迟数据"><a href="#延迟数据" class="headerlink" title="延迟数据"></a>延迟数据</h4><p>处理延迟数据之前先提出了一个问题 - 在延迟数据到达的情况下重新评估窗口是否仍然有意义？ 如果需要这样做，你需要增加最宽的窗口大小，用来允许容忍最大的数据延迟。这样将避免因延迟数据问题导致触发了不完整的时间窗口数据。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/late-events.png" alt=""></p><p>然而，可以说，对于强调低延迟处理的场景，这种延迟触发将毫无意义。在这种情况下，我们可以跟踪到目前为止我们观察到的最新时间戳，对于不会单调增加此值的事件，只需将它们添加到状态并跳过聚合计算和警报触发逻辑。</p><h4 id="冗余重复计算和状态大小"><a href="#冗余重复计算和状态大小" class="headerlink" title="冗余重复计算和状态大小"></a>冗余重复计算和状态大小</h4><p>在我们描述的实现中，我们保存每条数据处于状态中并在每个新数据来时遍历它们并一次又一次地计算聚合。这在重复计算上浪费计算资源方面显然不是最佳的。</p><p>保存每个交易数据处于状态的主要原因是什么？存储事件的粒度直接对应于时间窗口计算的精度。因为我们是存储每条明细交易数据，所以一旦它们离开精确的 2592000000 毫秒时间窗口（以毫秒为单位的 30 天），我们就可以精确地移除它们。在这一点上，值得提出一个问题——在估计这么长的时间窗口时，我们真的需要这个毫秒级的精度，还是在特殊情况下可以接受潜在的误报？如果你的用例的答案是不需要这样的精度，那么你可以基于分桶和预聚合实施额外的优化。这种优化的思想可以分解如下：</p><ul><li><p>不是存储每条明细交易数据，而是创建一个父类，该类可以包含单条数据的字段或是根据聚合函数计算处理一批数据后的聚合值。</p></li><li><p>不要使用以毫秒为单位的时间戳作为 MapState key，而是将它们四舍五入到你愿意接受的粒度级别（例如，一分钟），将数据分桶。</p></li><li><p>每当计算窗口时，将新的交易数据存储到聚合桶中，而不是为每个数据存储单独的数据点。</p></li></ul><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/pre-aggregation.png" alt=""></p><h4 id="状态数据和序列化器"><a href="#状态数据和序列化器" class="headerlink" title="状态数据和序列化器"></a>状态数据和序列化器</h4><p>为了进一步优化实现，我们可以问自己的另一个问题是获得具有完全相同时间戳的不同事件的可能性有多大。在所描述的实现中，我们展示了通过在 <code>MapState&lt;Long, Set&lt;Transaction&gt;&gt;</code> 中存储每个时间戳的数据集来解决这个问题的一种方法。但是，这种选择对性能的影响可能比预期的要大。原因是 Flink 当前不提供原生 Set 序列化器，而是强制使用效率较低的 Kryo 序列化器（FLINK-16729）。一个有意义的替代策略是假设在正常情况下，没有两个有差异的事件可以具有完全相同的时间戳，并将窗口状态转换为 <code>MapState&lt;Long, Transaction&gt;</code> 类型。你可以使用辅助输出来收集和监控与你的假设相矛盾的任何意外事件。性能优化期间，我通常建议你禁用 Kryo，并通过确保使用更高效的序列化程序来验证你的应用程序可以进一步优化的位置。</p><p>你可以通过设置断点并验证返回的 TypeInformation 的类型来快速确定你的类将使用哪个序列化程序。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/type-pojo.png" alt=""></p><p>PojoTypeInfo 表示将使用高效的 Flink POJO 序列化器。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/type-kryo.png" alt=""></p><p>GenericTypeInfo 表示使用了 Kryo 序列化程序。</p><p>交易数据修剪：我们可以将单个事件数据减少到仅要用到的字段，而不是存储完整的事件数据，减少数据序列化与反序列化对机器施加额外的压力。这可能需要根据活动规则的配置将单个事件提取需要对字段出来，并将这些字段存储到通用 Map<String, Object> 数据结构中。</p><p>虽然这种调整可能会对大对象产生显著的改进，但它不应该是你的首选。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文总结了我们在第一部分中开始的欺诈检测引擎的实现描述。在这篇博文中，我们演示了如何利用 ProcessFunction 来“模拟”具有复杂自定义逻辑的窗口。我们已经讨论了这种方法的优缺点，并详细说明了如何应用自定义场景特定的优化 - 这是 Window API 无法直接实现的。</p><p>这篇博文的目的是说明 Apache Flink API 的强大功能和灵活性。它的核心是 Flink 的支柱，作为开发人员，它为你节省了大量的工作，并通过提供以下内容很好地推广到广泛的用例：</p><ul><li><p>分布式集群中的高效数据交换</p></li><li><p>通过数据分区的水平可扩展性</p></li><li><p>具有快速本地访问的容错状态</p></li><li><p>方便处理状态数据，就像使用局部变量一样简单</p></li><li><p>多线程、并行执行引擎。 ProcessFunction 代码在单线程中运行，无需同步。 Flink 处理所有并行执行方面并正确访问共享状态，而你作为开发人员不必考虑（并发很难）。</p></li></ul><p>所有这些方面都使得使用 Flink 构建应用程序成为可能，这些应用程序远远超出了普通的流 ETL 用例，并且可以实现任意复杂的分布式事件驱动应用程序。使用 Flink，你可以重新思考处理广泛用例的方法，这些用例通常依赖于使用无状态并行执行节点并将状态容错问题“推”到数据库，这种方法通常注定会遇到可扩展性问题面对不断增长的数据量。</p><blockquote><p>本篇文章属于翻译文章，作者：zhisheng</p><p>原文地址：<a href="http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/">http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/</a></p><p>英文作者：alex_fedulov</p><p>英文原文地址：<a href="https://flink.apache.org/news/2020/07/30/demo-fraud-detection-3.html">https://flink.apache.org/news/2020/07/30/demo-fraud-detection-3.html</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何实现呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink 的动态欺诈检测系统(中)</title>
    <link href="http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/"/>
    <id>http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/</id>
    <published>2021-01-22T16:00:00.000Z</published>
    <updated>2021-01-23T15:53:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何实现呢？</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在上一篇博客中，我们对欺诈检测引擎的目标和所需要的功能进行了描述，我们还描述了如何基于可修改的规则而不是使用硬编码的 KeysExtractor 实现 Flink 应用程序的数据自定义分区。</p><p>我们在上篇博客中特意省略了有关如何初始化应用的规则以及如何在作业运行时更新的细节，在本文我们将详细的介绍这些细节，你将学习如何将上篇博客中描述的数据分区防御与动态配置结合使用，当这两种模式结合使用的时候，可以省去重新编译代码和重新部署 Flink 作业的需要，从而可以应对多种业务场景逻辑修改的情况。</p><h3 id="广播规则"><a href="#广播规则" class="headerlink" title="广播规则"></a>广播规则</h3><p>首先让我们看看预定义的数据处理代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Alert&gt; alerts =</span><br><span class="line">    transactions</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">        .keyBy((keyed) -&gt; keyed.getKey());</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicAlertFunction())</span><br></pre></td></tr></table></figure><p>DynamicKeyFunction 函数提供动态数据分区，同时 DynamicAlertFunction 函数负责执行处理数据的主要逻辑并根据已定义的规则发动告警消息。</p><p>在上篇文中中简化了用例，并假定已预先初始化了所应用的规则集数据，并可以通过 DynamicKeyFunction 的 <code>List&lt;Rules&gt;</code> 访问这些规则：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicKeyFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessFunction</span>&lt;<span class="title">Transaction</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Simplified */</span></span><br><span class="line">  List&lt;Rule&gt; rules = <span class="comment">/* Rules that are initialized somehow.*/</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然，在初始化阶段，可以直接在 Flink Job 的代码内部添加规则到此列表（创建<code>List</code>对象；使用它的<code>add</code>方法）。这样做的主要缺点是，每次修改规则后都需要重新编译作业。在真实的欺诈检测系统中，规则会经常更改，因此从业务和运营需求的角度来看，使此方法不可接受，需要一种不同的方法。</p><p>接下来，让我们看一下在上一篇文章中介绍的示例规则定义：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-134902.jpg" alt=""></p><p>上一篇文章介绍了使用 <code>DynamicKeyFunction</code>提取数据含 <code>groupingKeyNames</code> 里面字段组成数据分组 key 的方法。此规则第二部分中的参数由 <code>DynamicAlertFunction</code> 使用：它们定义了所执行操作的实际逻辑及其参数（例如告警触发限制）。这意味着相同的规则必须同时存在于<code>DynamicKeyFunction</code>和<code>DynamicAlertFunction</code>。</p><p>下图展示了我们正在构建的系统的最终工作图：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-135336.jpg" alt=""></p><p>上图的主要模块是：</p><ul><li><strong>Transaction Source</strong>：Flink 作业的 Source 端，它会并行的消费 Kafka 中的金融交易流数据</li><li>**Dynamic Key Function：动态的提取数据分区的 key。随后的<code>keyBy</code>函数会将动态的 key 值进行 hash，并在后续运算符的所有并行实例之间相应地对数据进行分区。</li><li><strong>Dynamic Alert Function</strong>：累积窗口中的数据，并基于该窗口创建告警。</li></ul><h3 id="Apache-Flink-内部的数据交换"><a href="#Apache-Flink-内部的数据交换" class="headerlink" title="Apache Flink 内部的数据交换"></a>Apache Flink 内部的数据交换</h3><p>上面的作业图还展示了运算符之间的各种数据交换模式，为了了解广播模式是如何工作的，我们先来看一下 Apache Flink 在分布式运行时存在哪些消息传播方法：</p><ul><li><p><strong>FORWARD</strong>：上图中 Transaction Source 后的 FORWARD 意味着每个 Transaction Source 的并行度实例消费到的数据都将精确的传输到后面的 DynamicKeyFunction 运算符的每个实例。它还表示两个连接的运算符处于相同的并行度，这种模式如下图所示：</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-143026.jpg" alt=""></p><ul><li><p><strong>HASH</strong>：DynamicKeyFunction 和 DynamicAlertFunction 之间的 HASH 意味着每条消息都会计算一个哈希值，并且消息会在下一个运算符的所有可用并行度之间均匀分配，这种连接一般是通过 keyBy 算子。</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-143447.jpg" alt=""></p></li></ul></li><li><p><strong>REBALANCE</strong>：这种情况下一般是手动的调用 rebalance() 函数或者并行度发生改变导致的，这样会导致数据以循环的方式重新分区，有助于某些情况喜爱的数据倾斜。</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-144041.jpg" alt=""></p><ul><li><p><strong>BROADCAST</strong>：在本文图二中的欺诈检测作业图中包含了一个 Rules Source，它会从 Kafka 中消费规则数据，然后通过 <strong>BROADCAST </strong>的通道将规则数据发动到处理实时数据流的算子中去。与在运算符之间传输数据的其他方法（例如 forward、hash、rebalence，这三种仅会将数据发到下游运算符的某个并行度中去）不同，broadcast 可以使得每条消息都会在下游所有的并行度中处理。broadcast 适用于需要影响所有消息处理的任务，而不管消息的 key 或者 Source 的分区是多少。</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-145129.jpg" alt=""></p></li></ul></li></ul><h3 id="广播状态"><a href="#广播状态" class="headerlink" title="广播状态"></a>广播状态</h3><p>为了使用规则数据流，我们需要将其连接到主数据流：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Streams setup</span></span><br><span class="line">DataStream&lt;Transaction&gt; transactions = [...]</span><br><span class="line">DataStream&lt;Rule&gt; rulesUpdateStream = [...]</span><br><span class="line"></span><br><span class="line">BroadcastStream&lt;Rule&gt; rulesStream = rulesUpdateStream.broadcast(RULES_STATE_DESCRIPTOR);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Processing pipeline setup</span></span><br><span class="line"> DataStream&lt;Alert&gt; alerts =</span><br><span class="line">     transactions</span><br><span class="line">         .connect(rulesStream)</span><br><span class="line">         .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">         .keyBy((keyed) -&gt; keyed.getKey())</span><br><span class="line">         .connect(rulesStream)</span><br><span class="line">         .process(<span class="keyword">new</span> DynamicAlertFunction())</span><br></pre></td></tr></table></figure><p>如您所见，可以通过调用<code>broadcast</code>方法并指定状态描述符，从任何常规流中创建广播流。在处理主数据流的事件时需要存储和查找广播的数据，因此，Flink 始终根据此状态描述符自动创建相应的<em>广播状态</em>。这与你在使用其他的状态类型不一样，那些是需要在 open 方法里面对其进行初始化。另请注意，广播状态始终是 KV 格式（<code>MapState</code>）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> MapStateDescriptor&lt;Integer, Rule&gt; RULES_STATE_DESCRIPTOR =</span><br><span class="line">        <span class="keyword">new</span> MapStateDescriptor&lt;&gt;(<span class="string">"rules"</span>, Integer.class, Rule.class);</span><br></pre></td></tr></table></figure><p>连接<code>rulesStream</code>后会导致 ProcessFunction 的内部发生某些变化。上一篇文章以稍微简化的方式介绍了<code>ProcessFunction</code>。但是 <code>DynamicKeyFunction</code>实际上是一个<code>BroadcastProcessFunction</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BroadcastProcessFunction</span>&lt;<span class="title">IN1</span>, <span class="title">IN2</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(IN1 value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        ReadOnlyContext ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(IN2 value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                 Context ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                 Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不同的是，添加<code>processBroadcastElement</code> 了方法，该方法是用于处理到达的广播规则流。以下新版本的<code>DynamicKeyFunction</code> 函数允许在 processElement 方法里面中动态的修改数据分发的 key 列表：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicKeyFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">BroadcastProcessFunction</span>&lt;<span class="title">Transaction</span>, <span class="title">Rule</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(Rule rule,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Context ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Collector&lt;Keyed&lt;Transaction, String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">    BroadcastState&lt;Integer, Rule&gt; broadcastState = ctx.getBroadcastState(RULES_STATE_DESCRIPTOR);</span><br><span class="line">    broadcastState.put(rule.getRuleId(), rule);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Transaction event,</span></span></span><br><span class="line"><span class="function"><span class="params">                           ReadOnlyContext ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Collector&lt;Keyed&lt;Transaction, String, Integer&gt;&gt; out)</span></span>&#123;</span><br><span class="line">    ReadOnlyBroadcastState&lt;Integer, Rule&gt; rulesState =</span><br><span class="line">                                  ctx.getBroadcastState(RULES_STATE_DESCRIPTOR);</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, Rule&gt; entry : rulesState.immutableEntries()) &#123;</span><br><span class="line">        <span class="keyword">final</span> Rule rule = entry.getValue();</span><br><span class="line">        out.collect(</span><br><span class="line">          <span class="keyword">new</span> Keyed&lt;&gt;(</span><br><span class="line">            event, KeysExtractor.getKey(rule.getGroupingKeyNames(), event), rule.getRuleId()));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的代码中，<code>processElement()</code>接收金融交易数据，并在 <code>processBroadcastElement()</code> 接收规则更新数据。创建新规则时，将如上面广播流的那张图所示进行分配，并会保存在所有使用 <code>processBroadcastState</code> 运算符的并行实例中。我们使用规则的 ID 作为存储和引用单个规则的 key。我们遍历动态更新的广播状态中的数据，而不是遍历硬编码的 <code>List&lt;Rules&gt;</code> 。</p><p>在将规则存储在广播 MapState 中时，DynamicAlertFunction 遵循相同的逻辑。如第 1 部分中所述，通过processElement 方法输入的每条消息均应按照一个特定规则进行处理，并通过 DynamicKeyFunction 对其进行“预标记”并带有相应的ID。我们需要做的就是使用提供的 ID 从 BroadcastState 中检索相应规则，并根据该规则所需的逻辑对其进行处理。在此阶段，我们还将消息添加到内部函数状态，以便在所需的数据时间窗口上执行计算。我们将在下一篇文章中考虑如何实现这一点。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在本文，我们继续研究了使用 Apache Flink 构建的欺诈检测系统的用例。我们研究了在并行运算符实例之间分配数据的不同方式，最重要的是广播状态。我们演示了如何通过广播状态提供的功能来组合和增强动态分区。在运行时发送动态更新的功能是 Apache Flink 的强大功能，适用于多种其他使用场景，例如控制状态（清除/插入/修复），运行 A / B 实验或执行 ML 模型系数的更新。</p><blockquote><p>本篇文章属于翻译文章，作者：zhisheng</p><p>原文地址：<a href="http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/">http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/</a></p><p>英文作者：<a href="https://twitter.com/alex_fedulov">alex_fedulov</a> </p><p>英文原文地址：<a href="https://flink.apache.org/news/2020/03/24/demo-fraud-detection-2.html">https://flink.apache.org/news/2020/03/24/demo-fraud-detection-2.html</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何实现呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink 的动态欺诈检测系统(上)</title>
    <link href="http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/"/>
    <id>http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/</id>
    <published>2021-01-21T16:00:00.000Z</published>
    <updated>2021-01-22T01:36:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何实现呢？</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在本系列博客中，你将学习到三种构建 Flink 应用程序的强大案例：</p><ul><li>动态更新应用程序的逻辑</li><li>动态的数据分区（shuffle），在作业运行时进行控制</li><li>基于自定义窗口逻辑的低延迟告警（不使用 Window API）</li></ul><p>这几个案例扩展了使用静态定义的数据流可以实现的功能，并提供了满足复杂业务需求的基础。</p><p><strong>动态更新应用程序的逻辑</strong> 允许作业在运行时进行更改，不需要将作业停止后修改代码再发布。</p><p><strong>动态的数据分区</strong> 为运行中的 Flink 作业作业提供了动态地将数据分组（group by）的功能。对于想要构建一个可以动态配置应用逻辑的 Flink 程序，类似功能很常见。</p><p><strong>自定义窗口管理</strong> 演示了如何在原生的 Window API 不能完全满足你的需求下，去通过最底层的 Process Function API 来完成你的需求。你将学会如何自定义 Window 逻辑来实现低延迟告警以及如何利用定时器（Timer）来限制状态的无限增长。</p><p>这几个案例都是建立在 Flink 核心功能的基础上，但是通过官方文档你可能无法立即明白，因为如果没有具体的用例，解释和呈现它们背后的原理其实并不是那么简单。这就是为什么我们将通过一些实际的案例来展示，本案例为 Apache Flink 的一个真实使用场景 —— 欺诈检测引擎。我希望你能从本系列文章中收获到这些强大的功能和方法，然后能应用在你们实际的应用场景中去。</p><p>在该系列的第一篇博客中，我们将先来看看这个应用程序的架构、组件和交互。然后我们将深入研究第一个案例的的实现细节 —— <strong>动态数据分区</strong>。</p><p>你将能够在本地运行完整的欺诈检测演示应用程序，并且可以通过 Github 仓库查看其完整实现代码。</p><h3 id="欺诈检测系统演示"><a href="#欺诈检测系统演示" class="headerlink" title="欺诈检测系统演示"></a>欺诈检测系统演示</h3><p>本次掩饰的欺诈检测引擎的代码是开源的，可以在线获取，要是想在本地运行它，请按照 <a href="">https://github.com/afedulov/fraud-detection-demo</a> 中的 README 描述的步骤自行进行操作。</p><p>你将看到该案例的代码和组件都很全，仅需要通过 docker 和 docker-compose 构建源码。仓库里面包含了下面组件：</p><ul><li>含有 Zookeeper 的 Apache Kafka</li><li>Apache Flink（应用程序）</li><li>欺诈检测引擎的 Web 应用</li></ul><p>欺诈检测引擎的目标是消费金融交易的实时数据流，然后根据一组检测规则对其进行评估。这些规则会经常更改和调整，在实际的生产系统中，重要的是要能在作业运行的时候去添加和删除规则，而不会因停止和重新启动作业从而造成高昂的代价。</p><p>当你在本地运行成功后，你在浏览器中输入 URL 可以看到如下效果：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-21-150159.jpg" alt="欺诈检测引擎演示UI"></p><p>点击 “Start” 按钮后，你可以在左侧看到系统中流动的金融交易大盘，你可以通过顶部的滑块去控制每秒生成的数据，中间部分用于管理 Flink 用于计算的规则，你可以在这里创建新规则以及发出控制命令，例如清除 Flink 的状态。</p><p>现成的演示带有一组预定义的示例规则，你可以点击 Start 按钮，一段时间之后，将观察到 UI 右侧部分中显示的告警，这些告警消息是 Flink 根据预定义的规则评估生成的交易流的结果。</p><p>我们的样本欺诈检测系统包含三个主要的组件：</p><ul><li>前端（React）</li><li>后端（SpringBoot）</li><li>欺诈检测 Flink 应用程序</li></ul><p>三者之间的组成关系如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-21-151639.jpg" alt=""></p><p>后端将 REST API 暴露给前端，用于创建/删除规则以及发出用于管理演示执行的控制命令，然后，它会将这些前端操作行为数据发送到 Kafka Topic <code>Control</code> 中。后端还包含了一个交易数据生成器组件，该组件用来模拟交易数据的，然后会将这些交易数据发送到 Kafka Topic <code>Transactions</code> 中，这些数据最后都会被 Flink 应用程序去消费，Flink 程序经过规则计算这些交易数据后生成的告警数据会发送到 Kafka Topic <code>Alerts</code> 中，并通过 Web Sockets  将数据传到前端 UI。</p><p>现在你已经熟悉了该欺诈检测引擎的总体结构和布局了，接下来我们详细介绍这个系统里面包含的内容。</p><h3 id="数据动态分区"><a href="#数据动态分区" class="headerlink" title="数据动态分区"></a>数据动态分区</h3><p>如果过去你曾经使用过 Flink DataStream API，那么你肯定很熟悉 keyBy 方法。对数据流中的所有数据按键进行 shuffle，这样具有相同 key 的元素就会被分配到相同的分区。</p><p>一般在程序中，数据分区的 keyBy 字段是固定的，由数据内的某些静态字段确定，例如，当构建一个简单的基于窗口的交易流聚合时，我们可能总是按照交易账户 ID 进行分组。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Transaction&gt; input = <span class="comment">// [...]</span></span><br><span class="line">DataStream&lt;...&gt; windowed = input</span><br><span class="line">  .keyBy(Transaction::getAccountId)</span><br><span class="line">  .window(<span class="comment">/*window specification*/</span>);</span><br></pre></td></tr></table></figure><p>这种方法是在广泛的用例中实现水平可伸缩性的主要模块，但是在应用程序试图在运行时提供业务逻辑灵活性的情况下，这还是不够的。为了理解为什么会发生这种情况，让我们首先以功能需求的形式为欺诈检测系统阐明一个现实的样本规则定义：</p><blockquote><p>在<strong>一个星期</strong> 之内，当 用户 <strong>A</strong> <strong>累计</strong> 向 <strong>B</strong> 用户支付的金额超过 <strong>1000000 美元</strong>，则触发一条告警</p></blockquote><p>PS：A 和 B 用字段描述的话分别是 付款人（payer）和受益人（beneficiary）</p><p>在上面的规则中，我们可以发现许多参数，我们希望能够在新提交的规则中指定这些参数，甚至可能在运行时进行动态的修改或调整：</p><ul><li>聚合的字段（付款金额）</li><li>分组字段（付款人和受益人）</li><li>聚合函数（求和）</li><li>窗口大小（1 星期）</li><li>阈值（1000000）</li><li>计算符号（大于）</li></ul><p>因此，我们将使用以下简单的 JSON 格式来定义上述参数：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ruleId"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"ruleState"</span>: <span class="string">"ACTIVE"</span>,</span><br><span class="line">  <span class="attr">"groupingKeyNames"</span>: [<span class="string">"payerId"</span>, <span class="string">"beneficiaryId"</span>],</span><br><span class="line">  <span class="attr">"aggregateFieldName"</span>: <span class="string">"paymentAmount"</span>,</span><br><span class="line">  <span class="attr">"aggregatorFunctionType"</span>: <span class="string">"SUM"</span>,</span><br><span class="line">  <span class="attr">"limitOperatorType"</span>: <span class="string">"GREATER"</span>,</span><br><span class="line">  <span class="attr">"limit"</span>: <span class="number">1000000</span>,</span><br><span class="line">  <span class="attr">"windowMinutes"</span>: <span class="number">10080</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这一点上，重要的是了解 groupingKeyNames 决定了数据的实际物理分区，所有指定参数（payerId + beneficiaryId）相同的交易数据都会汇总到同一个物理计算 operator 里面去。很明显，如果要实现这样的功能，在 Flink 里面是使用 keyBy 函数来完成。</p><p>Flink 官方文档中 keyBy() 函数的大多数示例都是使用硬编码的 <code>KeySelector</code>，它提取特定数据的字段。但是，为了支持所需的灵活性，我们必须根据规则中的规范以更加动态的方式提取它们，为此，我们将不得不使用一个额外的运算符，该运算符会将每条数据分配到正确的聚合实例中。</p><p>总体而言，我们的主要处理流程如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Alert&gt; alerts =</span><br><span class="line">    transactions</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">        .keyBy(<span class="comment">/* some key selector */</span>);</span><br><span class="line">        .process(<span class="comment">/* actual calculations and alerting */</span>)</span><br></pre></td></tr></table></figure><p>先前我们已经建立了每个规则定义一个<strong><code>groupingKeyNames</code></strong>参数，该参数指定将哪些字段组合用于传入事件的分组。每个规则可以使用这些字段的任意组合。同时，每个传入事件都可能需要根据多个规则进行评估。这意味着事件可能需要同时出现在计算 operator 的多个并行实例中，这些实例对应于不同的规则，因此需要进行分叉。确保此类事件的调度能达到 <code>DynamicKeyFunction()</code> 的目的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-22-004512.jpg" alt=""></p><p><code>DynamicKeyFunction</code>迭代一组已定义的规则，并通过 <code>keyBy()</code>函数提取所有数据所需的分组 key ：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicKeyFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessFunction</span>&lt;<span class="title">Transaction</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">   ...</span><br><span class="line">  <span class="comment">/* Simplified */</span></span><br><span class="line">  List&lt;Rule&gt; rules = <span class="comment">/* Rules that are initialized somehow.</span></span><br><span class="line"><span class="comment">                        Details will be discussed in a future blog post. */</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      Transaction event,</span></span></span><br><span class="line"><span class="function"><span class="params">      Context ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">      Collector&lt;Keyed&lt;Transaction, String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (Rule rule :rules) &#123;</span><br><span class="line">       out.collect(</span><br><span class="line">           <span class="keyword">new</span> Keyed&lt;&gt;(</span><br><span class="line">               event,</span><br><span class="line">               KeysExtractor.getKey(rule.getGroupingKeyNames(), event),</span><br><span class="line">               rule.getRuleId()));</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>KeysExtractor.getKey()</code>使用反射从数据中提取<code>groupingKeyNames</code>里面所有所需字段的值，并将它们拼接为字符串，例如<code>&quot;{payerId=25;beneficiaryId=12}&quot;</code>。Flink 将计算该字符串的哈希值，并将此特定组合的数据处理分配给集群中的特定服务器。这样就会跟踪<em>付款人25</em>和<em>受益人12</em>之间的所有交易，并在所需的时间范围内评估定义的规则。</p><p>注意，<code>Keyed</code>引入了具有以下签名的包装器类作为输出类型<code>DynamicKeyFunction</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Keyed</span>&lt;<span class="title">IN</span>, <span class="title">KEY</span>, <span class="title">ID</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> IN wrapped;</span><br><span class="line">  <span class="keyword">private</span> KEY key;</span><br><span class="line">  <span class="keyword">private</span> ID id;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">  <span class="function"><span class="keyword">public</span> KEY <span class="title">getKey</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> key;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此 POJO 的字段携带了以下信息：<code>wrapped</code>是原始数据，<code>key</code>是使用 <code>KeysExtractor</code>提取出来的结果，<code>id</code>是导致事件的调度规则的 ID（根据规则特定的分组逻辑）。</p><p>这种类型的事件将作为<code>keyBy()</code>函数的输入，并允许使用简单的 lambda 表达式作为<a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/api_concepts.html#define-keys-using-key-selector-functions"><code>KeySelector</code></a>实现动态数据 shuffle 的最后一步。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Alert&gt; alerts =</span><br><span class="line">    transactions</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">        .keyBy((keyed) -&gt; keyed.getKey());</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicAlertFunction())</span><br></pre></td></tr></table></figure><p>通过应用，<code>DynamicKeyFunction</code>我们隐式复制了事件，以便在 Flink 集群中并行的执行每个规则评估。通过这样做，我们获得了一个重要的功能——规则处理的水平可伸缩性。通过向集群添加更多服务器，即增加并行度，我们的系统将能够处理更多规则。实现此功能的代价是数据重复，这可能会成为一个问题，具体取决于一组特定的参数，例如传入数据速率，可用网络带宽，事件有效负载大小等。在实际情况下，可以进行其他优化应用，例如组合计算具有相同groupingKeyNames 的规则，或使用过滤层，将事件中不需要处理特定规则的所有字段删除。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在此博客文章中，我们通过查看示例用例（欺诈检测引擎）讨论了如何对 Flink 应用程序进行动态，运行时更改。我们已经描述了总体项目结构及其组件之间的交互，并提供了使用 docker 进行构建和运行演示欺诈检测应用程序。然后，我们展示了将 <strong>数据动态分区</strong> ，这是第一个实现灵活的动态配置的代码案例。</p><p>为了专注于描述本案例的核心机制，我们将 DSL 和基本规则引擎的复杂性降至最低。在未来，不难想象会添加一些扩展，例如允许使用更复杂的规则定义，包括某些事件的过滤，逻辑规则链接以及其他更高级的功能。</p><p>在本系列的第二篇博客中，我们将描述规则如何进入正在运行的欺诈检测引擎。此外，我们将详细介绍引擎的主要处理功能 <em>DynamicAlertFunction()</em> 的实现细节。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-22-011700.jpg" alt=""></p><p>在下一篇文章中，我们会教大家如何利用 Apache Flink 的广播流在我们的欺诈检测系统中动态的处理规则。</p><blockquote><p>本篇文章属于翻译文章，作者：zhisheng</p><p>原文地址：<a href="http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/">http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/</a></p><p>英文作者：<a href="https://twitter.com/alex_fedulov">alex_fedulov</a> </p><p>英文原文地址：<a href="https://flink.apache.org/news/2020/01/15/demo-fraud-detection.html">https://flink.apache.org/news/2020/01/15/demo-fraud-detection.html</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何实现呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Forward Asia 2020 全部 PPT 开放下载</title>
    <link href="http://www.54tianzhisheng.cn/2020/12/21/flink-forward-Asia-2020/"/>
    <id>http://www.54tianzhisheng.cn/2020/12/21/flink-forward-Asia-2020/</id>
    <published>2020-12-20T16:00:00.000Z</published>
    <updated>2020-12-21T15:12:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink Forward Asia 2020 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面图片介绍。</p><a id="more"></a><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142353.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142431.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142511.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142538.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142616.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142643.png" alt=""></p><h3 id="如何获取上面这些-PPT？"><a href="#如何获取上面这些-PPT？" class="headerlink" title="如何获取上面这些 PPT？"></a>如何获取上面这些 PPT？</h3><p>上面的这些 PPT 本人已经整理好了，你可以扫描下面二维码，关注微信公众号：zhisheng，然后在里面回复关键字: <strong>ffa2020</strong> 即可获取已放出的 PPT。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-28-144329.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink Forward Asia 2020 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面图片介绍。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.12 Release 文档解读</title>
    <link href="http://www.54tianzhisheng.cn/2020/12/06/Flink-1.12/"/>
    <id>http://www.54tianzhisheng.cn/2020/12/06/Flink-1.12/</id>
    <published>2020-12-05T16:00:00.000Z</published>
    <updated>2020-12-06T13:47:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.12 快要发布了，这里提前解读一下 Release 文档</p><a id="more"></a><p>本文的 Release 文档描述了在 Flink 1.11 和 Flink 1.12 之间更改的重要方面，例如配置，行为或依赖项。 如果您打算将 Flink 版本升级到 1.12，请仔细阅读这些说明。</p><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><p><strong>移除掉 ExecutionConfig 中过期的方法</strong></p><p>移除掉了 <code>ExecutionConfig#isLatencyTrackingEnabled</code> 方法, 你可以使用 <code>ExecutionConfig#getLatencyTrackingInterval</code> 方法代替.</p><p>移除掉了 <code>ExecutionConfig#enable/disableSysoutLogging</code>、<code>ExecutionConfig#set/isFailTaskOnCheckpointError</code> 过期的方法。</p><p>移除掉了 <code>-q</code> CLI 参数。</p><p><strong>移除掉过期的 <code>RuntimeContext#getAllAccumulators</code> 方法</strong></p><p>过期的 <code>RuntimeContext#getAllAccumulators</code> 方法被移除掉了，请使用 <code>RuntimeContext#getAccumulator</code> 方法作为代替。</p><p><strong>由于数据丢失的风险把 <code>CheckpointConfig#setPreferCheckpointForRecovery</code> 方法标为过期</strong></p><p><code>CheckpointConfig#setPreferCheckpointForRecovery</code> 方法标记为过期了, 因为作业在进行恢复时，如果使用较旧的 Checkpoint 状态而不使用新的 Save point 状态数据，可能会导致数据丢失。</p><p><strong>FLIP-134: DataStream API 的批处理执行</strong></p><ul><li>允许在 <code>KeyedStream.intervalJoin()</code> 的配置时间属性，在 Flink 1.12 之前 <code>KeyedStream.intervalJoin()</code> 算子的时间属性依赖于全局设置的时间属性。在 Flink 1.12 中我们可以在 IntervalJoin 方法后加上 <code>inProcessingTime()</code> 或 <code>inEventTime()</code> ，这样 Join 就不再依赖于全局的时间属性。</li></ul><ul><li><p>在 Flink 1.12 中将 DataStream API 的 <code>timeWindow()</code> 方法标记为过期，请使用 <code>window(WindowAssigner)</code>、<code>TumblingEventTimeWindows</code>、 <code>SlidingEventTimeWindows</code>、<code>TumblingProcessingTimeWindows</code> 或者 <code>SlidingProcessingTimeWindows</code>。</p></li><li><p>将 <code>StreamExecutionEnvironment.setStreamTimeCharacteristic()</code> 和 <code>TimeCharacteristic</code> 方法标记为过期。在 Flink 1.12 中，默认的时间属性改变成 EventTime 了，于是你不再需要该方法去开启 EventTime 了。在 EventTime 时间属性下，你使用 processing-time 的 windows 和 timers 也都依旧会生效。如果你想禁用水印，请使用 <code>ExecutionConfig.setAutoWatermarkInterval(long)</code> 方法。如果你想使用 <code>IngestionTime</code>，请手动设置适当的 WatermarkStrategy。如果你使用的是基于时间属性更改行为的通用 ‘time window’ 算子(eg: <code>KeyedStream.timeWindow()</code>)，请使用等效操作明确的指定处理时间和事件时间。</p></li><li><p>允许在 CEP PatternStream 上显式配置时间属性在 Flink 1.12 之前，CEP 算子里面的时间依赖于全局配置的时间属性，在 1.12 之后可以在 PatternStream 上使用 <code>inProcessingTime()</code> 或 <code>inEventTime()</code> 方法。</p></li></ul><p><strong>API 清理</strong></p><ul><li><p>移除了 UdfAnalyzer 配置，移除了 <code>ExecutionConfig#get/setCodeAnalysisMode</code> 方法和 <code>SkipCodeAnalysis</code> 类。</p></li><li><p>移除了过期的 <code>DataStream#split</code> 方法，该方法从很早的版本中已经标记成为过期的了，你可以使用 Side Output 来代替。</p></li><li><p>移除了过期的 <code>DataStream#fold()</code> 方法和其相关的类，你可以使用更加高性能的 <code>DataStream#reduce</code>。</p></li></ul><p><strong>扩展 CompositeTypeSerializerSnapshot 以允许复合序列化器根据外部配置迁移</strong></p><p>不再推荐使用 CompositeTypeSerializerSnapshot 中的 <code>isOuterSnapshotCompatible(TypeSerializer)</code> 方法，推荐使用 <code>OuterSchemaCompatibility#resolveOuterSchemaCompatibility(TypeSerializer)</code> 方法。</p><p><strong>将 Scala 版本升级到 2.1.1</strong></p><p>Flink 现在依赖 Scala 2.1.1，意味着不再支持 Scala 版本小于 2.11.11。</p><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><p><strong>对 aggregate 函数的 SQL DDL 使用新类型推断</strong></p><p>aggregate 函数的 <code>CREATE FUNCTION</code> DDL 现在使用新类型推断，可能有必要将现有实现更新为新的反射类型提取逻辑，将 <code>StreamTableEnvironment.registerFunction</code> 标为过期。</p><p><strong>更新解析器模块 FLIP-107</strong></p><p>现在 <code>METADATA</code> 属于保留关键字，记得使用反引号转义。</p><p><strong>将内部 aggregate 函数更新为新类型</strong></p><p>使用 COLLECT 函数的 SQL 查询可能需要更新为新类型的系统。</p><h2 id="Connectors-和-Formats"><a href="#Connectors-和-Formats" class="headerlink" title="Connectors 和 Formats"></a>Connectors 和 Formats</h2><p><strong>移除 Kafka 0.10.x 和 0.11.x Connector</strong></p><p>在 Flink 1.12 中，移除掉了 Kafka 0.10.x 和 0.11.x Connector，请使用统一的 Kafka Connector（适用于 0.10.2.x 版本之后的任何 Kafka 集群），你可以参考 Kafka Connector 页面的文档升级到新的 Flink Kafka Connector 版本。</p><p><strong>CSV 序列化 Schema 包含行分隔符</strong></p><p><code>csv.line-delimiter</code> 配置已经从 CSV 格式中移除了，因为行分隔符应该由 Connector 定义而不是由 format 定义。如果用户在以前的 Flink 版本中一直使用了该配置，则升级到 Flink 1.12 时，应该删除该配置。</p><p><strong>升级 Kafka Schema Registry Client 到 5.5.0 版本</strong></p><p><code>flink-avro-confluent-schema-registry</code> 模块不再在 fat-jar 中提供，你需要显式的在你自己的作业中添加该依赖，SQL-Client 用户可以使用<code>flink-sql-avro-confluent-schema-registry</code> fat jar。</p><p><strong>将 Avro 版本从 1.8.2 升级到 1.10.0 版本</strong></p><p><code>flink-avro</code> 模块中的 Avro 版本升级到了 1.10，如果出于某种原因要使用较旧的版本，请在项目中明确降级 Avro 版本。</p><p><strong>注意</strong>：我们观察到，与 1.8.2 相比，Avro 1.10 版本的性能有所下降，如果你担心性能，并且可以使用较旧版本的 Avro，那么请降级 Avro 版本。</p><p><strong>为 SQL Client 打包 <code>flink-avro</code> 模块时会创建一个 uber jar</strong></p><p>SQL Client jar 会被重命名为 <code>flink-sql-avro-1.12.jar</code>，以前是 <code>flink-avro-1.12-sql-jar.jar</code>，而且不再需要手动添加 Avro 依赖。</p><h2 id="Deployment（部署）"><a href="#Deployment（部署）" class="headerlink" title="Deployment（部署）"></a>Deployment（部署）</h2><p><strong>默认 Log4j 配置了日志大小超过 100MB 滚动</strong></p><p>默认的 log4j 配置现在做了变更：除了在 Flink 启动时现有的日志文件滚动外，它们在达到 100MB 大小时也会滚动。Flink 总共保留 10 个日志文件，从而有效地将日志目录的总大小限制为 1GB（每个 Flink 服务记录到该目录）。</p><p><strong>默认在 Flink Docker 镜像中使用 jemalloc</strong></p><p>在 Flink 的 Docker 镜像中，jemalloc 被用作默认的内存分配器，以减少内存碎片问题。用户可以通过将 <code>disable-jemalloc</code> 标志传递给 <code>docker-entrypoint.sh</code> 脚本来回滚使用 glibc。有关更多详细信息，请参阅 Docker 文档上的 Flink。</p><p><strong>升级 Mesos 版本到 1.7</strong></p><p>将 Mesos 依赖版本从 1.0.1 版本升级到 1.7.0 版本。</p><p><strong>如果 Flink 进程在超时后仍未停止，则发送 SIGKILL</strong></p><p>在 Flink 1.12 中，如果 SIGTERM 无法成功关闭 Flink 进程，我们更改了独立脚本的行为以发出 SIGKILL。</p><p><strong>介绍非阻塞作业提交</strong></p><p>提交工作的语义略有变化，提交调用几乎立即返回，并且作业处于新的 INITIALIZING 状态，当作业处于该状态时，对作业做 Savepoint 或者检索作业详情信息等操作将不可用。</p><p>一旦创建了该作业的 JobManager，该作业就处于 CREATED 状态，并且所有的调用均可用。</p><h2 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h2><p><strong>FLIP-141: Intra-Slot Managed Memory 共享</strong></p><p><code>python.fn-execution.buffer.memory.size</code> 和 <code>python.fn-execution.framework.memory.size</code> 的配置已删除，因此不再生效。除此之外，<code>python.fn-execution.memory.managed</code> 默认的值更改为 <code>true</code>， 因此默认情况下 Python workers 将使用托管内存。</p><p><strong>FLIP-119 Pipelined Region Scheduling</strong></p><p>从 Flink 1.12 开始，将以 pipelined region 为单位进行调度。pipelined region 是一组流水线连接的任务。这意味着，对于包含多个 region 的流作业，在开始部署任务之前，它不再等待所有任务获取 slot。取而代之的是，一旦任何 region 获得了足够的任务 slot 就可以部署它。对于批处理作业，将不会为任务分配 slot，也不会单独部署任务。取而代之的是，一旦某个 region 获得了足够的 slot，则该任务将与所有其他任务一起部署在同一区域中。</p><p>可以使用 <code>jobmanager.scheduler.scheduling-strategy：legacy</code> 启用旧的调度程序。</p><p><strong>RocksDB optimizeForPointLookup 导致丢失时间窗口</strong></p><p>默认情况下，我们会将 RocksDB 的 ReadOptions 的 setTotalOrderSeek 设置为true，以防止用户忘记使用 optimizeForPointLookup。 同时，我们支持通过RocksDBOptionsFactory 自定义 ReadOptions。如果观察到任何性能下降，请将 setTotalOrderSeek 设置为 false（根据我们的测试，这是不可能的）。</p><p><strong>自定义 OptionsFactory 设置似乎对 RocksDB 没有影响</strong></p><p>过期的 OptionsFactory 和 ConfigurableOptionsFactory 类已移除，请改用 RocksDBOptionsFactory 和 ConfigurableRocksDBOptionsFactory。 如果有任何扩展 DefaultConfigurableOptionsFactory 的类，也请重新编译你的应用程序代码。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.12 快要发布了，这里提前解读一下 Release 文档&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>强烈推荐三本 Spark 新书籍</title>
    <link href="http://www.54tianzhisheng.cn/2020/10/18/Spark-book/"/>
    <id>http://www.54tianzhisheng.cn/2020/10/18/Spark-book/</id>
    <published>2020-10-17T16:00:00.000Z</published>
    <updated>2020-10-18T10:49:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>挺好的三本书</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>看到标题大家可能会想，zhisheng 之前不是一直写 Flink 相关的文章吗？咋开始推荐 Spark 书籍了，这里解释一下，因为本人前段时间接手了公司 Spark 引擎，所以偶尔也会抽空学习一下 Spark，这不看到几本不错的 Spark 书籍，于是想在这里与大家分享一下。</p><h3 id="《Stream-Processing-with-Apache-Spark》"><a href="#《Stream-Processing-with-Apache-Spark》" class="headerlink" title="《Stream Processing with Apache Spark》"></a>《Stream Processing with Apache Spark》</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-101423.png" alt=""></p><p>这本书出版时间是 2019 年 6 月，算是与 《Stream Processing with Apache Flink》是姊妹篇，主要是讲 Spark 的流处理，比如 Structured Streaming 和 Spark Streaming，对 Spark 流处理感兴趣的不可错过该书，虽然现在 Flink 是流处理的 No1，但是并不影响对比着学习他们之间的技术。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-100905.png" alt="流处理章节目录"></p><h3 id="《Learning-Spark-2nd-Edition》"><a href="#《Learning-Spark-2nd-Edition》" class="headerlink" title="《Learning Spark, 2nd Edition》"></a>《Learning Spark, 2nd Edition》</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-101504.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-101551.png" alt=""></p><p>这本书出版时间是 2020 年 7 月，全书我觉得对于整个 Spark 的体系讲的还是很全的，从概念的介绍，到 API / SQL 的使用，再到如何优化 Spark 作业，接着讲解了 Structured Streaming，然后还讲解了通过 Spark 构建数据湖，并且该章节中还对目前很热门的三大数据湖框架 Apache Hudi / Apache Iceberg / Delta Lake 进行了介绍。接着讲解了 Spark 在机器学习相关场景的水碱和应用，最后介绍了 Spark 3.0 的新特性，也是目前唯一不多介绍 Spark 3.0 版本的书籍之一。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-102258.png" alt="本书的目录"></p><h3 id="《Spark-in-Action-2nd-Edition》"><a href="#《Spark-in-Action-2nd-Edition》" class="headerlink" title="《Spark in Action, 2nd Edition》"></a>《Spark in Action, 2nd Edition》</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-102357.png" alt=""></p><p>本书出版时间是 2020 年 5 月，出版社是 Manning，不同于上面两本书是出版于 O’Reilly。本书内容跟其标题其实还是比较相符的，主讲实战，目录如下。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-103030.png" alt=""></p><p>扫描下面二维码，回复 Spark 可获取本文提及到的三本书</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-103615.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;挺好的三本书&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spark" scheme="http://www.54tianzhisheng.cn/tags/Spark/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>用了 Flink History Server，妈妈再也不用担心我的作业半夜挂了</title>
    <link href="http://www.54tianzhisheng.cn/2020/10/13/flink-history-server/"/>
    <id>http://www.54tianzhisheng.cn/2020/10/13/flink-history-server/</id>
    <published>2020-10-12T16:00:00.000Z</published>
    <updated>2020-10-15T00:34:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>保存作业停止之前的信息</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Flink On YARN 默认作业挂了之后打开的话，是一个如下这样的页面：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-151818.jpg" alt="作业失败后"></p><p>对于这种我们页面我们只能查看 JobManager 的日志，不再可以查看作业挂掉之前的运行的 Web UI，很难清楚知道作业在挂的那一刻到底发生了啥？如果我们还没有 Metrics 监控的话，那么完全就只能通过日志去分析和定位问题了，所以如果能还原之前的 Web UI，我们可以通过 UI 发现和定位一些问题。</p><h3 id="History-Server-介绍"><a href="#History-Server-介绍" class="headerlink" title="History Server 介绍"></a>History Server 介绍</h3><p>那么这里就需要利用 Flink 中的 History Server 来解决这个问题。那么 History Server 是什么呢？</p><p>它可以用来在相应的 Flink 集群关闭后查询已完成作业的统计信息。例如有个批处理作业是凌晨才运行的，并且我们都知道只有当作业处于运行中的状态，才能够查看到相关的日志信息和统计信息。所以如果作业由于异常退出或者处理结果有问题，我们又无法及时查看（凌晨运行的）作业的相关日志信息。那么 History Server 就显得十分重要了，因为通过 History Server 我们才能查询这些已完成作业的统计信息，无论是正常退出还是异常退出。</p><p>此外，它对外提供了 REST API，它接受 HTTP 请求并使用 JSON 数据进行响应。Flink 任务停止后，JobManager 会将已经完成任务的统计信息进行存档，History Server 进程则在任务停止后可以对任务统计信息进行查询。比如：最后一次的 Checkpoint、任务运行时的相关配置。</p><p>那么如何开启这个呢？你需要在 flink-conf.yml 中配置如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>==============================================================================</span><br><span class="line"><span class="meta">#</span> HistoryServer</span><br><span class="line"><span class="meta">#</span>==============================================================================</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> The HistoryServer is started and stopped via bin/historyserver.sh (start|stop)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Directory to upload completed jobs to. Add this directory to the list of</span><br><span class="line"><span class="meta">#</span> monitored directories of the HistoryServer as well (see below). </span><br><span class="line"><span class="meta">#</span> flink job 运行完成后的日志存放目录</span><br><span class="line">jobmanager.archive.fs.dir: hdfs:///flink/history-log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> The address under which the web-based HistoryServer listens.</span><br><span class="line"><span class="meta">#</span> flink history进程所在的主机</span><br><span class="line"><span class="meta">#</span>historyserver.web.address: 0.0.0.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> The port under which the web-based HistoryServer listens.</span><br><span class="line"><span class="meta">#</span> flink history进程的占用端口</span><br><span class="line"><span class="meta">#</span>historyserver.web.port: 8082</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Comma separated list of directories to monitor for completed jobs.</span><br><span class="line"><span class="meta">#</span> flink history进程的hdfs监控目录</span><br><span class="line">historyserver.archive.fs.dir: hdfs:///flink/history-log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Interval in milliseconds for refreshing the monitored directories.</span><br><span class="line"><span class="meta">#</span> 刷新受监视目录的时间间隔（以毫秒为单位）</span><br><span class="line"><span class="meta">#</span>historyserver.archive.fs.refresh-interval: 10000</span><br></pre></td></tr></table></figure><p>注意： <strong>jobmanager.archive.fs.dir 要和 historyserver.archive.fs.dir 配置的路径要一样</strong> </p><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/historyserver.sh start</span><br></pre></td></tr></table></figure><p>发现报错如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">2020-10-13 21:21:01,310 main INFO  org.apache.flink.core.fs.FileSystem                           - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.</span><br><span class="line">2020-10-13 21:21:01,336 main INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory  - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.</span><br><span class="line">2020-10-13 21:21:01,352 main INFO  org.apache.flink.runtime.security.modules.JaasModule          - Jaas file will be created as /tmp/jaas-354359771751866787.conf.</span><br><span class="line">2020-10-13 21:21:01,355 main INFO  org.apache.flink.runtime.security.SecurityUtils               - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.</span><br><span class="line">2020-10-13 21:21:01,363 main WARN  org.apache.flink.runtime.webmonitor.history.HistoryServer     - Failed to create Path or FileSystem for directory 'hdfs:///flink/history-log'. Directory will not be monitored.</span><br><span class="line">org.apache.flink.core.fs.UnsupportedFileSystemSchemeException: Could not find a file system implementation for scheme 'hdfs'. The scheme is not directly supported by Flink and no Hadoop file system to support this scheme could be loaded.</span><br><span class="line">        at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:450)</span><br><span class="line">        at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:362)</span><br><span class="line">        at org.apache.flink.core.fs.Path.getFileSystem(Path.java:298)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:187)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:137)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:122)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:119)</span><br><span class="line">        at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.main(HistoryServer.java:119)</span><br><span class="line">Caused by: org.apache.flink.core.fs.UnsupportedFileSystemSchemeException: Hadoop is not in the classpath/dependencies.</span><br><span class="line">        at org.apache.flink.core.fs.UnsupportedSchemeFactory.create(UnsupportedSchemeFactory.java:58)</span><br><span class="line">        at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:446)</span><br><span class="line">        ... 8 more</span><br><span class="line">2020-10-13 21:21:01,367 main ERROR org.apache.flink.runtime.webmonitor.history.HistoryServer     - Failed to run HistoryServer.</span><br><span class="line">org.apache.flink.util.FlinkException: Failed to validate any of the configured directories to monitor.</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:196)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:137)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:122)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:119)</span><br><span class="line">        at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.main(HistoryServer.java:119)</span><br></pre></td></tr></table></figure><p>这个异常的原因是因为 Flink 集群的 CLASS_PATH 下缺少了 HDFS 相关的 jar，我们可以引入 HDFS 的依赖放到 lib 目录下面或者添加 Hadoop 的环境变量。</p><p>这里我们在 historyserver.sh 脚本中增加下面脚本，目的就是添加 Hadoop 的环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> export hadoop classpath</span><br><span class="line">if [ `command -v hadoop` ];then</span><br><span class="line">  export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line">else</span><br><span class="line">  echo "hadoop command not found in path!"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>添加后再启动脚本则可以运行成功了，打开页面 <code>机器IP:8082</code> 则可以看到历史所有运行完成或者失败的作业列表信息。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-141733.png" alt="作业列表信息"></p><p>点进单个作业可以看到作业挂之前的所有信息，便于我们去查看挂之前作业的运行情况（Exception 信息/Checkpoint 信息/算子的流入和流出数据量信息等）</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-142108.png" alt="作业挂之前的运行情况"></p><h3 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h3><p>再来看看配置的 <code>/flink/history-log/</code> 目录有什么东西呢？执行下面命令可以查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls /flink/history-log/</span><br></pre></td></tr></table></figure><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152148.jpg" alt="hdfs 文件目录"></p><p>其实 history server 会在本地存储已结束 Job 信息，你可以配置 <code>historyserver.web.tmpdir</code> 来决定存储在哪，默认的拼接规则为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.getProperty(<span class="string">"java.io.tmpdir"</span>) + File.separator + <span class="string">"flink-web-history-"</span> + UUID.randomUUID()</span><br></pre></td></tr></table></figure><p>Linux 系统临时目录为 /tmp，你可以看到源码中 HistoryServerOptions 该类中的可选参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* The local directory used by the HistoryServer web-frontend.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;String&gt; HISTORY_SERVER_WEB_DIR =</span><br><span class="line">    key(<span class="string">"historyserver.web.tmpdir"</span>)</span><br><span class="line">        .noDefaultValue()</span><br><span class="line">        .withDescription(<span class="string">"This configuration parameter allows defining the Flink web directory to be used by the"</span> +</span><br><span class="line">            <span class="string">" history server web interface. The web interface will copy its static files into the directory."</span>);</span><br></pre></td></tr></table></figure><p>那么我们找到本地该临时目录，可以观察到里面保存着很多 JS 文件，其实就是我们刚才看到的页面</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152227.jpg" alt="本地临时目录"></p><p>历史服务存储文件中，存储了用于页面展示的模板配置。历史任务信息存储在 Jobs 路径下，其中包含了已经完成的 Job，每次启动都会从 historyserver.archive.fs.dir 拉取所有的任务元数据信息。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152249.jpg" alt="Jobs 目录"></p><p>每个任务文件夹中包含我们需要获取的一些信息，通过 REST API 获取时指标时，就是返回这些内容（Checkpoint/Exception 信息等）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152331.jpg" alt="具体 Job"></p><h3 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API"></a>REST API</h3><p>以下是可用且带有示例 JSON 响应的请求列表。所有请求格式样例均为 <code>http://hostname:8082/jobs</code>，下面我们仅列出了 URLs 的 <em>path</em> 部分。 尖括号中的值为变量，例如作业 <code>7684be6004e4e955c2a558a9bc463f65</code> 的 <code>http://hostname:port/jobs/&lt;jobid&gt;/exceptions</code> 请求须写为 <code>http://hostname:port/jobs/7684be6004e4e955c2a558a9bc463f65/exceptions</code>。</p><ul><li><code>/config</code></li><li><code>/jobs/overview</code></li><li><code>/jobs/&lt;jobid&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices</code></li><li><code>/jobs/&lt;jobid&gt;/config</code></li><li><code>/jobs/&lt;jobid&gt;/exceptions</code></li><li><code>/jobs/&lt;jobid&gt;/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasktimes</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/taskmanagers</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/&lt;subtasknum&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/&lt;subtasknum&gt;/attempts/&lt;attempt&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/&lt;subtasknum&gt;/attempts/&lt;attempt&gt;/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/plan</code></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这样我们就可以开心的去查看作业挂之前的 Web UI 信息了，妈妈在也不用担心我的作业挂了！😁</p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/zh/monitoring/historyserver.html">History Server</a> </li><li><a href="https://www.jianshu.com/p/48aaad9cfc7d">flink历史服务</a> </li></ul><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;保存作业停止之前的信息&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>如何生成 Flink 作业的交互式火焰图？</title>
    <link href="http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/"/>
    <id>http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/</id>
    <published>2020-10-04T16:00:00.000Z</published>
    <updated>2020-10-11T14:09:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 作业生成火焰图</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Flink 是目前最流行的大数据及流式计算框架之一，用户可以使用 Java/Scala/Python  的DataStream 接口或者标准 SQL 语言来快速实现一个分布式高可用的流式应用，通过内部的 Java JIT、off-heap 内存管理等技术优化性能，并且有完整的 Source、Sink、WebUI、Metrics 等功能集成，让 Flink 几乎成为了流式计算的事实标准。</p><p>但是当处理海量数据的时候，很容易出现各种异常和性能瓶颈，这时我们需要优化系统性能时，常常需要分析程序运行行为和性能瓶颈。Profiling 技术是一种在应用运行时收集程序相关信息的动态分析手段，常用的 JVM Profiler 可以从多个方面对程序进行动态分析，如 CPU、Memory、Thread、Classes、GC 等，其中 CPU Profiling 的应用最为广泛。CPU Profiling 经常被用于分析代码的执行热点，如“哪个方法占用 CPU 的执行时间最长”、“每个方法占用 CPU 的比例是多少”等等，通过 CPU Profiling 得到上述相关信息后，研发人员就可以轻松针对热点瓶颈进行分析和性能优化，进而突破性能瓶颈，大幅提升系统的吞吐量。</p><p>本文介绍我们在做性能优化常用的火焰图以及为如何集成火焰图到通用的 Flink 作业中。</p><h3 id="火焰图介绍"><a href="#火焰图介绍" class="headerlink" title="火焰图介绍"></a>火焰图介绍</h3><p>火焰图是《性能之巅》作者以及 DTrace 等一系列 Linux 系统优化工具作者 Brendan Gregg 大神的作品之一，可以非常清晰地展示应用程序的函数调用栈以及函数调用时间占比，基本原理是通过各种 agent 在程序运行时采样并输出日志，使用 FlameGraph 工具把日志提取出来输出可在浏览器交互式查看的 SVG图片。</p><p>Uber 开源了 jvm-profiler 项目，介绍如何为 Spark 应用和 Java 应用添加火焰图支持，但是目前 Flink 社区和  jvm-profiler 官网都还没有相关的使用教程。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-06-3411601968266_.pic_hd.jpg" alt=""></p><p>实际上基于 JVM 的程序都可以使用这个工具，本文将基于 jvm-profiler 来介绍如何生成 Flink 作业的火焰图。</p><h3 id="下载和编译-jvm-profiler"><a href="#下载和编译-jvm-profiler" class="headerlink" title="下载和编译 jvm-profiler"></a>下载和编译 jvm-profiler</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone git clone https://github.com/uber-common/jvm-profiler.git</span><br><span class="line"></span><br><span class="line">mvn clean install -DskipTests=true -Dcheckstyle.skip -Dfast -T 8C</span><br></pre></td></tr></table></figure><p>编译好了之后，将项目 target 目录下的 jvm-profiler-1.0.0.jar 复制一份到 flink 的 lib 目录下面</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp target/jvm-profiler-1.0.0.jar /usr/local/flink-1.11.1/lib</span><br></pre></td></tr></table></figure><h3 id="下载-FlameGraph"><a href="#下载-FlameGraph" class="headerlink" title="下载 FlameGraph"></a>下载 FlameGraph</h3><p>由于 jvm-profiler 支持生成火焰图需要的日志文件，将日志转化成交互式 SVG 图片还是使用 Brendan Gregg 的FlameGraph 工具。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/brendangregg/FlameGraph.git</span><br></pre></td></tr></table></figure><p>下载项目源码即可，后面会使用 flamegraph.pl 工具来生成图片文件。</p><h3 id="配置-Flink"><a href="#配置-Flink" class="headerlink" title="配置 Flink"></a>配置 Flink</h3><p>对于 Flink 应用，我们只需要在 TaskManager 中注入打点的 Java agent 即可，这里测试，我就使用本地 standalone 模式，修改 Flink conf 目录下的 flink-conf.yaml 文件，添加一下如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.java.opts.taskmanager: "-javaagent:/usr/local/flink-1.11.1/lib/jvm-profiler-1.0.0.jar=sampleInterval=50"</span><br></pre></td></tr></table></figure><p>目前最小的采样间隔就是 50 毫秒，然后启动集群和运行一个 Flink 作业：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./bin/start-cluster.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//运行一个作业</span><br><span class="line">./bin/flink run ./examples/streaming/StateMachineExample.jar</span><br></pre></td></tr></table></figure><p>运行之后可以看到 TaskManager 的 stdout 里面打印如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-06-3421601969081_.pic_hd.jpg" alt=""></p><p>因为已经注入 Java agent，因此在标准输出中会定期添加火焰图所需要的打点数据，然后使用下面的命令提取相关日志，并且使用 jvm-profiler 和 FlameGraph 提供的工具来生成 SVG 图片文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//1、提取 stdout 文件中的相关日志</span><br><span class="line"></span><br><span class="line">cat log/flink-zhisheng-taskexecutor-0-zhisheng.out | grep "ConsoleOutputReporter - Stacktrace:" | awk '&#123;print substr($0,37)&#125;' &gt; stacktrace.json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、在 jvm-profiler 目录下执行下面命令</span><br><span class="line"></span><br><span class="line">python ./stackcollapse.py -i /usr/local/flink-1.11.1/stacktrace.json &gt; stacktrace.folded</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//3、在 FlameGraph 目录下执行下面命令生成 SVG 图片</span><br><span class="line"></span><br><span class="line">./flamegraph.pl /Users/zhisheng/Documents/github/jvm-profiler/stacktrace.folded &gt; stacktrace.svg</span><br></pre></td></tr></table></figure><p>然后用浏览器打开刚才生成的 SVG 图片就可以看到火焰图信息。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-06-073728.png" alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文主要目的在于教大家如何利用 jvm-profiler 去生成 Flink 作业的运行火焰图，这样可以在遇到性能瓶颈问题的时候会很方便大家去定位问题，关于如何去读懂生成的火焰图，后面可以再分享系列文章。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://tech.meituan.com/2019/10/10/jvm-cpu-profiler.html">JVM CPU Profiler技术原理及源码深度解析</a> </li><li><a href="https://github.com/uber-common/jvm-profiler">jvm-profile</a> </li></ul><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 作业生成火焰图&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 精进学习知识星球内容整理</title>
    <link href="http://www.54tianzhisheng.cn/2020/08/09/flink-zsxq/"/>
    <id>http://www.54tianzhisheng.cn/2020/08/09/flink-zsxq/</id>
    <published>2020-08-08T16:00:00.000Z</published>
    <updated>2020-10-11T14:12:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>整理自己发在知识星球和公众号的系列文章，方便查找。</p><a id="more"></a><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><br />进知识星球的小伙伴有的是刚接触 Flink 的，有的是根本没接触过的<img src="https://cdn.nlark.com/yuque/0/2020/png/311057/1596964608579-e55b42ad-54e1-4390-bdad-1c290b1476aa.png#align=left&amp;display=inline&amp;height=20&amp;margin=%5Bobject%20Object%5D&amp;originHeight=48&amp;originWidth=48&amp;size=0&amp;status=done&amp;style=none&amp;width=20" alt="">，有的是已经用 Flink 很久的，所以很难适合所有的口味。<br /><br><br />我一向认为对一门技术的学习方式应该是：<br /></p><ul><li>了解（知道它的相关介绍、用处）</li><li>用（了解常用 API）</li><li>用熟（对常用 API 能够用熟来，并了解一些高级 API）</li><li>解决问题（根据业务场景遇到的问题能够定位问题并解决）</li><li>看源码（深入源码的实现，此种情况主要是兴趣爱好驱动）</li></ul><p><br />这里先把《从 0 到 1 学习 Flink》的系列文章给列出来，我觉得从这个系列文章的顺序来学习起码可以让你先达到第四个步骤，如果有什么疑问或者文章不足之处欢迎指出。</p><p><a name="kPvuh"></a></p><h3 id="《从-0-到-1-学习-Flink》系列"><a href="#《从-0-到-1-学习-Flink》系列" class="headerlink" title="《从 0 到 1 学习 Flink》系列"></a>《从 0 到 1 学习 Flink》系列</h3><ul><li><a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从 0 到 1 学习 —— Apache Flink 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从 0 到 1 学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从 0 到 1 学习 —— Flink 配置文件详解</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从 0 到 1 学习 —— Flink JobManager 高可用性配置</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从 0 到 1 学习 —— Data Source 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从 0 到 1 学习 —— 如何自定义 Data Source ？</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从 0 到 1 学习 —— Data Sink 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从 0 到 1 学习 —— 如何自定义 Data Sink ？</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从 0 到 1 学习 —— Flink Data transformation(转换)</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从 0 到 1 学习 —— 介绍Flink中的Stream Windows</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从 0 到 1 学习 —— </a><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239105&amp;idx=1&amp;sn=be0c2c5bd4396e94561e8aa08d98625c&amp;chksm=8f5a1addb82d93cb184b782ac059c61230dc2f9b18604eb71542385647a094a21c30c5732447&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 流计算编程–看看别人怎么用 Session Window</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从 0 到 1 学习 —— </a><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239498&amp;idx=2&amp;sn=1b3d429f615d9bd9b0226f8737671546&amp;chksm=8f5a1856b82d9140c6ccc90e8ef1aeb7654da8187122a6e1722225b305c2c5a0534eed6ae992&amp;token=1858295303&amp;lang=zh_CN#rd">这一次带你彻底搞懂 Flink Watermark</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从 0 到 1 学习 —— Flink 中几种 Time 详解</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从 0 到 1 学习 —— Flink 项目如何运行？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从 0 到 1 学习 —— Flink parallelism 和 Slot 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从 0 到 1 学习 —— Flink 写入数据到 ElasticSearch</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从 0 到 1 学习 —— </a><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238504&amp;idx=1&amp;sn=7756ce7af39b2068eb72ced6f67cf992&amp;chksm=8f5a0474b82d8d6202674cb5b6eafc35f5e006111bc94c19a900da12a5ce416c1731a924055a&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 实时写入数据到 ElasticSearch 性能调优</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从 0 到 1 学习 —— Flink 写入数据到 Kafka</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从 0 到 1 学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从 0 到 1 学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从 0 到 1 学习 —— 你上传的 jar 包藏到哪里去了?</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— Flink 中如何管理配置？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从 0 到 1 学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来?</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint 轻量级分布式快照</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/uRN3VfA">使用 Prometheus Grafana 监控 Flink</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/yVnaYR7">使用 InflubDB 和 Grafana 监控 Flink JobManager TaskManager 和作业</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/vbIMJAu">从0到1搭建一套 Flink 监控系统</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/11/23/flink-metrics/">详解 Flink Metrics 原理与监控实战</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/RJqj6YV">Flink 读取 Kafka 商品数据后写入到 Redis</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/ny3Z3rb">一文搞懂 Flink 网络流控与反压机制</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://t.zsxq.com/UVfqfae">一文搞懂Flink内部的Exactly Once和At Least Once</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://t.zsxq.com/eYNBaAa">Flink On K8s</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://t.zsxq.com/zjQvjeM">Apache Flink 是如何管理好内存的?</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650241012&amp;idx=1&amp;sn=1fc2d3848c957f759036a5d2a55ae09f&amp;chksm=8f5a1da8b82d94be63cbd12d4ceac54442b353f3d1453d02de72898e7b4af7e0f1affca1d568&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 参数配置和常见参数调优</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239999&amp;idx=1&amp;sn=5183e97f78d35b59cb6cdc318de114a7&amp;chksm=8f5a19a3b82d90b59fe7cf9bf894f37245f722ed342fcc3a7fa046fe28cb8d4d6643c9c1cc84&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 状态生存时间（State TTL）机制的底层实现</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239366&amp;idx=2&amp;sn=7489bf383e2deb3921daf6480887e090&amp;chksm=8f5a1bdab82d92cc6dcdf71ea51663b7d647f2259fe6e27b5244a66891c0156f6dfe233a7fe8&amp;token=1858295303&amp;lang=zh_CN#rd">Flink State 最佳实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239077&amp;idx=2&amp;sn=39bedd4f5a381f06a133acae290edd86&amp;chksm=8f5a1a39b82d932fb1000ad1f45492b1b42c1eec3bb40ec40198bbc71d3e03b2134c2d242f7f&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 使用大状态时的一点优化</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239265&amp;idx=2&amp;sn=cbc2bda736883cd9f695893a19e50544&amp;chksm=8f5a1b7db82d926b20f0e2740303227da5b47bac2a661ccd61257c18b7d26b8207eab045abff&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 使用 broadcast 实现维表或配置的实时更新</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238830&amp;idx=2&amp;sn=8791a75eb00b50f3a687527fe9e10667&amp;chksm=8f5a0532b82d8c2443cd6c0f9f0ddaff0be73cfda21a1db0a66cf7c586eed4f9b77bf3eb7b68&amp;token=1858295303&amp;lang=zh_CN#rd">Spark/Flink广播实现作业配置动态更新</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239009&amp;idx=2&amp;sn=2c63bcba31f91a15ca2e2cf3cacf5566&amp;chksm=8f5a1a7db82d936bc6114dacfed17ca9ad4a92eab2c941ad35bfd90aefb67d35f741ace80563&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 清理过期 Checkpoint 目录的正确姿势</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238962&amp;idx=1&amp;sn=b66c4940b1243fa74343650d1b3dc93a&amp;chksm=8f5a05aeb82d8cb8453aee1435114a0fcfe50dc219fd1b3dfdf074d39f8ca6e7de802d5bae23&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 状态管理与 Checkpoint 机制</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/">Flink 能否动态更改 Checkpoint 配置</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/">Flink Checkpoint 问题排查实用指南</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238609&amp;idx=2&amp;sn=ad36eb812f8d487895300d0cfe2b1604&amp;chksm=8f5a04cdb82d8ddb73c8624c20a7875f197f67bcf5569e1077f4df49107e494aa2c277beaae8&amp;token=1858295303&amp;lang=zh_CN#rd">Apache Flink 管理大型状态之增量 Checkpoint 详解</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238515&amp;idx=2&amp;sn=980e495c5373e64ef249c1ab1b6e072c&amp;chksm=8f5a046fb82d8d79032fffb76cabdbcccf60518ec54451ae4f2db6a5a89ffb0ed3ffe8132e4c&amp;token=1858295303&amp;lang=zh_CN#rd">深入理解 Flink 容错机制</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239239&amp;idx=2&amp;sn=8ea3e361350f7e5475d2f5acab24fe48&amp;chksm=8f5a1b5bb82d924d8d3b091cd8c6f756f984de3fcec945f08d59973b01454e86c73684982c8c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 使用 connect 实现双流匹配</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239115&amp;idx=2&amp;sn=f6ff30687c0ecaf2e10b23434674257e&amp;chksm=8f5a1ad7b82d93c1f2f492f70ea5257671eba44f48c00c1be8008310af15ad857c66fbbbc2cf&amp;token=1858295303&amp;lang=zh_CN#rd">Flink流计算编程–Flink扩容、程序升级前后的思考</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239150&amp;idx=2&amp;sn=738a83a0c4981ac851c077d27fc390bb&amp;chksm=8f5a1af2b82d93e42d24119e8563a6ec50968e5c3d9bce7f075777baff37f63583a169055a6d&amp;token=1858295303&amp;lang=zh_CN#rd">Flink HDFS Sink 如何保证 exactly-once 语义</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/08/24/Flink-Connector/">Flink Connector 深度解析</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">如何使用 Side Output 来分流？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 不可以连续 Split(分流)？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238825&amp;idx=1&amp;sn=28da5840a8c22c7c675d7d4987824f33&amp;chksm=8f5a0535b82d8c232681d2bc935bf99fa7c3d05f0406c184f71722e53a5209b2f19816f31ae1&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 全链路端到端延迟的测量方法</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238573&amp;idx=2&amp;sn=7d2488578fc93bfeaa58ddb4279925ce&amp;chksm=8f5a0431b82d8d272250167dd261369a9ed824f94a1edc9ac49e73f16368b29b1e538bbfc62a&amp;token=1858295303&amp;lang=zh_CN#rd">Flink on Yarn / K8s 原理剖析及实践</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238455&amp;idx=2&amp;sn=1b8cec83df9c72a4dbe56b11d6d3e7f0&amp;chksm=8f5a07abb82d8ebddb349f2f48cae697a6a39a9bab16b80fba4850bb325ee2010c6df0cf8599&amp;token=1858295303&amp;lang=zh_CN#rd">如何使用 Kubernetes 部署 Flink 应用</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238685&amp;idx=2&amp;sn=b023313ecbaf30d9a66e75636c6dfa7a&amp;chksm=8f5a0481b82d8d970433c857c11a4e5af971f21d6c9c4e70eb619cfeb2b871a344b3a7764830&amp;token=1858295303&amp;lang=zh_CN#rd">一张图轻松掌握 Flink on YARN 基础架构与启动流程</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238700&amp;idx=2&amp;sn=a391c6cf1f1e4d6e22f6453a4033f575&amp;chksm=8f5a04b0b82d8da68459f17ea2105b9f5f130b5aff498579e6cf4cb426cd6109a3a2462f1f5c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink on YARN 常见问题与排查思路</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238695&amp;idx=2&amp;sn=222d820e2a0485ab31811b6ab774b0b2&amp;chksm=8f5a04bbb82d8dad2650a4e751743d950a64082f2b7ba7796f8d35a936c076453b1cf3f0abbb&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 单并行度内使用多线程来提高作业性能</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238477&amp;idx=1&amp;sn=fe053b103d62978274a6163110ee7b7a&amp;chksm=8f5a0451b82d8d471d071e3260eb4acb20e7e3633d36bcd557f43d1065842305e183f0f9a0df&amp;token=1858295303&amp;lang=zh_CN#rd">Flink中资源管理机制解读与展望</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238405&amp;idx=1&amp;sn=a262bef27509f0017688e16374ad44c0&amp;chksm=8f5a0799b82d8e8f99a365822bc678b77ced5dc03c3c4817a4f8635d9b77e96e0ac258e88ffa&amp;token=1858295303&amp;lang=zh_CN#rd">Flink Back Pressure(背压)是怎么实现的？有什么绝妙之处？</a> </li></ul><p><br /><br><a name="0yw1g"></a></p><h3 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h3><ul><li><a href="https://wx.zsxq.com/dweb2/index/tags/Flink%20SQL/828214288542">知识星球 Flink 标签所有内容</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240680&amp;idx=1&amp;sn=4046b105912524306ca4ceb4a598a251&amp;chksm=8f5a1cf4b82d95e251b6caf14715d992d213219006b9bddb7883cdd203960fe6eaf5f796af47&amp;token=1858295303&amp;lang=zh_CN#rd">Java SPI 机制在 Flink SQL 中的应用</a> </li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 通过 DDL 和 SQL 来实现读取 Kafka 数据并处理后将数据写回 Kafka</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink SQL 实战——读取Kafka数据处理后写入 ElasticSearch 6 和 7 两种版本</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239141&amp;idx=2&amp;sn=4b441f383f479215ebd5e1f5bb8a650f&amp;chksm=8f5a1af9b82d93ef123a7789811551fe5d7d3e0360a7b48ead90befdbdf8b75ce7ad2cf1629c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 聚合性能优化 – MiniBatch 分析</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239126&amp;idx=1&amp;sn=10b51d1409f5b3461294139aa5cc7e9e&amp;chksm=8f5a1acab82d93dcd301ab695419ce829e7623c708d8cc8ed3099c7d00882f0211431b3c68e2&amp;token=1858295303&amp;lang=zh_CN#rd">Flink流计算编程：双流中实现Inner Join、Left Join与Right Join</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238819&amp;idx=2&amp;sn=97f1b2ddca379a28e390b21858bfc05b&amp;chksm=8f5a053fb82d8c29881f4a788cd254322223cb39299c6211ec93bdccae13162dd023a38dea1f&amp;token=1858295303&amp;lang=zh_CN#rd">Flink SQL 如何实现数据流的 Join？</a> </li></ul><p><a name="86fd4aa6"></a></p><h3 id="《Flink-各版本功能特性解读》"><a href="#《Flink-各版本功能特性解读》" class="headerlink" title="《Flink 各版本功能特性解读》"></a>《Flink 各版本功能特性解读》</h3><ul><li><a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a> </li><li><a href="https://t.zsxq.com/rFEUVBA">Flink 1.11 日志文件该如何配置？</a> </li><li><a href="https://t.zsxq.com/a27yRJu">Flink 1.11 Release 文档解读</a></li><li><a href="https://t.zsxq.com/NNNVj2j">Apache Flink 1.10 TaskManager 内存管理优化</a> </li><li><a href="https://t.zsxq.com/3BEemeq">Flink 版本升级方案</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240568&amp;idx=2&amp;sn=49a5e1418e6974584f404de03a6bc9d2&amp;chksm=8f5a1c64b82d957287c1fefa6bf89a0da3c596c9b33f8c289e47aaf2c82d7aafeabe3785ccbe&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 1.11 新特性详解:【非对齐】Unaligned Checkpoint 优化高反压</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240506&amp;idx=2&amp;sn=de3023a00224753985258156174f7103&amp;chksm=8f5a1fa6b82d96b0592606cdf12ced520d108dac8c2bc867f9fb16ed1243cff3c8418cad68a8&amp;token=1858295303&amp;lang=zh_CN#rd">千呼万唤，Apache Flink 1.11.0 新功能正式介绍</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239638&amp;idx=1&amp;sn=24f51ee03ca45304aa46ebeda2ac95b1&amp;chksm=8f5a18cab82d91dcd8dd1d3953f2979ccc83f86256eacb286f8c6f52e76c185ca084ebbe6719&amp;token=1858295303&amp;lang=zh_CN#rd">重磅！Apache Flink 1.11 会有哪些牛逼的功能</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239034&amp;idx=2&amp;sn=484ee31a60a14245bff0c07260537398&amp;chksm=8f5a1a66b82d93700626252ecab8766d19900543eb1e65c74ee9c99eb3c91d7f3fc944a90807&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 1.10 新特性研究</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/22/flink-1.9/">修改代码150万行！Apache Flink 1.9.0做了这些重大修改！</a> </li></ul><p><br /></p><p><a name="fGimX"></a></p><h3 id="《Flink-在大厂的实践与应用》"><a href="#《Flink-在大厂的实践与应用》" class="headerlink" title="《Flink 在大厂的实践与应用》"></a>《Flink 在大厂的实践与应用》</h3><ul><li><a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">携程——如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a> </li><li><a href="https://t.zsxq.com/v7QzNZ3">数据仓库、数据库的对比介绍与实时数仓案例分享</a> </li><li><a href="https://t.zsxq.com/MniUnqb">基于 Apache Flink 的监控告警系统 文章</a></li><li><a href="http://www.54tianzhisheng.cn/2019/12/23/flink-monitor-alert/">基于 Apache Flink 的监控告警系统 视频</a></li><li><a href="https://t.zsxq.com/FMRNvr7">如何利用Flink Rest API 监控满足生产环境非常刚需的需求</a></li><li><a href="https://t.zsxq.com/NvnuRNj">无流量 Flink 作业告警</a> </li><li><a href="https://t.zsxq.com/MRvzfAA">Apache Flink 维表关联实战</a> </li><li><a href="https://t.zsxq.com/2NbQFqF">如何利用 Flink 实时将应用 Error 日志告警？</a> </li><li><a href="https://t.zsxq.com/MvfUvzN">Flink 流批一体的技术架构以及在阿里 的实践</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240828&amp;idx=2&amp;sn=d05803fdf6f436fe1e61b6bc60eba375&amp;chksm=8f5a1d60b82d94769b7e787773f82e7d339dd495d4d46bd8916585212cbbda145fbf99e731b9&amp;token=1858295303&amp;lang=zh_CN#rd">基于 Flink 搭建实时个性化营销平台？</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240481&amp;idx=1&amp;sn=1f33c26869d87d0093232c5b70a0c02a&amp;chksm=8f5a1fbdb82d96ab07611d1a18d12645b2b0c0b339e27338c9c7203045b06d838ae88f31ae1d&amp;token=1858295303&amp;lang=zh_CN#rd">基于 Flink 和 Drools 的实时日志处理</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239383&amp;idx=1&amp;sn=10933a52ddf0d7da1f8714076721c93a&amp;chksm=8f5a1bcbb82d92dd6fac7130b8de1505d6333619f7f47fc85fda53825191a24f88b8ccc922b2&amp;token=1858295303&amp;lang=zh_CN#rd">新一代大数据实时数据架构到底长啥样</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239356&amp;idx=1&amp;sn=01af257bbe0f0ac4e55120fd223081bf&amp;chksm=8f5a1b20b82d92361e759118362e832bfd30ff1a47530494122ee880a47f3faf7c49bc55ba4b&amp;token=1858295303&amp;lang=zh_CN#rd">从 Spark Streaming 到 Apache Flink：bilibili 实时平台的架构与实践</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239347&amp;idx=1&amp;sn=a5793f0e4f832ae6eb7d9583e1f4ec91&amp;chksm=8f5a1b2fb82d92395ef6262c1217dbda64a1601103c6d3672a35d760f58148db0febcb62d7ae&amp;token=1858295303&amp;lang=zh_CN#rd">日均万亿条数据如何处理？爱奇艺实时计算平台这样做</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239313&amp;idx=1&amp;sn=ea9865bb3fe191ef0c1839638e46f866&amp;chksm=8f5a1b0db82d921bae1a6cf70f008b7486f5f8f7d72f14e90f9ef0d00ba15b588d224340e732&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 流批一体的实践与探索</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239311&amp;idx=2&amp;sn=8045b336e524067172ecd407ae35898a&amp;chksm=8f5a1b13b82d920556ab98abe5a2c02edd3672299884b2ef99c8efde49465483854e9cf96d68&amp;token=1858295303&amp;lang=zh_CN#rd">趣头条基于 Flink+ClickHouse 构建实时数据分析平台</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239271&amp;idx=1&amp;sn=490e5ce1363fe73ef4b9b785bdaee46f&amp;chksm=8f5a1b7bb82d926dcfcf9515ee36a28bbee67c3aa15490a2889ded545a68f37a12258348f53c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 维表关联多种方案对比</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/12/30/flink-meituan-real-time-warehouse/">美团点评基于 Flink 的实时数仓平台实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/12/10/flink-real-time-data-analysis-platform/">基于 Apache Flink 的大规模准实时数据分析平台</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/11/30/flink-checkpoint-hdfs/">阿里巴巴 Flink 踩坑经验：如何大幅降低 HDFS 压力？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/11/30/flink-in-58/">58 同城基于 Flink 的千亿级实时计算平台架构实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/11/30/flink-aqniu/">基于 Flink 构建关联分析引擎的挑战和实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/25/flink-didi/">滴滴实时计算发展之路及平台架构实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/23/flink-ebay/">如何使用 Flink 每天实时处理百亿条日志？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/20/Flink-meituan-dw/">美团点评基于 Flink 的实时数仓建设实践</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238820&amp;idx=1&amp;sn=652c34aff71827174011e999caaad037&amp;chksm=8f5a0538b82d8c2e6203f921cf2fdd0ceab0bc54e9bdd2696036887ffc1cbeb6f8f25bfe0df1&amp;token=1858295303&amp;lang=zh_CN#rd">基于Kafka+Flink+Redis的电商大屏实时计算案例</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238731&amp;idx=1&amp;sn=706a72f5ad2e4c3bb1ce22980886af46&amp;chksm=8f5a0557b82d8c41312f88d1baf3feb1dca719805645938e2e1cc691402b18c65215d73ef43b&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 在小红书推荐系统中的应用</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238450&amp;idx=1&amp;sn=109ecd71a60b1f96c6d8a020e08ab65e&amp;chksm=8f5a07aeb82d8eb8bbd8bfb10febc977a42df7633cee79162c5300da0ce40ed93cabedb59b05&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 实战 | 贝壳找房基于Flink的实时平台建设</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238345&amp;idx=2&amp;sn=f62f1dca57a5782bc3c68e63699ce4a4&amp;chksm=8f5a07d5b82d8ec36f3931bb7da3fc24c4a2bc0ecf60b686cc3fb33c45eba02aca833c4a4cb9&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 在趣头条的应用与实践</a> </li></ul><p><br /><br><br /></p><p><a name="0ycqX"></a></p><h3 id="《Flink-实战与性能优化》专栏部分文章"><a href="#《Flink-实战与性能优化》专栏部分文章" class="headerlink" title="《Flink 实战与性能优化》专栏部分文章"></a>《Flink 实战与性能优化》专栏部分文章</h3><p><br />因为这个专栏是一开始自己写的，当时还没有和任何一家公司签协议，所以当时就是想放在知识星球的，后面有公司联系，才有完整的专栏文章诞生出来，否则自己也不知道是否可以坚持写完这个系列，所以后面合作开这个专栏后新写的文章就没放在星球了，因为签了合同的，是不能够在其他平台公开的，这里希望大家可以体谅，但是已经早公开的依旧不会删除掉的，有如下这些文章：<br /></p><ul><li><a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹实时计算框架Flink</a> </li><li><a href="https://t.zsxq.com/fqfuVRR">《大数据重磅炸弹——实时计算引擎 Flink》开篇词</a> </li></ul><p><strong>预备篇</strong>：</p><ul><li><a href="https://t.zsxq.com/emMBaQN">你公司到底需不需要引入实时计算引擎？</a> </li><li><a href="https://t.zsxq.com/eM3ZRf2">一文让你彻底了解大数据实时计算框架 Flink</a> </li><li><a href="https://t.zsxq.com/eAyRz7Y">别再傻傻的分不清大数据框架Flink、Blink、Spark Streaming、Structured Streaming和Storm之间的区别了</a> </li><li><a href="https://t.zsxq.com/iaMJAe6">Flink 环境准备看这一篇就够了</a>  </li><li><a href="https://t.zsxq.com/iaMJAe6">一文讲解从 Flink 环境安装到源码编译运行</a>  </li><li><a href="https://t.zsxq.com/eaIIiAm">通过 WordCount 程序教你快速入门上手 Flink</a> </li><li><a href="https://t.zsxq.com/Vnq72jY">Flink 如何处理 Socket 数据及分析实现过程</a> </li><li><a href="https://t.zsxq.com/BiyvFUZ">Flink job 如何在 Standalone、YARN、Mesos、K8S 上部署运行？</a>   </li></ul><p><br /><strong>基础篇 :</strong></p><ul><li><a href="https://t.zsxq.com/fufUBiA">Flink 数据转换必须熟悉的算子（Operator)</a>   </li><li><a href="https://t.zsxq.com/r7aYB2V">Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</a>  </li><li><a href="https://t.zsxq.com/byZbyrb">如何使用 Flink Window 及 Window 基本概念与实现原理</a>   </li><li><a href="https://t.zsxq.com/VzNBi2r">如何使用 DataStream API 来处理数据？</a>  </li><li><a href="https://t.zsxq.com/Iub6IQf">Flink WaterMark 详解及结合 WaterMark 处理延迟数据</a> </li><li><a href="https://t.zsxq.com/IufaAU3">Flink 常用的 Source 和 Sink Connectors 介绍</a></li><li><a href="https://t.zsxq.com/ayB6miy">Flink 最最最常使用的 Connector —— Kafka 该如何使用？</a></li><li><a href="https://t.zsxq.com/qBAUji2">如何自定义 Flink Connectors（Source 和 Sink）？</a></li><li><a href="https://t.zsxq.com/n2rJAQR">Flink 读取 Kafka 数据后如何批量写入到 MySQL？</a></li><li><a href="https://t.zsxq.com/QRvJq7U">一文了解如何使用 Flink Connectors —— ElasticSearch？</a></li><li><a href="https://t.zsxq.com/aQVVvn2">一文了解如何使用 Flink Connectors —— HBase？</a></li><li><a href="https://t.zsxq.com/vJ2V3rZ">如何利用 Redis 存储 Flink 计算后的数据？</a></li></ul><p><a name="5CT86"></a></p><h3 id="《Flink-源码解析文章》"><a href="#《Flink-源码解析文章》" class="headerlink" title="《Flink 源码解析文章》"></a>《Flink 源码解析文章》</h3><ul><li><a href="https://t.zsxq.com/UZfaYfE">Flink 源码解析 —— 源码编译运行</a>   </li><li><a href="https://t.zsxq.com/zZZjaYf">Flink 源码解析 —— 项目结构一览</a>   </li><li><a href="https://t.zsxq.com/zZZjaYf">Flink 源码解析 —— </a><a href="https://t.zsxq.com/fEQN7Aa">Flink 源码的结构和其对应的功能点</a></li><li><a href="https://t.zsxq.com/qnMFEUJ">Flink 源码解析—— local 模式启动流程</a>   </li><li><a href="https://t.zsxq.com/QZVRZJA">Flink 源码解析 —— standalonesession 模式启动流程</a>  </li><li><a href="https://t.zsxq.com/u3fayvf">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a>   </li><li><a href="https://t.zsxq.com/MnQRByb">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a>   </li><li><a href="https://t.zsxq.com/YJ2Zrfi">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a>  </li><li><a href="https://t.zsxq.com/qnMFEUJ">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a>  </li><li><a href="https://t.zsxq.com/naaMf6y">Flink 源码解析 —— 如何获取 JobGraph？</a>  </li><li><a href="https://t.zsxq.com/qRFIm6I">Flink 源码解析 —— 如何获取 StreamGraph？</a>  </li><li><a href="https://t.zsxq.com/2VRrbuf">Flink 源码解析 —— Flink JobManager 有什么作用？</a>  </li><li><a href="https://t.zsxq.com/RZbu7yN">Flink 源码解析 —— Flink TaskManager 有什么作用</a>   </li><li><a href="https://t.zsxq.com/3JQJMzZ">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a>  </li><li><a href="https://t.zsxq.com/eu7mQZj">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a>  </li><li><a href="https://t.zsxq.com/ynQNbeM">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a>  </li><li><a href="https://t.zsxq.com/JaQfeMf">Flink 源码解析 —— 深度解析 Flink 序列化机制</a>   </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-core 源码解析</a>   </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-datadog 源码解析</a>   </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-dropwizard 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-graphite 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-influxdb 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-jmx 源码解析</a> </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-slf4j 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-statsd 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-prometheus 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink 注解源码解析</a> </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 实战</a> </li></ul><p><br /></p><p><a name="8rxG3"></a></p><h3 id="《Flink-自己录制过的视频》"><a href="#《Flink-自己录制过的视频》" class="headerlink" title="《Flink 自己录制过的视频》"></a>《Flink 自己录制过的视频》</h3><ul><li><a href="https://t.zsxq.com/RJqj6YV">Flink 整合 Apollo 动态更新配置</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 整合 Nacos 动态更新配置</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 专栏的开篇词</a> </li><li><a href="https://t.zsxq.com/RJqj6YV">你公司到底需不需要引入实时计算引擎</a></li><li><a href="https://t.zsxq.com/RJqj6YV">一文让你彻底了解大数据实时计算框架 Flink</a></li><li><a href="https://t.zsxq.com/RJqj6YV">别再傻傻的分不清大数据框架 Flink、Blink、Spark Streaming、Structured Streaming 和 Storm 之间的区别了</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink环境准备</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink环</a><a href="https://t.zsxq.com/RJqj6YV">境</a><a href="https://t.zsxq.com/RJqj6YV">安装</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink WordCount 程序入门上手及分析实现过程</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 如何处理 Socket 数据及分析实现过程</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</a></li><li><a href="https://t.zsxq.com/RJqj6YV">如何使用 Flink Window 及 Window 基本概念与实现原理</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink_Window组件深度讲解和如何自定义Window</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 读取 Kafka 商品数据后写入到 Redis</a></li><li><a href="https://t.zsxq.com/RJqj6YV">基于 Apache Flink 的监控告警系统</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink源码解析01——源码编译运行</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析02——源码结构一览</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析03——源码阅读规划</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析04——flink-example模块源码结构</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析05——flink-example模块源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析06——flink-example-streaming 异步IO源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析07——flink-example-streaming SideOutput源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析08——flink-example-streaming Socket源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析09——flink-example-streaming window和join源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析10——flink-example-streaming 源码分析总结</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink到底是否可以动态更改checkpoint配置</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 通过 DDL 和 SQL 来实现读取 Kafka 数据并处理后将数据写回 Kafka</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink SQL 实战——读取Kafka数据处理后写入 ElasticSearch 6 和 7 两种版本</a></li></ul><p><br /><br><br /></p><p><a name="R5umY"></a></p><h3 id="其他资源下载"><a href="#其他资源下载" class="headerlink" title="其他资源下载"></a>其他资源下载</h3><ul><li><a href="http://www.54tianzhisheng.cn/2019/12/07/Flink_Forward_Asia_2019/">Flink Forward Asia 2019 的 PPT和视频下载</a></li><li><a href="http://www.54tianzhisheng.cn/2020/05/13/flink-forward-2020/">Flink Forward 2020 PPT 下载</a> </li><li><a href="https://t.zsxq.com/emuVZrb">实时计算平台架构（上）</a></li><li><a href="https://t.zsxq.com/UnmMZN7">实时计算平台架构（下）</a></li><li><a href="https://t.zsxq.com/VfQ76iU">基于Flink实现的商品实时推荐系统</a></li><li><a href="https://t.zsxq.com/jIYB6QR">Flink1.8学习路线</a></li><li><a href="https://t.zsxq.com/6Q3vN3b">Kafka 学习文章和视频</a> </li><li><a href="https://t.zsxq.com/UNvnae6">数据分析指南</a> </li><li><a href="https://t.zsxq.com/jei27QZ">TimeoutException The heartbeat of TaskManager</a> </li><li><a href="https://t.zsxq.com/nu3fyV7">Flink on RocksDB 参数调优指南</a> </li><li><a href="https://t.zsxq.com/RRvjAyn">2020最新Java面试题及答案</a> </li><li><a href="https://t.zsxq.com/vBuzVj6">以业务为核心的中台体系建设</a> </li><li><a href="https://t.zsxq.com/Q7uVrvz">Skip List–跳表(全网最详细的跳表文章没有之一)</a> </li><li><a href="https://t.zsxq.com/N37mUzB">Stream Processing with Apache Flink</a> </li><li><a href="https://t.zsxq.com/NZf2JAq">假如我是面试官，我会问你这些问题，请接招</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239970&amp;idx=2&amp;sn=8703de96f1657bd811953dfff4d6abdd&amp;chksm=8f5a19beb82d90a8949b3bdd0c517ae66becede295307d6e3d7f8e634b82a2972797ef8648b9&amp;token=1858295303&amp;lang=zh_CN#rd">YARN 运行机制分析</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239168&amp;idx=1&amp;sn=2e3e8d26b3eec376782b4415be86b399&amp;chksm=8f5a1a9cb82d938afc6c842187b255120624bfaa7c8090a9554277f08f279c28500d1191dd8a&amp;token=1858295303&amp;lang=zh_CN#rd">企业大数据平台仓库架构建设思路</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238519&amp;idx=1&amp;sn=7967857af5e7c435715c388592e326f9&amp;chksm=8f5a046bb82d8d7d15c678d21e274301183a446911dd66739a8728aa6794033eb6cea7d62ea5&amp;token=1858295303&amp;lang=zh_CN#rd">吐血之作 | 流系统Spark/Flink/Kafka/DataFlow端到端一致性实现对比</a> </li></ul><p><br /><br><br /><br><br />另外就是星球里可以向我提问，我看到问题会及时回答的，发现提问的还是比较少，想想当初就该还是要所有的都付费才能进，免费进的就会让你不珍惜自己付出的钱💰，自己也不会持续跟着一直学习下去。后面我会根据提问情况把长期潜水且当初是没付费的移除掉！<br /><br><br />还有就是群里的一些问题解答会同步到这里沉淀下来！如果你对这些问题还有更好的解答也欢迎提出你的回答，如果觉得棒的话我会进行一定额度的打赏！<br /><br><br />打赏包括但不限制于：<br /></p><ul><li>高质量的问题</li><li>学习资料资源分享</li><li>问题全面的解答</li><li>分享自己的建议</li></ul><p><br />好好做好这几点，肯定会把入知识星球的钱赚到！<br /><br><br />为什么要做一个这样的 Flink 知识星球？<br /></p><ul><li>帮助他人成长就是自己在成长</li><li>主动促使自己去深入这门技术（心里总觉得要对得起付费玩家）</li><li>真的想遇到那么一两个人可以一直好好学习下去（学习真特么是孤独的，一个人学习确实遇到的坑很多，效率肯定也低点，如果没有找到的话，那么还是我自己的那句话：坑要自己一个个填，路要自己一步步走！）</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p><br />一个人走的快一些，一群人走的远一些，欢迎扫码上面的二维码加入知识星球，我们一起向前！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;整理自己发在知识星球和公众号的系列文章，方便查找。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.11 日志该如何配置？</title>
    <link href="http://www.54tianzhisheng.cn/2020/08/02/flink-1.11-log/"/>
    <id>http://www.54tianzhisheng.cn/2020/08/02/flink-1.11-log/</id>
    <published>2020-08-01T16:00:00.000Z</published>
    <updated>2020-07-09T04:39:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.11 日志升级到了 Log4j2，并且 Web UI 增强了功能。</p><a id="more"></a><h3 id="Flink-1-11-之前"><a href="#Flink-1-11-之前" class="headerlink" title="Flink 1.11 之前"></a>Flink 1.11 之前</h3><p>在 Flink 1.11 之前，Flink 使用的日志是 Log4j，配置文件 <code>log4j.properties</code> 中的内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">log4j.rootLogger=INFO, file</span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#log4j.logger.org.apache.flink=INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">log4j.logger.akka=INFO</span><br><span class="line">log4j.logger.org.apache.kafka=INFO</span><br><span class="line">log4j.logger.org.apache.hadoop=INFO</span><br><span class="line">log4j.logger.org.apache.zookeeper=INFO</span><br><span class="line"></span><br><span class="line"># Log all infos in the given file</span><br><span class="line">log4j.appender.file=org.apache.log4j.FileAppender</span><br><span class="line">log4j.appender.file.file=$&#123;log.file&#125;</span><br><span class="line">log4j.appender.file.append=false</span><br><span class="line">log4j.appender.file.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.file.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, file</span><br></pre></td></tr></table></figure><p>该配置文件会将 JobManager 和 TaskManager 的日志分别打印在不同的文件中，每个文件的日志大小一直会增加，如果想配置日志文件按大小滚动的话可以使用 RollingFileAppender，则要将配置文件改成如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">log4j.rootLogger=INFO, RFA</span><br><span class="line"> </span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#log4j.logger.org.apache.flink=INFO</span><br><span class="line"> </span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">log4j.logger.akka=INFO</span><br><span class="line">log4j.logger.org.apache.kafka=INFO</span><br><span class="line">log4j.logger.org.apache.hadoop=INFO</span><br><span class="line">log4j.logger.org.apache.zookeeper=INFO</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">log4j.appender.RFA=org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.RFA.File=$&#123;log.file&#125;</span><br><span class="line">log4j.appender.RFA.MaxFileSize=256MB</span><br><span class="line">log4j.appender.RFA.Append=true</span><br><span class="line">log4j.appender.RFA.MaxBackupIndex=10</span><br><span class="line">log4j.appender.RFA.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.RFA.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %t %-5p %-60c %x - %m%n</span><br><span class="line"> </span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, RFA</span><br></pre></td></tr></table></figure><p><strong>为什么要在生产环境下将日志文件改成按照大小滚动呢？</strong></p><p>无非是在生产情况下，流数据是非常大的，有的时候自己可能会通过 print() 打印出来流数据进来验证结果，有的时候可能是打印的日志记录做 debug 用，然后到生产忘记关了，结果到生产就全部将流数据打印出来，这种情况下，就会导致 TaskManager 的日志文件会非常大，那么我们打开 Web UI 查看可能就会很卡，这也就是为啥我们有时候打开 Web UI 查看日志的时候，非常卡顿，加载不出来的原因了，主要原因就是日志文件太大导致的。</p><p>当然有的同学可能会想着将 Flink 作业的日志发到 Kafka 做统一的收集，然后做一些日志分析告警和再消费发到 ElasticSearch 等去做日志搜索，如果是发到 Kafka，可以使用 KafkaLog4jAppender，日志文件配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">log4j.rootLogger=INFO, kafka</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#log4j.logger.org.apache.flink=INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">log4j.logger.akka=INFO</span><br><span class="line">log4j.logger.org.apache.kafka=INFO</span><br><span class="line">log4j.logger.org.apache.hadoop=INFO</span><br><span class="line">log4j.logger.org.apache.zookeeper=INFO</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># log send to kafka</span><br><span class="line">log4j.appender.kafka=org.apache.kafka.log4jappender.KafkaLog4jAppender</span><br><span class="line">log4j.appender.kafka.brokerList=localhost:9092</span><br><span class="line">log4j.appender.kafka.topic=flink_logs</span><br><span class="line">log4j.appender.kafka.compressionType=none</span><br><span class="line">log4j.appender.kafka.requiredNumAcks=0</span><br><span class="line">log4j.appender.kafka.syncSend=false</span><br><span class="line">log4j.appender.kafka.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.kafka.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p %c&#123;1&#125;:%L - %m%n</span><br><span class="line">log4j.appender.kafka.level=INFO</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, kafka</span><br></pre></td></tr></table></figure><h3 id="Flink-1-11"><a href="#Flink-1-11" class="headerlink" title="Flink 1.11"></a>Flink 1.11</h3><p>在 Flink 1.11 中，将 Log4j 升级到了 Log4j2，可以通过查看 <a href="https://github.com/apache/flink/pull/11073">FLINK-15672</a> 可以知道变更的文件很多，</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-08-03-152451.png" alt=""></p><p>新版本的日志配置文件还是叫 <code>log4j.properties</code>，配置如下所示，不清楚为啥 FLINK-15672 代码提交中改了很多地方的配置文件名为 <code>log4j2.properties</code>，但是 Flink 最后打包的 conf 目录下还是保持和之前一样的文件名，按道理不是也应该进行更改成 <code>log4j2.properties</code> 的吗？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">rootLogger.level = INFO</span><br><span class="line">rootLogger.appenderRef.file.ref = MainAppender</span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#logger.flink.name = org.apache.flink</span><br><span class="line">#logger.flink.level = INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">logger.akka.name = akka</span><br><span class="line">logger.akka.level = INFO</span><br><span class="line">logger.kafka.name= org.apache.kafka</span><br><span class="line">logger.kafka.level = INFO</span><br><span class="line">logger.hadoop.name = org.apache.hadoop</span><br><span class="line">logger.hadoop.level = INFO</span><br><span class="line">logger.zookeeper.name = org.apache.zookeeper</span><br><span class="line">logger.zookeeper.level = INFO</span><br><span class="line"></span><br><span class="line"># Log all infos in the given file</span><br><span class="line">appender.main.name = MainAppender</span><br><span class="line">appender.main.type = File</span><br><span class="line">appender.main.append = false</span><br><span class="line">appender.main.fileName = $&#123;sys:log.file&#125;</span><br><span class="line">appender.main.layout.type = PatternLayout</span><br><span class="line">appender.main.layout.pattern = %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline</span><br><span class="line">logger.netty.level = OFF</span><br></pre></td></tr></table></figure><p>默认这个配置也是不会对日志文件进行按照大小滚动的，那么如果我们要保持和之前的效果一样（按照日志大小滚动日志文件）该怎么做呢？你可以更改配置文件的内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">rootLogger.level = INFO</span><br><span class="line">rootLogger.appenderRef.rolling.ref = RollingFileAppender</span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#logger.flink.name = org.apache.flink</span><br><span class="line">#logger.flink.level = INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">logger.akka.name = akka</span><br><span class="line">logger.akka.level = INFO</span><br><span class="line">logger.kafka.name= org.apache.kafka</span><br><span class="line">logger.kafka.level = INFO</span><br><span class="line">logger.hadoop.name = org.apache.hadoop</span><br><span class="line">logger.hadoop.level = INFO</span><br><span class="line">logger.zookeeper.name = org.apache.zookeeper</span><br><span class="line">logger.zookeeper.level = INFO</span><br><span class="line"></span><br><span class="line"># Log all infos in the given rolling file</span><br><span class="line">appender.rolling.name = RollingFileAppender</span><br><span class="line">appender.rolling.type = RollingFile</span><br><span class="line">appender.rolling.append = false</span><br><span class="line">appender.rolling.fileName = $&#123;sys:log.file&#125;</span><br><span class="line">appender.rolling.filePattern = $&#123;sys:log.file&#125;.%i</span><br><span class="line">appender.rolling.layout.type = PatternLayout</span><br><span class="line">appender.rolling.layout.pattern = %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="line">appender.rolling.policies.type = Policies</span><br><span class="line">appender.rolling.policies.size.type = SizeBasedTriggeringPolicy</span><br><span class="line">appender.rolling.policies.size.size = 200MB</span><br><span class="line">appender.rolling.strategy.type = DefaultRolloverStrategy</span><br><span class="line">appender.rolling.strategy.max = 10</span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline</span><br><span class="line">logger.netty.level = OFF</span><br></pre></td></tr></table></figure><p>如果你升级了到 1.11 版本，不能继续延用之前 1.11 之前的配置的那种日志文件滚动的配置了，需要做点变更。上面配置的表示日志文件以每隔 200MB 会进行切分，然后日志切分后的文件名是 <code>${sys:log.file}.%i</code>，以数字结尾。</p><p>1.11 进行了配置厚度的效果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-08-03-154604.jpg" alt="TaskManager 日志列表展示"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-08-03-154643.jpg" alt="JobManager 日志列表展示"></p><p>从上面图中可以发现 1.11 对于查看日志比之前友好了不少，多个日志文件都有列表展示，而不再是之前只能查看单个日志文件了。</p><p>注：为了演示日志文件滚动的效果，测试的时候设置的日志 <code>appender.rolling.policies.size.size</code> 是 1KB</p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.11 日志升级到了 Log4j2，并且 Web UI 增强了功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.11 Release 文档解读</title>
    <link href="http://www.54tianzhisheng.cn/2020/06/29/flink-1.11/"/>
    <id>http://www.54tianzhisheng.cn/2020/06/29/flink-1.11/</id>
    <published>2020-06-28T16:00:00.000Z</published>
    <updated>2020-06-30T00:14:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.11 快要发布了，这里提前解读一下 Release 文档</p><a id="more"></a><h3 id="集群和部署"><a href="#集群和部署" class="headerlink" title="集群和部署"></a>集群和部署</h3><ul><li><strong>支持 Hadoop 3.0 及更高的版本</strong>：Flink 不再提供任何 <code>flink-shaded-hadoop-</code> 依赖。用户可以通过配置 HADOOP_CLASSPATH 环境变量(推荐)或在 lib 文件夹下放入 Hadoop 依赖项。另外 <code>include-hadoop</code> Maven profile 也已经被移除了。</li><li><strong>移除了 LegacyScheduler</strong>：Flink 不再支持 legacy scheduler，如果你设置了 <code>jobmanager.scheduler: legacy</code> 将不再起作用并且会抛出 IllegalArgumentException 异常，该参数的默认值并且是唯一选项为 ng。</li><li><strong>将用户代码的类加载器和 slot 的生命周期进行绑定</strong>：只要为单个作业分配了至少一个 slot，TaskManager 就会重新使用用户代码的类加载器。这会稍微改变 Flink 的恢复行为，从而不会重新加载静态字段。这样做的好处是，可以大大减轻对 JVM metaspace 的压力。</li><li><strong>slave 文件重命名为 workers</strong>：对于 Standalone 模式安装，worker 节点文件不再是 slaves 而是 workers，以前使用 <code>start-cluster.sh</code>  和 <code>stop-cluster.sh</code>  脚本的设置需要重命名该文件。</li><li><strong>完善 Flink 和 Docker 的集成</strong>： <code>Dockerfiles</code> 文件样例和 <code>build.sh</code> Docker 镜像文件都从 Flink GitHub 仓库中移除了，这些示例社区不再提供，因此 <code>flink-contrib/docker-flink</code> 、 <code>flink-container/docker</code> 和 <code>flink-container/kubernetes</code> 模块都已删除了。目前你可以通过查看 <a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/deployment/docker.html">Flink Docker integration</a> 官方文档学会如何使用和自定义 Flink Docker 镜像，文档中包含了 docker run、docker compose、docker swarm 和 standalone Kubernetes。</li></ul><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><ul><li><strong>JobManager 使用新的内存模型</strong>：可以参考 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-116%3A+Unified+Memory+Configuration+for+Job+Managers">FLIP-116</a>，介绍了 JobManager 新的内存模型，提供了新的配置选项来控制 JobManager 的进程内存消耗，这种改变会影响 Standalone、YARN、Mesos 和 Active Kubernetes。如果你尝试在不做任何调整的情况下重用以前的Flink 配置，则新的内存模型可能会导致 JVM 的计算内存参数不同，从而导致性能发生变化甚至失败，可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/memory/mem_migration.html#migrate-job-manager-memory-configuration">Migrate Job Manager Memory Configuration</a> 文档进行迁移变更。 <code>jobmanager.heap.size</code> 和 <code>jobmanager.heap.mb</code> 配置参数已经过期了，如果这些过期的选项还继续使用的话，为了维持向后兼容性，它们将被解释为以下新选项之一：<ul><li>jobmanager.memory.heap.size：JVM Heap，为了 Standalone 和 Mesos 部署</li><li>jobmanager.memory.process.size：进程总内存，为了容器部署（Kubernetes 和 YARN）</li></ul></li></ul><p>   下面两个选项已经删除了并且不再起作用了：</p><ul><li>containerized.heap-cutoff-ratio</li><li>containerized.heap-cutoff-min</li></ul><p>   JVM 参数，JobManager JVM 进程的 direct 和 metaspace 内存现在通过下面两个参数进行配置：</p><ul><li>jobmanager.memory.off-heap.size</li><li><p>jobmanager.memory.jvm-metaspace.size</p><p>如果没有正确配置或存在相应的内存泄漏，这些新的限制可能会产生相应的 OutOfMemoryError 异常，可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/memory/mem_trouble.html#outofmemoryerror-direct-buffer-memory">OutOfMemoryError</a> 文档进行解决。</p></li></ul><ul><li><strong>移除过期的</strong><code>mesos.resourcemanager.tasks.mem</code><strong>参数</strong></li></ul><h3 id="Table-API-SQL"><a href="#Table-API-SQL" class="headerlink" title="Table API/SQL"></a>Table API/SQL</h3><ul><li><strong>Blink planner 成为默认的 planner</strong></li><li><p><strong>改变了 Table API 的包结构</strong>：由于包 <code>org.apache.flink.table.api.scala/java</code> 中的各种问题，这些包下的所有类都已迁移。 此外，如 Flink 1.9 中所述，scala 表达式已移至 <code>org.apache.flink.table.api</code> 。</p><p> 如果你之前使用了下面的类：</p><ul><li><code>org.apache.flink.table.api.java.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.scala.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.java.BatchTableEnvironment</code> </li><li><code>org.apache.flink.table.api.scala.BatchTableEnvironment</code> </li></ul></li></ul><p>   如果你不需要转换成 DataStream 或者从 DataStream 转换，那么你可以使用：</p><ul><li><code>org.apache.flink.table.api.TableEnvironment</code> </li></ul><p>   如果你需要转换成 DataStream/DataSet，或者从 DataStream/DataSet 转换，那么你需要将依赖 imports 改成：</p><ul><li><code>org.apache.flink.table.api.bridge.java.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.bridge.java.BatchTableEnvironment</code> </li><li><code>org.apache.flink.table.api.bridge.scala.BatchTableEnvironment</code> </li></ul><p>   对于 Scala 表达式，使用下面的 import：</p><ul><li><code>org.apache.flink.table.api._ instead of org.apache.flink.table.api.bridge.scala._</code> </li></ul><p>   如果你使用 Scala 隐式转换成 DataStream/DataSet，或者从 DataStream/DataSet 转换，那么该导入</p><ul><li><code>org.apache.flink.table.api.bridge.scala._</code> </li></ul><ul><li><strong>移除 StreamTableSink 接口中的 emitDataStream 方法</strong>：该接口的 emitDataStream 方法将移除</li><li><strong>移除 BatchTableSink 中的 emitDataSet 方法</strong>：将该接口的 emitDataSet 方法重命名为 consumeDataSet 并且返回 DataSink</li><li><strong>纠正</strong> <code>TableEnvironment.execute()</code><strong>和</strong> <code>StreamTableEnvironment.execute()</code> <strong>的执行行为</strong>：在早期的版本， <code>TableEnvironment.execute()</code> 和 <code>StreamExecutionEnvironment.execute()</code> 都可以触发 Table 程序和 DataStream 程序。从 Flink 1.11.0 开始，Table 程序只能由 <code>TableEnvironment.execute()</code> 触发。将 Table 程序转换为 DataStream 程序（通过 <code>toAppendStream()</code> 或 <code>toRetractStream()</code> 方法）后，只能由 <code>StreamExecutionEnvironment.execute()</code> 触发它。</li><li><strong>纠正</strong> <code>ExecutionEnvironment.execute()</code>  <strong>和</strong> <code>BatchTableEnvironment.execute()</code> <strong>的执行行为</strong>：在早期的版本中， <code>BatchTableEnvironment.execute()</code> 和 <code>ExecutionEnvironment.execute()</code> 都可以触发 Table 和 DataSet 应用程序（针对老的 planner）。 从 Flink 1.11.0 开始，批处理 Table 程序只能由 <code>BatchEnvironment.execute()</code> 触发。将 Table 程序转换为DataSet 程序（通过 toDataSet() 方法）后，只能由 <code>ExecutionEnvironment.execute()</code> 触发它。</li><li><strong>在 Row 类型中添加了更改标志</strong>：在 Row 类型中添加了一个更改标志 RowKind</li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li><strong>重命名</strong> <code>log4j-yarn-session.properties</code> <strong>和</strong> <code>logback-yarn.xml</code> <strong>配置文件</strong>：日志配置文件 <code>log4j-yarn-session.properties</code> 和 <code>logback-yarn.xml</code> 被重命名为 <code>log4j-session.properties</code> 和 <code>logback-session.xml</code> 而且， <code>yarn-session.sh</code> 和 <code>kubernet -session.sh</code> 使用这些日志配置文件。</li></ul><h3 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h3><ul><li><strong>删除已弃用的后台清理开关</strong>： <code>StateTtlConfig#cleanupInBackground</code> 已经被删除，因为在 1.10 中该方法已被弃用，并且默认启用了后台 TTL。</li><li><p><strong>删除禁用 TTL 压缩过滤器的的选项</strong>：默认情况下，RocksDB 中的 TTL 压缩过滤器在 1.10 中是启用的，在 1.11+ 中总是启用的。因此，在 1.11 中删除了以下选项和方法：</p><ul><li>state.backend.rocksdb.ttl.compaction.filter.enabled</li><li>StateTtlConfig#cleanupInRocksdbCompactFilter()</li><li>RocksDBStateBackend#isTtlCompactionFilterEnabled</li><li>RocksDBStateBackend#enableTtlCompactionFilter</li><li>RocksDBStateBackend#disableTtlCompactionFilter</li><li>(state_backend.py) is_ttl_compaction_filter_enabled</li><li>(state_backend.py) enable_ttl_compaction_filter</li><li>(state_backend.py) disable_ttl_compaction_filter</li></ul></li><li><p><strong>改变</strong> <code>StateBackendFactory#createFromConfig</code> <strong>的参数类型</strong>：从 Flink 1.11 开始， <code>StateBackendFactory</code> 接口中的 <code>createFromConfig</code>方法中的参数变为 ReadableConfig 而不是 Configuration。Configuration 类是 ReadableConfig 接口的实现类，因为它实现了 ReadableConfig 接口，所以自定义 StateBackend 也应该做相应的调整。</p></li><li><strong>删除过期的</strong> <code>OptionsFactory</code> <strong>和</strong> <code>ConfigurableOptionsFactory</code> <strong>类</strong>：过期的 OptionsFactory 和 ConfigurableOptionsFactory 类已被删除。请改用 RocksDBOptionsFactory 和 ConfigurableRocksDBOptionsFactory。如果任何类扩展了DefaultConfigurableOptionsFactory，也请重新编译你的应用程序代码。</li><li><strong>默认情况下启用</strong> setTotalOrderSeek：从 Flink 1.11 开始，默认情况下，RocksDB 的 ReadOptions 将启用 setTotalOrderSeek 选项。这是为了防止用户忘记使用 optimizeForPointLookup。为了向后兼容，我们支持通过 RocksDBOptionsFactory 自定义 ReadOptions。如果观察到性能下降，请将 setTotalOrderSeek 设置为 false（根据我们的测试，这种情况不应该发生）。</li><li><strong>增加</strong> <code>state.backend.fs.memory-threshold</code> <strong>的默认值</strong>： <code>state.backend.fs.memory-threshold</code> 的默认值已从 1K 增加到20K，以防止在远程 FS 上为小状态创建太多小文件。对于那些 source 处配置很多并行度或者有状态的算子的作业可能会因此变更而出现 <code>JM OOM</code> 或 <code>RPC message exceeding maximum frame size</code> 的问题。如果遇到此类问题，请手动将配置设置回 1K。</li></ul><h3 id="PyFlink"><a href="#PyFlink" class="headerlink" title="PyFlink"></a>PyFlink</h3><ul><li><strong>对于不支持的数据类型将抛出异常</strong>：可以使用一些参数（例如，精度）来配置数据类型。但是，在以前的版本中，用户提供的精度没有任何效果，会使用该精度的默认值。为了避免混淆，从 Flink 1.11 开始，如果不支持该数据类型，则将引发异常。 更改包括：<ul><li><code>TimeType</code> 精度只能为 <code>0</code></li><li><code>VarBinaryType</code>/<code>VarCharType</code> 的长度是 <code>0x7fffffff</code></li><li><code>DecimalType</code> 可选值是 <code>38</code>/<code>18</code></li><li><code>TimestampType</code>/<code>LocalZonedTimestampType</code> 的精度只能是 <code>3</code></li><li><code>DayTimeIntervalType</code> 的单位是 <code>SECOND</code> ，<code>fractionalPrecision</code> 精度只能为 <code>3</code></li><li><code>YearMonthIntervalType</code> 的单位是 <code>MONTH</code> ，<code>yearPrecision</code> 精度只能为 <code>2</code></li><li><code>CharType</code>/<code>BinaryType</code>/<code>ZonedTimestampType</code> 不支持</li></ul></li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li><strong>将所有的 MetricReporters 转换为 plugins</strong>：Flink 的所有 MetricReporters 都已经转换为 plugins，它们不再存放在 lib 目录下（这样做可能会导致依赖冲突），而应该放到 <code>/plugins/&lt;some_directory&gt;</code> 目录下。</li><li><strong>改变 DataDog 的 metrics reporter Counter Metrics</strong>：现在 DataDog metrics reporter 程序将 Counter 指标上报为报告时间间隔内的事件数，而不是总数，将 Counter 语义与 DataDog 文档保持一致。</li><li><strong>切换 Log4j2 为默认的</strong>：Flink 现在默认使用 Log4j2，希望恢复到 Log4j1 的用户可以在日志文档中找到操作说明</li><li><strong>更改 JobManager API 的日志请求行为</strong>：从 JobManager 服务端请求一个不可用的 log 或者 stdout 文件现在会返回 404 状态码，在之前的版本中，会返回 <code>file unavailable</code> 。</li><li><strong>移除 lastCheckpointAlignmentBuffered metric</strong>：现在 lastCheckpointAlignmentBuffered metric 已经被移除了，因为在发出 Checkpoint barrier 之后，上游的任务不会发送任何数据，直到下游侧完成对齐为止，WebUI 仍然会显示该值，但现在始终为 0。</li></ul><h3 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h3><ul><li><strong>移除 Kafka 0.8/0.9 Connector</strong></li><li><strong>移除 ElasticSearch 2.x Connector</strong></li><li><strong>移除</strong> KafkaPartitioner</li><li><strong>改进的 fallback 文件系统，以只处理特定的文件系统</strong></li><li><strong>将</strong> <code>FileSystem#getKind</code> <strong>方法设置过期的</strong></li></ul><h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><ul><li><strong>流作业在 Checkpoint 同步部分失败时会立即失败</strong>：无论配置什么参数，Checkpoint 同步部分中的失败（如算子抛出异常）都将立即使其任务（和作业）失败，从 Flink 1.5 版本开始，可以通过设置 <code>setTolerableCheckpointFailureNumber(...)</code> 或 <code>setFailTaskOnCheckpointError(...)</code> 参数来忽略此类的失败，现在这两个参数只影响异步的失败。</li><li><strong>Checkpoint 超时不再被</strong> <code>CheckpointConfig#setTolerableCheckpointFailureNumber</code> <strong>忽略</strong>：现在将 Checkpoint 超时视为正常的 Checkpoint 故障，并根据 <code>CheckpointConfig＃setTolerableCheckpointFailureNumber</code> 配置的值进行检查。</li></ul><h3 id="各种接口变更"><a href="#各种接口变更" class="headerlink" title="各种接口变更"></a>各种接口变更</h3><ul><li><strong>移除过期的</strong> <code>StreamTask#getCheckpointLock()</code> ：在方法在 Flink 1.10 中已经设置过期了，目前不再提供该方法。用户可以使用 MailboxExecutor 来执行需要与任务线程安全的操作。</li><li><strong>flink-streaming-java 模块不再依赖 flink-client 模块</strong>：从 Flink 1.11.0 开始，flink-streaming-java 模块不再依赖 flink-client 模块，如果你项目依赖于 flink-client 模块，需要显示的添加其为依赖项。</li><li><strong>AsyncWaitOperator 是可链接的</strong>：默认情况下，将允许 AsyncWaitOperator 与所有算子链接在一起，但带有 SourceFunction 的任务除外。</li><li><strong>更改了</strong> <code>ShuffleEnvironment</code> <strong>接口的</strong> <code>createInputGates</code> <strong>和</strong> <code>createResultPartitionWriters</code> <strong>方法的参数类型</strong>。</li><li><code>CompositeTypeSerializerSnapshot#isOuterSnapshotCompatible</code> 方法标示过期了。</li><li><strong>移除了过期的 TimestampExtractor</strong>：可以使用 TimestampAssigner 和 WatermarkStrategies。</li><li><strong>将</strong> <code>ListCheckpointed</code> <strong>标示为过期的</strong>：可以使用 CheckpointedFunction 作为代替</li><li><strong>移除了过期的 state 连接方法</strong>：移除了 <code>RuntimeContext#getFoldingState()</code> 、 <code>OperatorStateStore#getSerializableListState()</code> 和 <code>OperatorStateStore#getOperatorState()</code> 连接状态的方法，这意味着在 1.10 运行成功的代码在 1.11 上是运行不了的。</li></ul><p>详情参考 <a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.11.html">https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.11.html</a></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.11 快要发布了，这里提前解读一下 Release 文档&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flink 1.10 TaskManager 内存管理优化</title>
    <link href="http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/"/>
    <id>http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/</id>
    <published>2020-05-15T16:00:00.000Z</published>
    <updated>2020-05-16T03:34:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Flink 1.10 对 TaskManager 的内存模型和 Flink 应用程序的配置选项进行了重大变更。这些最近引入的更改做到了对内存消耗提供了严格的控制，使得 Flink 在各种部署环境（例如 Kubernetes，Yarn，Mesos）更具有适应能力，</p><a id="more"></a><p>在本文中，我们将介绍 Flink 1.10 中的内存模型、如何设置和管理 Flink 应用程序的内存消耗以及社区在最新的 Apache Flink Release 版本中的变化。</p><h3 id="Flink-内存模型的介绍"><a href="#Flink-内存模型的介绍" class="headerlink" title="Flink 内存模型的介绍"></a>Flink 内存模型的介绍</h3><p>对 Apache Flink 的内存模型有清晰的了解，可以使您更有效地管理各种情况下的资源使用情况。 下图描述了 Flink 中的主要内存组件：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-05-16-032601.png" alt="Flink: Total Process Memory"></p><p>TaskManager 进程是一个 JVM 进程，从较高的角度来看，它的内存由 JVM Heap 和 Off-Heap 组成。这些类型的内存由 Flink 直接使用，或由 JVM 用于其特定目的（比如元空间 metaspace）。</p><p>Flink 中有两个主要的内存使用者：</p><ul><li>用户代码中的作业 task 算子</li><li>Flink 框架本身的内部数据结构、网络缓冲区 (Network Buffers)等</li></ul><p>请注意，用户代码可以直接访问所有的内存类型：JVM 堆、Direct 和 Native 内存。因此，Flink 不能真正控制其分配和使用。但是，有两种供作业 Task 使用并由 Flink 严格控制的 Off-Heap 内存，它们分别是：</p><ul><li>Managed Memory (Off-Heap)</li><li>网络缓冲区 (Network Buffers)</li></ul><p>网络缓冲区 (Network Buffers) 是 JVM Direct 内存的一部分，分配在算子和算子之间用于进行用户数据的交换。</p><h3 id="怎么去配置-Flink-的内存"><a href="#怎么去配置-Flink-的内存" class="headerlink" title="怎么去配置 Flink 的内存"></a>怎么去配置 Flink 的内存</h3><p>在最新 Flink 1.10 版本中，为了提供更好的用户体验，框架提供了内存组件的高级和细粒度调优。在 TaskManager 中设置内存基本上有三种选择。</p><p>前两个（也是最简单的）选择是需要你配置以下两个选项之一，以供 TaskManager 的 JVM 进程使用的总内存：</p><ul><li>Total Process Memory：Flink Java 应用程序（包括用户代码）和 JVM 运行整个进程所消耗的总内存。</li><li>Total Flink Memory：仅 Flink Java 应用程序消耗的内存，包括用户代码，但不包括 JVM 为其运行而分配的内存。</li></ul><p>如果是以 standalone 模式部署，则建议配置 Total Flink Memory，在这种情况下，显式声明为 Flink 分配多少内存是一种常见的做法，而外部 JVM 开销却很少。</p><p>对于在容器化环境（例如 Kubernetes，Yarn 或 Mesos）中部署 Flink 的情况，建议配置 Total Process Memory，因为它表示所请求容器的总内存大小，容器化环境通常严格执行此内存限制。</p><p>其余的内存组件将根据其默认值或其他已配置的参数自动进行调整。Flink 还会检查整体一致性。你可以在相应的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/memory/mem_detail.html">文档</a>中找到有关不同内存组件的更多信息。 此外，你可以使用 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-49%3A+Unified+Memory+Configuration+for+TaskExecutors">FLIP-49</a> 的配置电子表格尝试不同的配置选项，并根据你的情况检查相应的结果。</p><p>如果要从 1.10 之前的 Flink 版本进行迁移，我们建议你遵循 Flink 文档的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/memory/mem_migration.html">迁移指南</a>中的步骤。</p><h3 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h3><p>在配置 Flink 的内存时，可以使用相应选项的值固定不同内存组件的大小，也可以使用多个选项进行调整。下面我们提供有关内存设置的更多信息。</p><h4 id="按比例细分-Total-Flink-Memory"><a href="#按比例细分-Total-Flink-Memory" class="headerlink" title="按比例细分 Total Flink Memory"></a>按比例细分 Total Flink Memory</h4><p>此方法允许按比例细分 Total Flink Memory，其中 Managed Memory（如果未明确设置）和网络缓冲区可以占用一部分。然后，将剩余的内存分配给 Task Heap（如果未明确设置）和其他固定的 JVM Heap 和 Off-Heap 组件。下图是这种设置的示例：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-05-16-032632.png" alt=""></p><p><strong>请注意</strong>：</p><p>Flink 会校验分配的 Network Memory 大小在其最小值和最大值之间，否则 Flink 的启动会失败，最大值和最小值的限制具有默认值，这些默认值是可以被相应的配置选项覆盖。</p><p>通常，Flink 将配置的占比分数视为提示。在某些情况下，真正分配的值可能与占比分数不匹配。例如，如果将 Total Flink Memory 和 Task Heap 配置为固定值，则 Managed Memory 将获得一定比例的内存，而 Network Memory 将获得可能与该比例不完全匹配的剩余内存。</p><h4 id="控制容器内存限制的更多提示"><a href="#控制容器内存限制的更多提示" class="headerlink" title="控制容器内存限制的更多提示"></a>控制容器内存限制的更多提示</h4><p>堆内存和 direct 内存的使用是由 JVM 管理的。在 Apache Flink 或其用户应用程序中，还有许多其他 native 内存消耗的可能来源，它们不是由 Flink 或 JVM 管理的。通常很难控制它们的限制大小，这会使调试潜在的内存泄漏变得复杂。</p><p>如果 Flink 的进程以不受管理的方式分配了过多的内存，则在容器化环境中通常可能导致 TaskManager 容器会被杀死。在这种情况下，可能很难理解哪种类型的内存消耗已超过其限制。 Flink 1.10 引入了一些特定的调整选项，以清楚地表示这些组件。 尽管 Flink 不能始终严格执行严格的限制和界限，但此处的想法是明确计划内存使用情况。 下面我们提供一些示例，说明内存设置如何防止容器超出其内存限制：</p><ul><li><p><strong>RocksDB 状态不能太大</strong>：RocksDB 状态后端的内存消耗是在 Managed Memory 中解决的。 RocksDB 默认情况下遵守其限制（仅自 Flink 1.10 起）。你可以增加 Managed Memory 的大小以提高 RocksDB 的性能，也可以减小 Managed Memory 的大小以节省资源。</p></li><li><p><strong>用户代码或其依赖项会消耗大量的 off-heap 内存</strong>：调整 Task Off-Heap 选项可以为用户代码或其任何依赖项分配额外的 direct 或 native 内存。Flink 无法控制 native 分配，但它设置了 JVM Direct 内存分配的限制。Direct 内存限制由 JVM 强制执行。</p></li><li><p><strong>JVM metaspace 需要额外的内存</strong>：如果遇到 <code>OutOfMemoryError：Metaspace</code>，Flink 提供了一个增加其限制的选项，并且 JVM 将确保不超过该限制。</p></li><li><p><strong>JVM 需要更多内部内存</strong>：无法直接控制某些类型的 JVM 进程分配，但是 Flink 提供了 JVM 开销选项。这些选项允许声明额外的内存量，这些内存是为这些分配所预期的，并且未被其他选项覆盖。</p></li></ul><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>最新的 Flink 版本（Flink 1.10）对 Flink 的内存配置进行了一些重大更改，从而可以比以前更好地管理应用程序内存和调试 Flink。未来 JobManager 的内存模型也会采取类似的更改，可以参考 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP+116%3A+Unified+Memory+Configuration+for+Job+Managers">FLIP-116</a>，因此请继续关注即将发布的新版本中新增的功能。如果你对社区有任何建议或问题，我们建议你注册 Apache Flink 邮件列表并参与其中的讨论。</p><blockquote><p>博客英文地址：<a href="https://flink.apache.org/news/2020/04/21/memory-management-improvements-flink-1.10.html">https://flink.apache.org/news/2020/04/21/memory-management-improvements-flink-1.10.html</a><br>作者: Andrey Zagrebin<br>本文翻译作者：zhisheng<br>翻译后首发地址：<a href="http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/">http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flink 1.10 对 TaskManager 的内存模型和 Flink 应用程序的配置选项进行了重大变更。这些最近引入的更改做到了对内存消耗提供了严格的控制，使得 Flink 在各种部署环境（例如 Kubernetes，Yarn，Mesos）更具有适应能力，&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Forward 2020 PPT 下载</title>
    <link href="http://www.54tianzhisheng.cn/2020/05/13/flink-forward-2020/"/>
    <id>http://www.54tianzhisheng.cn/2020/05/13/flink-forward-2020/</id>
    <published>2020-05-12T16:00:00.000Z</published>
    <updated>2020-05-13T15:04:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink Forward 2020 是在线上举办的一次会议</p><a id="more"></a><p>1、《Keynote:Introducing Stateful Functions 2.0: Stream Processing meets Serverless Applications》<br>Stephan Ewen – Apache Flink PMC,Ververica Co-founder, CTO</p><p>讲解嘉宾：李钰（绝顶） – Apache Flink Committer，Apache Flink 1.10 Release Manager，阿里巴巴高级技术专家</p><p>2、《Keynote:Stream analytics made real with Pravega and Apache Flink》<br>  Srikanth Satya – VP of Engineering at DellEMC</p><p>讲解嘉宾：滕昱 – DellEMC 技术总监</p><p>3、《Keynote:Apache Flink – Completing Cloudera’s End to End Streaming Platform》<br>  Marton Balassi – Apache Flink PMC ，Senior Solutions Architect at Cloudera</p><p>Joe Witt – VP of Engineering at Cloudera</p><p>讲解嘉宾：杨克特（鲁尼） – Apache Member, Apache Flink PMC, 阿里巴巴高级技术专家</p><p>4、《Keynote:The Evolution of Data Infrastructure at Splunk》<br>Eric Sammer – Distinguished Engineer at Splunk</p><p>讲解嘉宾：王治江（淘江） – 阿里巴巴高级技术专家</p><p>5、《Flink SQL 之 2020：舍我其谁》<br>Fabian Hueske, &amp; Timo Walther</p><p>讲解嘉宾：伍翀（云邪），Apache Flink PMC，阿里巴巴技术专家</p><p>6、《微博基于 Flink 的机器学习实践》</p><p>分享嘉宾：</p><p>于茜，微博机器学习研发中心高级算法工程师。多年来致力于使用 Flink 构建实时数据处理和在线机器学习框架，有丰富的社交媒体应用推荐系统的开发经验。</p><p>曹富强，微博机器学习研发中心系统工程师。现负责微博机器学习平台数据计算模块。主要涉及实时计算 Flink，Storm，Spark Streaming，离线计算 Hive，Spark 等。目前专注于 Flink 在微博机器学习场景的应用。</p><p>于翔，微博机器学习研发中心算法架构工程师。</p><p>7、《Flink’s application at Didi》</p><p>分享嘉宾：薛康 – 现任滴滴技术专家，实时计算负责人</p><p>8、《Alink：提升基于 Flink 的机器学习平台易用性》</p><p>分享嘉宾：杨旭（品数） – 阿里巴巴资深技术专家。</p><p>9、《Google: 机器学习工作流的分布式处理》<br>Ahmet Altay &amp; Reza Rokni &amp; Robert Crowe</p><p>讲解嘉宾：秦江杰 – Apache Flink PMC，阿里巴巴高级技术专家</p><p>10、《Flink + AI Flow：让 AI 易如反掌》</p><p>分享嘉宾：秦江杰 – Apache Flink PMC，阿里巴巴高级技术专家</p><p>11、《终于等到你：PyFlink + Zeppelin》</p><p>分享嘉宾：</p><p>孙金城（金竹） – Apache Member，Apache Flink PMC，阿里巴巴高级技术专家</p><p>章剑锋（简锋） – Apache Member，Apache Zeppelin PMC，阿里巴巴高级技术专家</p><p>12、《Uber ：使用 Flink CEP 进行地理情形检测的实践》<br>Teng (Niel) Hu</p><p>讲解嘉宾：付典 – Apache Flink Committer，阿里巴巴技术专家</p><p>13、《AWS: 如何在全托管 Apache Flink 服务中提供应用高可用》</p><p>Ryan Nienhuis &amp; Tirtha Chatterjee</p><p>讲解嘉宾：章剑锋（简锋） – Apache Member，Apache Zeppelin PMC，阿里巴巴高级技术专家</p><p>14、《Production-Ready Flink and Hive Integration – what story you can tell now?》</p><p>Bowen Li</p><p>讲解嘉宾：李锐（天离） – Apache Hive PMC，阿里巴巴技术专家</p><p>15、《Data Warehouse, Data Lakes, What’s Next?》<br>Xiaowei Jiang</p><p>讲解嘉宾：金晓军（仙隐） – 阿里巴巴高级技术专家</p><p>16、《Netflix 的 Flink 自动扩缩容》</p><p>Abhay Amin</p><p>讲解嘉宾：吕文龙（龙三），阿里巴巴技术专家</p><p>17、《Apache Flink 误用之痛》</p><p>Konstantin Knauf</p><p>讲解嘉宾：孙金城（金竹） – Apache Member，Apache Flink PMC，阿里巴巴高级技术专家</p><p>18、《A deep dive into Flink SQL》</p><p>分享嘉宾：伍翀（云邪），Apache Flink PMC，阿里巴巴技术专家</p><p>19、《Lyft: 基于Flink的准实时海量数据分析平台》</p><p>Ying Xu &amp; Kailash Hassan Dayanand</p><p>讲解嘉宾：王阳（亦祺），阿里巴巴技术专家</p><h3 id="如何获取上面这些-PPT？"><a href="#如何获取上面这些-PPT？" class="headerlink" title="如何获取上面这些 PPT？"></a>如何获取上面这些 PPT？</h3><p>上面的这些 PPT 本人已经整理好了，你可以扫描下面二维码，关注微信公众号：zhisheng，然后在里面回复关键字: <strong>ff2020</strong> 即可获取已放出的 PPT。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-28-144329.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink Forward 2020 是在线上举办的一次会议&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>如何实时监控 Flink 集群和作业？</title>
    <link href="http://www.54tianzhisheng.cn/2020/05/07/flink-job-monitor/"/>
    <id>http://www.54tianzhisheng.cn/2020/05/07/flink-job-monitor/</id>
    <published>2020-05-06T16:00:00.000Z</published>
    <updated>2020-05-07T13:03:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 相关的组件和作业的稳定性通常是比较关键的，所以得需要对它们进行监控，如果有异常，则需要及时告警通知。本章先会教会教会大家如何利用现有 Flink UI 上面的信息去发现和排查问题，会指明一些比较重要和我们非常关心的指标，通过这些指标我们能够立马定位到问题的根本原因。接着笔者会教大家如何去利用现有的 Metrics Reporter 去构建一个 Flink 的监控系统，它可以收集到所有作业的监控指标，并会存储这些监控指标数据，最后还会有一个监控大盘做数据可视化，通过这个大盘可以方便排查问题。</p><a id="more"></a><h2 id="实时监控-Flink-及其作业"><a href="#实时监控-Flink-及其作业" class="headerlink" title="实时监控 Flink 及其作业"></a>实时监控 Flink 及其作业</h2><p>当将 Flink JobManager、TaskManager 都运行起来了，并且也部署了不少 Flink Job，那么它到底是否还在运行、运行的状态如何、资源 TaskManager 和 Slot 的个数是否足够、Job 内部是否出现异常、计算速度是否跟得上数据生产的速度 等这些问题其实对我们来说是比较关注的，所以就很迫切的需要一个监控系统帮我们把整个 Flink 集群的运行状态给展示出来。通过监控系统我们能够很好的知道 Flink 内部的整个运行状态，然后才能够根据项目生产环境遇到的问题 ‘对症下药’。下面分别来讲下 JobManager、TaskManager、Flink Job 的监控以及最关心的一些监控指标。</p><h3 id="监控-JobManager"><a href="#监控-JobManager" class="headerlink" title="监控 JobManager"></a>监控 JobManager</h3><p>我们知道 JobManager 是 Flink 集群的中控节点，类似于 Apache Storm 的 Nimbus 以及 Apache Spark 的 Driver 的角色。它负责作业的调度、作业 Jar 包的管理、Checkpoint 的协调和发起、与 TaskManager 之间的心跳检查等工作。如果 JobManager 出现问题的话，就会导致作业 UI 信息查看不了，TaskManager 和所有运行的作业都会受到一定的影响，所以这也是为啥在 7.1 节中强调 JobManager 的高可用问题。 </p><p>在 Flink 自带的 UI 上 JobManager 那个 Tab 展示的其实并没有显示其对应的 Metrics，那么对于 JobManager 来说常见比较关心的监控指标有哪些呢？</p><h4 id="基础指标"><a href="#基础指标" class="headerlink" title="基础指标"></a>基础指标</h4><p>因为 Flink JobManager 其实也是一个 Java 的应用程序，那么它自然也会有 Java 应用程序的指标，比如内存、CPU、GC、类加载、线程信息等。</p><ul><li>内存：内存又分堆内存和非堆内存，在 Flink 中还有 Direct 内存，每种内存又有初始值、使用值、最大值等指标，因为在 JobManager 中的工作其实相当于 TaskManager 来说比较少，也不存储事件数据，所以通常 JobManager 占用的内存不会很多，在 Flink JobManager 中自带的内存 Metrics 指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_Memory_Direct_Count</span><br><span class="line">jobmanager_Status_JVM_Memory_Direct_MemoryUsed</span><br><span class="line">jobmanager_Status_JVM_Memory_Direct_TotalCapacity</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Committed</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Max</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Used</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_Count</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_MemoryUsed</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_TotalCapacity</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Committed</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Max</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Used</span><br></pre></td></tr></table></figure><ul><li>CPU：JobManager 分配的 CPU 使用情况，如果使用类似 K8S 等资源调度系统，则需要对每个容器进行设置资源，比如 CPU 限制不能超过多少，在 Flink JobManager 中自带的 CPU 指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_CPU_Load</span><br><span class="line">jobmanager_Status_JVM_CPU_Time</span><br></pre></td></tr></table></figure><ul><li>GC：GC 信息对于 Java 应用来说是避免不了的，每种 GC 都有时间和次数的指标可以供参考，提供的指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_MarkSweep_Count</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_MarkSweep_Time</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_Scavenge_Count</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_Scavenge_Time</span><br></pre></td></tr></table></figure><h4 id="Checkpoint-指标"><a href="#Checkpoint-指标" class="headerlink" title="Checkpoint 指标"></a>Checkpoint 指标</h4><p>因为 JobManager 负责了作业的 Checkpoint 的协调和发起功能，所以 Checkpoint 相关的指标就有表示 Checkpoint 执行的时间、Checkpoint 的时间长短、完成的 Checkpoint 的次数、Checkpoint 失败的次数、Checkpoint 正在执行 Checkpoint 的个数等，其对应的指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_job_lastCheckpointAlignmentBuffered</span><br><span class="line">jobmanager_job_lastCheckpointDuration</span><br><span class="line">jobmanager_job_lastCheckpointExternalPath</span><br><span class="line">jobmanager_job_lastCheckpointRestoreTimestamp</span><br><span class="line">jobmanager_job_lastCheckpointSize</span><br><span class="line">jobmanager_job_numberOfCompletedCheckpoints</span><br><span class="line">jobmanager_job_numberOfFailedCheckpoints</span><br><span class="line">jobmanager_job_numberOfInProgressCheckpoints</span><br><span class="line">jobmanager_job_totalNumberOfCheckpoints</span><br></pre></td></tr></table></figure><h4 id="重要的指标"><a href="#重要的指标" class="headerlink" title="重要的指标"></a>重要的指标</h4><p>另外还有比较重要的指标就是 Flink UI 上也提供的，类似于 Slot 总共个数、Slot 可使用的个数、TaskManager 的个数（通过查看该值可以知道是否有 TaskManager 发生异常重启）、正在运行的作业数量、作业运行的时间和完成的时间、作业的重启次数，对应的指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_job_uptime</span><br><span class="line">jobmanager_numRegisteredTaskManagers</span><br><span class="line">jobmanager_numRunningJobs</span><br><span class="line">jobmanager_taskSlotsAvailable</span><br><span class="line">jobmanager_taskSlotsTotal</span><br><span class="line">jobmanager_job_downtime</span><br><span class="line">jobmanager_job_fullRestarts</span><br><span class="line">jobmanager_job_restartingTime</span><br></pre></td></tr></table></figure><h3 id="监控-TaskManager"><a href="#监控-TaskManager" class="headerlink" title="监控 TaskManager"></a>监控 TaskManager</h3><p>TaskManager 在 Flink 集群中也是一个个的进程实例，它的数量代表着能够运行作业个数的能力，所有的 Flink 作业最终其实是会在 TaskManager 上运行的，TaskManager 管理着运行在它上面的所有作业的 Task 的整个生命周期，包括了 Task 的启动销毁、内存管理、磁盘 IO、网络传输管理等。</p><p>因为所有的 Task 都是运行运行在 TaskManager 上的，有的 Task 可能会做比较复杂的操作或者会存储很多数据在内存中，那么就会消耗很大的资源，所以通常来说 TaskManager 要比 JobManager 消耗的资源要多，但是这个资源具体多少其实也不好预估，所以可能会出现由于分配资源的不合理，导致 TaskManager 出现 OOM 等问题。一旦 TaskManager 因为各种问题导致崩溃重启的话，运行在它上面的 Task 也都会失败，JobManager 与它的通信也会丢失。因为作业出现 failover，所以在重启这段时间它是不会去消费数据的，所以必然就会出现数据消费延迟的问题。对于这种情况那么必然就很需要 TaskManager 的监控信息，这样才能够对整个集群的 TaskManager 做一个提前预警。</p><p>那么在 Flink 中自带的 TaskManager Metrics 有哪些呢？主要也是 CPU、类加载、GC、内存、网络等。其实这些信息在 Flink UI 上也是有，如下图所示，不知道读者有没有细心观察过。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-030513.png" alt=""></p><p>在这个 TaskManager 的 Metrics 监控页面通常比较关心的指标有内存相关的，还有就是 GC 的指标，通常一个 TaskManager 出现 OOM 之前会不断的进行 GC，在这个 Metrics 页面它展示了年轻代和老年代的 GC 信息（时间和次数），如下图所示，大家可以细心观察下是否 TaskManager OOM 前老年代和新生代的 GC 次数比较、时间比较长。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-030954.png" alt=""></p><p>在 Flink Reporter 中提供的 TaskManager Metrics 指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">taskmanager_Status_JVM_CPU_Load</span><br><span class="line">taskmanager_Status_JVM_CPU_Time</span><br><span class="line">taskmanager_Status_JVM_ClassLoader_ClassesLoaded</span><br><span class="line">taskmanager_Status_JVM_ClassLoader_ClassesUnloaded</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Old_Generation_Count</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Old_Generation_Time</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Young_Generation_Count</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Young_Generation_Time</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_Count</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_MemoryUsed</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_TotalCapacity</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Committed</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Max</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Used</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_Count</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_MemoryUsed</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_TotalCapacity</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Committed</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Max</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Used</span><br><span class="line">taskmanager_Status_JVM_Threads_Count</span><br><span class="line">taskmanager_Status_Network_AvailableMemorySegments</span><br><span class="line">taskmanager_Status_Network_TotalMemorySegments</span><br><span class="line">taskmanager_Status_Shuffle_Netty_AvailableMemorySegments</span><br><span class="line">taskmanager_Status_Shuffle_Netty_TotalMemorySegments</span><br></pre></td></tr></table></figure><h3 id="监控-Flink-作业"><a href="#监控-Flink-作业" class="headerlink" title="监控 Flink 作业"></a>监控 Flink 作业</h3><p>对于运行的作业来说，其实我们会更关心其运行状态，如果没有其对应的一些监控信息，那么对于我们来说这个 Job 就是一个黑盒，完全不知道是否在运行，Job 运行状态是什么、Task 运行状态是什么、是否在消费数据、消费数据是咋样（细分到每个 Task）、消费速度能否跟上生产数据的速度、处理数据的过程中是否有遇到什么错误日志、处理数据是否有出现反压问题等等。</p><p>上面列举的这些问题通常来说是比较关心的，那么在 Flink UI 上也是有提供的查看对应的信息的，点开对应的作业就可以查看到作业的执行图，每个 Task 的信息都是会展示出来的，包含了状态、Bytes Received（接收到记录的容量大小）、Records Received（接收到记录的条数）、Bytes Sent（发出去的记录的容量大小）、Records Sent（发出去记录的条数）、异常信息、timeline（作业运行状态的时间线）、Checkpoint 信息，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-042958.png" alt=""></p><p>这些指标也可以通过 Flink 的 Reporter 进行上报存储到第三方的时序数据库，然后通过类似 Grafana 展示出来，如下图所示。通过这些信息大概就可以清楚的知道一个 Job 的整个运行状态，然后根据这些运行状态去分析作业是否有问题。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-070124.png" alt=""></p><p>在流作业中最关键的指标无非是作业的实时性，那么延迟就是衡量作业的是否实时的一个基本参数，但是对于现有的这些信息其实还不知道作业的消费是否有延迟，通常来说可以结合 Kafka 的监控去查看对应消费的 Topic 的 Group 的 Lag 信息，如果 Lag 很大就表明有数据堆积了，另外还有一个办法就是需要自己在作业中自定义 Metrics 做埋点，将算子在处理数据的系统时间与数据自身的 Event Time 做一个差值，求得值就可以知道算子消费的数据是什么时候的了。比如在 1571457964000（2019-10-19 12:06:04）Map 算子消费的数据的事件时间是 1571457604000（2019-10-19 12:00:04），相差了 6 分钟，那么就表明消费延迟了 6 分钟，然后通过 Metrics Reporter 将埋点的 Metrics 信息上传，这样最终就可以获取到作业在每个算子处的消费延迟的时间。</p><p>上面的是针对于作业延迟的判断方法，另外像类似于作业反压的情况，在 Flink 的 UI 也会有展示，具体怎么去分析和处理这种问题在 9.1 节中有详细讲解。</p><p>根据这些监控信息不仅可以做到提前预警，做好资源的扩容（比如增加容器的数量／内存／CPU／并行度／Slot 个数），也还可以找出作业配置的资源是否有浪费。通常来说一个作业的上线可能是会经过资源的预估，然后才会去申请这个作业要配置多少资源，比如算子要使用多少并行度，最后上线后可以通过完整的运行监控信息查看该作业配置的并行度是否有过多或者配置的内存比较大。比如出现下面这些情况的时候可能就是资源出现浪费了：</p><ul><li>作业消费从未发生过延迟，即使在数据流量高峰的时候，也未发生过消费延迟</li><li>作业运行所在的 TaskManager 堆内存使用率异常的低</li><li>作业运行所在的 TaskManager 的 GC 时间和次数非常规律，没有出现异常的现象，如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-064123.png" alt=""></p><p>在 Flink Metrics Reporter 上传的指标中大概有下面这些：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">taskmanager_job_task_Shuffle_Netty_Input_Buffers_outPoolUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Input_Buffers_outputQueueLength</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inPoolUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputExclusiveBuffersUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputFloatingBuffersUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputQueueLength</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInLocal</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInLocalPerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInRemote</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInRemotePerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInLocal</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInLocalPerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInRemote</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInRemotePerSecond</span><br><span class="line">taskmanager_job_task_buffers_inPoolUsage</span><br><span class="line">taskmanager_job_task_buffers_inputExclusiveBuffersUsage</span><br><span class="line">taskmanager_job_task_buffers_inputFloatingBuffersUsage</span><br><span class="line">taskmanager_job_task_buffers_inputQueueLength</span><br><span class="line">taskmanager_job_task_buffers_outPoolUsage</span><br><span class="line">taskmanager_job_task_buffers_outputQueueLength</span><br><span class="line">taskmanager_job_task_checkpointAlignmentTime</span><br><span class="line">taskmanager_job_task_currentInputWatermark</span><br><span class="line">taskmanager_job_task_numBuffersInLocal</span><br><span class="line">taskmanager_job_task_numBuffersInLocalPerSecond</span><br><span class="line">taskmanager_job_task_numBuffersInRemote</span><br><span class="line">taskmanager_job_task_numBuffersInRemotePerSecond</span><br><span class="line">taskmanager_job_task_numBuffersOut</span><br><span class="line">taskmanager_job_task_numBuffersOutPerSecond</span><br><span class="line">taskmanager_job_task_numBytesIn</span><br><span class="line">taskmanager_job_task_numBytesInLocal</span><br><span class="line">taskmanager_job_task_numBytesInLocalPerSecond</span><br><span class="line">taskmanager_job_task_numBytesInPerSecond</span><br><span class="line">taskmanager_job_task_numBytesInRemote</span><br><span class="line">taskmanager_job_task_numBytesInRemotePerSecond</span><br><span class="line">taskmanager_job_task_numBytesOut</span><br><span class="line">taskmanager_job_task_numBytesOutPerSecond</span><br><span class="line">taskmanager_job_task_numRecordsIn</span><br><span class="line">taskmanager_job_task_numRecordsInPerSecond</span><br><span class="line">taskmanager_job_task_numRecordsOut</span><br><span class="line">taskmanager_job_task_numRecordsOutPerSecond</span><br><span class="line">taskmanager_job_task_operator_currentInputWatermark</span><br><span class="line">taskmanager_job_task_operator_currentOutputWatermark</span><br><span class="line">taskmanager_job_task_operator_numLateRecordsDropped</span><br><span class="line">taskmanager_job_task_operator_numRecordsIn</span><br><span class="line">taskmanager_job_task_operator_numRecordsInPerSecond</span><br><span class="line">taskmanager_job_task_operator_numRecordsOut</span><br><span class="line">taskmanager_job_task_operator_numRecordsOutPerSecond</span><br></pre></td></tr></table></figure><h3 id="最关心的性能指标"><a href="#最关心的性能指标" class="headerlink" title="最关心的性能指标"></a>最关心的性能指标</h3><p>上面已经提及到 Flink 的 JobManager、TaskManager 和运行的 Flink Job 的监控以及常用的监控信息，这些指标有的是可以直接在 Flink 的 UI 上观察到的，另外 Flink 提供了 Metrics Reporter 进行上报存储到监控系统中去，然后通过可视化的图表进行展示，在 8.2 节中将教大家如何构建一个完整的监控系统。那么有了这么多监控指标，其实哪些是比较重要的呢，比如说这些指标出现异常的时候可以发出告警及时进行通知，这样可以做到预警作用，另外还可以根据这些信息进行作业资源的评估。下面列举一些笔者觉得比较重要的指标：</p><h4 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h4><p>在 JobManager 中有着该集群中所有的 TaskManager 的个数、Slot 的总个数、Slot 的可用个数、运行的时间、作业的 Checkpoint 情况，笔者觉得这几个指标可以重点关注。</p><ul><li>TaskManager 个数：如果出现 TaskManager 突然减少，可能是因为有 TaskManager 挂掉重启，一旦该 TaskManager 之前运行了很多作业，那么重启带来的影响必然是巨大的。</li><li>Slot 个数：取决于 TaskManager 的个数，决定了能运行作业的最大并行度，如果资源不够，及时扩容。</li><li>作业运行时间：根据作业的运行时间来判断作业是否存活，中途是否掉线过。</li><li>Checkpoint 情况：Checkpoint 是 JobManager 发起的，并且关乎到作业的状态是否可以完整的保存。</li></ul><h4 id="TaskManager"><a href="#TaskManager" class="headerlink" title="TaskManager"></a>TaskManager</h4><p>因为所有的作业最终都是运行在 TaskManager 上，所以 TaskManager 的监控指标也是异常的监控，并且作业的复杂度也会影响 TaskManager 的资源使用情况，所以 TaskManager 的基础监控指标比如内存、GC 如果出现异常或者超出设置的阈值则需要立马进行告警通知，防止后面导致大批量的作业出现故障重启。</p><ul><li>内存使用率：部分作业的算子会将所有的 State 数据存储在内存中，这样就会导致 TaskManager 的内存使用率会上升，还有就是可以根据该指标看作业的利用率，从而最后来重新划分资源的配置。</li><li>GC 情况：分时间和次数，一旦 TaskManager 的内存率很高的时候，必定伴随着频繁的 GC，如果在 GC 的时候没有得到及时的预警，那么将面临 OOM 风险。</li></ul><h4 id="Flink-Job"><a href="#Flink-Job" class="headerlink" title="Flink Job"></a>Flink Job</h4><p>作业的稳定性和及时性其实就是大家最关心的，常见的指标有：作业的状态、Task 的状态、作业算子的消费速度、作业出现的异常日志。</p><ul><li>作业的状态：在 UI 上是可以看到作业的状态信息，常见的状态变更信息如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-080858.png" alt=""></p><ul><li>Task 的状态：其实导致作业的状态发生变化的原因通常是由于 Task 的运行状态出现导致，所以也需要对 Task 的运行状态进行监控，Task 的运行状态如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-081049.png" alt=""></p><ul><li><p>作业异常日志：导致 Task 出现状态异常的根因通常是作业中的代码出现各种各样的异常日志，最后可能还会导致作业无限重启，所以作业的异常日志也是需要及时关注。</p></li><li><p>作业重启次数：当 Task 状态和作业的状态发生变化的时候，如果作业中配置了重启策略或者开启了 Checkpoint 则会进行作业重启的，重启作业的带来的影响也会很多，并且会伴随着一些不确定的因素，最终导致作业一直重启，这样既不能解决问题，还一直在占用着资源的消耗。</p></li><li><p>算子的消费速度：代表了作业的消费能力，还可以知道作业是否发生延迟，可以包含算子接收的数据量和发出去数据量，从而可以知道在算子处是否有发生数据的丢失。</p></li></ul><h3 id="小结与反思"><a href="#小结与反思" class="headerlink" title="小结与反思"></a>小结与反思</h3><p>本节讲了 Flink 中常见的监控对象，比如 JobManager、TaskManager 和 Flink Job，对于这几个分别介绍了其内部大概有的监控指标，以及在真实生产环境关心的指标，你是否还有其他的监控指标需要补充呢？ </p><p>本节涉及的监控指标对应的含义可以参考官网链接：<a href="https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/metrics.html#system-metrics">metrics</a></p><p>本节涉及的监控指标列表地址：<a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-monitor/flink_monitor_measurements.md">flink_monitor_measurements</a></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 相关的组件和作业的稳定性通常是比较关键的，所以得需要对它们进行监控，如果有异常，则需要及时告警通知。本章先会教会教会大家如何利用现有 Flink UI 上面的信息去发现和排查问题，会指明一些比较重要和我们非常关心的指标，通过这些指标我们能够立马定位到问题的根本原因。接着笔者会教大家如何去利用现有的 Metrics Reporter 去构建一个 Flink 的监控系统，它可以收集到所有作业的监控指标，并会存储这些监控指标数据，最后还会有一个监控大盘做数据可视化，通过这个大盘可以方便排查问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Apache Flink 的实时 Error 日志告警</title>
    <link href="http://www.54tianzhisheng.cn/2020/04/15/flink-error-log-alert/"/>
    <id>http://www.54tianzhisheng.cn/2020/04/15/flink-error-log-alert/</id>
    <published>2020-04-14T16:00:00.000Z</published>
    <updated>2020-05-07T13:03:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。</p><a id="more"></a><h3 id="日志处理方案的演进"><a href="#日志处理方案的演进" class="headerlink" title="日志处理方案的演进"></a>日志处理方案的演进</h3><p>日志处理的方案也是有一个演进的过程，要想弄清楚整个过程，我们先来看下日志的介绍。</p><h4 id="什么是日志？"><a href="#什么是日志？" class="headerlink" title="什么是日志？"></a>什么是日志？</h4><p>日志是带时间戳的基于时间序列的数据，它可以反映系统的运行状态，包括了一些标识信息（应用所在服务器集群名、集群机器 IP、机器设备系统信息、应用名、应用 ID、应用所属项目等）</p><h4 id="日志处理方案演进"><a href="#日志处理方案演进" class="headerlink" title="日志处理方案演进"></a>日志处理方案演进</h4><p>日志处理方案的演进过程：</p><ul><li>日志处理 v1.0: 应用日志分布在很多机器上，需要人肉手动去机器查看日志信息。</li><li>日志处理 v2.0: 利用离线计算引擎统一的将日志收集，形成一个日志搜索分析平台，提供搜索让用户根据关键字进行搜索和分析，缺点就是及时性比较差。</li><li>日志处理 v3.0: 利用 Agent 实时的采集部署在每台机器上的日志，然后统一发到日志收集平台做汇总，并提供实时日志分析和搜索的功能，这样从日志产生到搜索分析出结果只有简短的延迟（在用户容忍时间范围之内），优点是快，但是日志数据量大的情况下带来的挑战也大。</li></ul><h3 id="日志采集工具对比"><a href="#日志采集工具对比" class="headerlink" title="日志采集工具对比"></a>日志采集工具对比</h3><p>上面提到的日志采集，其实现在已经有很多开源的组件支持去采集日志，比如 Logstash、Filebeat、Fluentd、Logagent 等，这里简单做个对比。</p><h4 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h4><p>Logstash 是一个开源数据收集引擎，具有实时管道功能。Logstash 可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。如下图所示，Logstash 将采集到的数据用作分析、监控、告警等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-025214.jpg" alt=""></p><p><strong>优势</strong>：Logstash 主要的优点就是它的灵活性，它提供很多插件，详细的文档以及直白的配置格式让它可以在多种场景下应用。而且现在 ELK 整个技术栈在很多公司应用的比较多，所以基本上可以在往上找到很多相关的学习资源。</p><p><strong>劣势</strong>：Logstash 致命的问题是它的性能以及资源消耗(默认的堆大小是 1GB)。尽管它的性能在近几年已经有很大提升，与它的替代者们相比还是要慢很多的，它在大数据量的情况下会是个问题。另一个问题是它目前不支持缓存，目前的典型替代方案是将 Redis 或 Kafka 作为中心缓冲池：</p><h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h4><p>作为 Beats 家族的一员，Filebeat 是一个轻量级的日志传输工具，它的存在正弥补了 Logstash 的缺点，Filebeat 作为一个轻量级的日志传输工具可以将日志推送到 Kafka、Logstash、ElasticSearch、Redis。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-030138.jpg" alt=""></p><p><strong>优势</strong>：Filebeat 只是一个二进制文件没有任何依赖。它占用资源极少，尽管它还十分年轻，正式因为它简单，所以几乎没有什么可以出错的地方，所以它的可靠性还是很高的。它也为我们提供了很多可以调节的点，例如：它以何种方式搜索新的文件，以及当文件有一段时间没有发生变化时，何时选择关闭文件句柄。</p><p><strong>劣势</strong>：Filebeat 的应用范围十分有限，所以在某些场景下我们会碰到问题。例如，如果使用 Logstash 作为下游管道，我们同样会遇到性能问题。正因为如此，Filebeat 的范围在扩大。开始时，它只能将日志发送到 Logstash 和 Elasticsearch，而现在它可以将日志发送给 Kafka 和 Redis，在 5.x 版本中，它还具备过滤的能力。</p><h4 id="Fluentd"><a href="#Fluentd" class="headerlink" title="Fluentd"></a>Fluentd</h4><p>Fluentd 创建的初衷主要是尽可能的使用 JSON 作为日志输出，所以传输工具及其下游的传输线不需要猜测子字符串里面各个字段的类型。这样它为几乎所有的语言都提供库，这也意味着可以将它插入到自定义的程序中。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-031337.png" alt=""></p><p><strong>优势</strong>：和多数 Logstash 插件一样，Fluentd 插件是用 Ruby 语言开发的非常易于编写维护。所以它数量很多，几乎所有的源和目标存储都有插件(各个插件的成熟度也不太一样)。这也意味这可以用 Fluentd 来串联所有的东西。</p><p><strong>劣势</strong>：因为在多数应用场景下得到 Fluentd 结构化的数据，它的灵活性并不好。但是仍然可以通过正则表达式来解析非结构化的数据。尽管性能在大多数场景下都很好，但它并不是最好的，它的缓冲只存在与输出端，单线程核心以及 Ruby GIL 实现的插件意味着它大的节点下性能是受限的。</p><h4 id="Logagent"><a href="#Logagent" class="headerlink" title="Logagent"></a>Logagent</h4><p>Logagent 是 Sematext 提供的传输工具，它用来将日志传输到 Logsene(一个基于 SaaS 平台的 Elasticsearch API)，因为 Logsene 会暴露 Elasticsearch API，所以 Logagent 可以很容易将数据推送到 Elasticsearch 。</p><p><strong>优势</strong>：可以获取 /var/log 下的所有信息，解析各种格式的日志，可以掩盖敏感的数据信息。它还可以基于 IP 做 GeoIP 丰富地理位置信息。同样，它轻量又快速，可以将其置入任何日志块中。Logagent 有本地缓冲，所以在数据传输目的地不可用时不会丢失日志。</p><p><strong>劣势</strong>：没有 Logstash 灵活。</p><h3 id="日志结构设计"><a href="#日志结构设计" class="headerlink" title="日志结构设计"></a>日志结构设计</h3><p>前面介绍了日志和对比了常用日志采集工具的优势和劣势，通常在不同环境，不同机器上都会部署日志采集工具，然后采集工具会实时的将新的日志采集发送到下游，因为日志数据量毕竟大，所以建议发到 MQ 中，比如 Kafka，这样再想怎么处理这些日志就会比较灵活。假设我们忽略底层采集具体是哪种，但是规定采集好的日志结构化数据如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEvent</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String type;<span class="comment">//日志的类型(应用、容器、...)</span></span><br><span class="line">    <span class="keyword">private</span> Long timestamp;<span class="comment">//日志的时间戳</span></span><br><span class="line">    <span class="keyword">private</span> String level;<span class="comment">//日志的级别(debug/info/warn/error)</span></span><br><span class="line">    <span class="keyword">private</span> String message;<span class="comment">//日志内容</span></span><br><span class="line">    <span class="comment">//日志的标识(应用 ID、应用名、容器 ID、机器 IP、集群名、...)</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; tags = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后上面这种 LogEvent 的数据（假设采集发上来的是这种结构数据的 JSON 串，所以需要在 Flink 中做一个反序列化解析）就会往 Kafka 不断的发送数据，样例数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"app"</span>,</span><br><span class="line"><span class="attr">"timestamp"</span>: <span class="number">1570941591229</span>,</span><br><span class="line"><span class="attr">"level"</span>: <span class="string">"error"</span>,</span><br><span class="line"><span class="attr">"message"</span>: <span class="string">"Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/flink/api/common/ExecutionConfig$GlobalJobParameters"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"cluster_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"app_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"host_ip"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line"><span class="attr">"app_id"</span>: <span class="string">"21"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么在 Flink 中如何将应用异常或者错误的日志做实时告警呢？</p><h3 id="异常日志实时告警项目架构"><a href="#异常日志实时告警项目架构" class="headerlink" title="异常日志实时告警项目架构"></a>异常日志实时告警项目架构</h3><p>整个异常日志实时告警项目的架构如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-035811.png" alt=""></p><p>应用日志散列在不同的机器，然后每台机器都有部署采集日志的 Agent（可以是上面的 Filebeat、Logstash 等），这些 Agent 会实时的将分散在不同机器、不同环境的应用日志统一的采集发到 Kafka 集群中，然后告警这边是有一个 Flink 作业去实时的消费 Kafka 数据做一个异常告警计算处理。如果还想做日志的搜索分析，可以起另外一个作业去实时的将 Kafka 的日志数据写入进 ElasticSearch，再通过 Kibana 页面做搜索和分析。</p><h3 id="日志数据发送到-Kafka"><a href="#日志数据发送到-Kafka" class="headerlink" title="日志数据发送到 Kafka"></a>日志数据发送到 Kafka</h3><p>上面已经讲了日志数据 LogEvent 的结构和样例数据，因为要在服务器部署采集工具去采集应用日志数据对于本地测试来说可能稍微复杂，所以在这里就只通过代码模拟构造数据发到 Kafka 去，然后在 Flink 作业中去实时消费 Kafka 中的数据，下面演示构造日志数据发到 Kafka 的工具类，这个工具类主要分两块，构造 LogEvent 数据和发送到 Kafka。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BuildLogEventDataUtil</span> </span>&#123;</span><br><span class="line">    <span class="comment">//Kafka broker 和 topic 信息</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String BROKER_LIST = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LOG_TOPIC = <span class="string">"zhisheng_log"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeDataToKafka</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, BROKER_LIST);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        KafkaProducer producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//模拟构造 LogEvent 对象</span></span><br><span class="line">            LogEvent logEvent = <span class="keyword">new</span> LogEvent().builder()</span><br><span class="line">                    .type(<span class="string">"app"</span>)</span><br><span class="line">                    .timestamp(System.currentTimeMillis())</span><br><span class="line">                    .level(logLevel())</span><br><span class="line">                    .message(message(i + <span class="number">1</span>))</span><br><span class="line">                    .tags(mapData())</span><br><span class="line">                    .build();</span><br><span class="line"><span class="comment">//            System.out.println(logEvent);</span></span><br><span class="line">            ProducerRecord record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(LOG_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(logEvent));</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        writeDataToKafka();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">message</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"这是第 "</span> + i + <span class="string">" 行日志！"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">logLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"debug"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"warn"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"error"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">hostIp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.11"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.12"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.13"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">mapData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">"app_id"</span>, <span class="string">"11"</span>);</span><br><span class="line">        map.put(<span class="string">"app_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"cluster_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"host_ip"</span>, hostIp());</span><br><span class="line">        map.put(<span class="string">"class"</span>, <span class="string">"BuildLogEventDataUtil"</span>);</span><br><span class="line">        map.put(<span class="string">"method"</span>, <span class="string">"main"</span>);</span><br><span class="line">        map.put(<span class="string">"line"</span>, String.valueOf(<span class="keyword">new</span> Random().nextInt(<span class="number">100</span>)));</span><br><span class="line">        <span class="comment">//add more tag</span></span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果之前 Kafka 中没有 zhisheng_log 这个 topic，运行这个工具类之后也会自动创建这个 topic 了。</p><h3 id="Flink-实时处理日志数据"><a href="#Flink-实时处理日志数据" class="headerlink" title="Flink 实时处理日志数据"></a>Flink 实时处理日志数据</h3><p>在 3.7 章中已经讲过如何使用 Flink Kafka connector 了，接下来就直接写代码去消费 Kafka 中的日志数据，作业代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEventAlert</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ParameterTool parameterTool = ExecutionEnvUtil.createParameterTool(args);</span><br><span class="line">        StreamExecutionEnvironment env = ExecutionEnvUtil.prepare(parameterTool);</span><br><span class="line">        Properties properties = KafkaConfigUtil.buildKafkaProps(parameterTool);</span><br><span class="line">        FlinkKafkaConsumer011&lt;LogEvent&gt; consumer = <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">                parameterTool.get(<span class="string">"log.topic"</span>),</span><br><span class="line">                <span class="keyword">new</span> LogSchema(),</span><br><span class="line">                properties);</span><br><span class="line">        env.addSource(consumer)</span><br><span class="line">                .print();</span><br><span class="line">        env.execute(<span class="string">"log event alert"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为 Kafka 的日志数据是 JSON 的，所以在消费的时候需要额外定义 Schema 来反序列化数据，定义的 LogSchema 如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogSchema</span> <span class="keyword">implements</span> <span class="title">DeserializationSchema</span>&lt;<span class="title">LogEvent</span>&gt;, <span class="title">SerializationSchema</span>&lt;<span class="title">LogEvent</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Gson gson = <span class="keyword">new</span> Gson();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LogEvent <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> gson.fromJson(<span class="keyword">new</span> String(bytes), LogEvent.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEndOfStream</span><span class="params">(LogEvent logEvent)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(LogEvent logEvent) &#123;</span><br><span class="line">        <span class="keyword">return</span> gson.toJson(logEvent).getBytes(Charset.forName(<span class="string">"UTF-8"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInformation&lt;LogEvent&gt; <span class="title">getProducedType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TypeInformation.of(LogEvent.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置文件中设置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka.brokers=localhost:9092</span><br><span class="line">kafka.group.id=zhisheng</span><br><span class="line">log.topic=zhisheng_log</span><br></pre></td></tr></table></figure><p>接下来先启动 Kafka，然后运行 BuildLogEventDataUtil 工具类，往 Kafka 中发送模拟的日志数据，接下来运行 LogEventAlert 类，去消费将 Kafka 中的数据做一个验证，运行结果如下图所示，可以发现有日志数据打印出来了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-072350.png" alt=""></p><h3 id="处理应用异常日志"><a href="#处理应用异常日志" class="headerlink" title="处理应用异常日志"></a>处理应用异常日志</h3><p>上面已经能够处理这些日志数据了，但是需求是要将应用的异常日志做告警，所以在消费到所有的数据后需要过滤出异常的日志，比如可以使用 filter 算子进行过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.filter(logEvent -&gt; <span class="string">"error"</span>.equals(logEvent.getLevel()))</span><br></pre></td></tr></table></figure><p>过滤后只有 error 的日志数据打印出来了，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-073245.png" alt=""></p><p>再将作业打包通过 UI 提交到集群运行的结果如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-080120.png" alt=""></p><p>再获取到这些 Error 类型的数据后，就可以根据这个数据构造成一个新的 Event，组装成告警消息，然后在 Sink 处调用下游的通知策略进行告警通知，当然这些告警通知策略可能会很多，然后还有收敛策略。具体的通知策略和收敛策略在这节不做细讲，最后发出的应用异常日志告警消息中会携带一个链接，点击该链接可以跳转到对应的应用异常页面，这样就可以查看应用堆栈的详细日志，更加好定位问题。</p><h3 id="小结与反思"><a href="#小结与反思" class="headerlink" title="小结与反思"></a>小结与反思</h3><p>本节开始讲了日志处理方案的演进，接着分析最新日志方案的实现架构，包含它的日志结构设计和异常日志实时告警的方案，然后通过模拟日志数据发送到 Kafka，Flink 实时去处理这种日志的数据进行告警。</p><p>本节涉及的代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-monitor/flink-learning-monitor-alert">flink-learning-monitor-alert</a></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 能否动态更改 Checkpoint 配置</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-03-01T01:35:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间在社区邮件中看到有人提问是否可以动态开启 Checkpoint，昨天在钉钉群中又看到有个同学在问能够动态调整 Checkpoint 的时间，其实不仅仅是这些，在社区邮件和群里经常看到有问这块内容的问题，所以可以发现在 Flink 中其实关于 Checkpoint 相关的东西还是非常重要且解决起来比较麻烦，估计应该也困扰了不少人。</p><a id="more"></a><p>不过今天的话题不是在于去讨论 Checkpoint 的机制，因为前面两个问题都涉及到了动态的去配置 Checkpoint 的参数（是否开启和 Checkpoint 的时间间隔），而 zhisheng 我在前面通过两个视频讲解了 <a href="http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/">Flink 如何与 Apollo 和 Nacos 整合去动态的更改作业配置</a>，所以私底下就有同学找我咨询是否可以动态的更改 Checkpoint 配置，我当时因为知道其实有些参数是一旦初始化了之后是改不了的，但是具体什么参数我也不难全部列举，所以只好回答那位同学说：以自己实测的结果为准哈。</p><p>所以这里我就给大家演示一下到底是否可以动态的更改 Checkpoint 配置，请看我在 B 站的视频：</p><p><a href="https://www.bilibili.com/video/av92655075/">https://www.bilibili.com/video/av92655075/</a></p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=92655075&cid=158192037&page=1" allowfullscreen="true"> </iframe><p>通过这个视频，虽然我是使用 Flink 和 Nacos 整合的，作业监听到了 Checkpoint 的配置做了修改，但是可以发现其实 Checkpoint 更改后其实是不生效的。</p><p>这里仅从个人的思考来解释一下：因为 Flink 是 Lazy Evaluation（延迟执行），当程序的 main 方法执行时，我们创建的 env 会依次进行属性的初始化配置，但是数据源加载数据和数据转换等算子不会立马执行，这些算子操作会被创建并添加到程序的执行计划中去，只有当执行环境 env 的 execute 方法被显示地触发执行时，整个程序才开始执行实际的操作（StreamGraph -&gt; JobGraph -&gt; ExecutionGraph），所以在程序执行 execute 方法后再修改 env 的配置其实就不起作用了。</p><p>另外给大家来看下邱从贤(负责 Flink State 相关)对能否动态配置 Checkpoint 的回答：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-03-01-011804.png" alt=""></p><p>相关的测试代码在: <a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-configration-center/flink-learning-configration-center-nacos">https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-configration-center/flink-learning-configration-center-nacos</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间在社区邮件中看到有人提问是否可以动态开启 Checkpoint，昨天在钉钉群中又看到有个同学在问能够动态调整 Checkpoint 的时间，其实不仅仅是这些，在社区邮件和群里经常看到有问这块内容的问题，所以可以发现在 Flink 中其实关于 Checkpoint 相关的东西还是非常重要且解决起来比较麻烦，估计应该也困扰了不少人。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink 整合 Apollo，动态更新 Flink 作业配置</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-26T00:39:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人自己录的视频，讲解 Flink 整和 Apollo，动态更新作业配置，无需重启作业！</p><a id="more"></a><p>在上一篇讲解 <a href="http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/">Flink 与 Nacos 整合的视频</a> 中，讲过了常见的几种更新配置的方法，最常使用的可能就是通过广播流的方式，相信看完上个视频的，估计对整合 Nacos 做动态更新配置应该问题不大，zhisheng 我也觉得稍微简单，尤其 Nacos 搭建安装也比较简单。不知道大家公司有没有使用 Nacos 呢？我知道有的公司使用 Apollo 居多，所以后面就有读者问我能不能出个整合 Apollo 的视频，所以我趁着周末大晚上的时间就开始折腾了一番，本篇文章将给大家讲解与 Apollo 整合，动态的更新 Flink 配置。</p><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。</p><p>因为它的自身架构原因，导致安装可能会比较复杂，需要安装好多个组件，个人觉得比 Nacos 复杂，幸好的是官方的文档比较详细，跟着安装步骤来说还是没有问题的。zhisheng 我是只在自己 Mac 电脑上面安装了一个单机版的，仅为测试使用。</p><p>快速上手的请参考该链接 <a href="https://github.com/nobodyiam/apollo-build-scripts">https://github.com/nobodyiam/apollo-build-scripts</a>，这样你就能够在几分钟内在本地环境部署、启动 Apollo 配置中心。另外还提供了 Quick Start 的 Docker 版本，如果你对 Docker 比较熟悉的话，那更方便了。</p><p>主要演示流程（安装 Apollo 和整合 Flink），本人录了个视频，更方便大家去实战操作，欢迎观看：</p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=91742999&cid=156618259&page=1" allowfullscreen="true"> </iframe><p>代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-apollo">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-apollo</a></p><p>注意引入 Apollo 的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.ctrip.framework.apollo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>apollo-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人自己录的视频，讲解 Flink 整和 Apollo，动态更新作业配置，无需重启作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Apollo" scheme="http://www.54tianzhisheng.cn/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Flink 整合 Nacos，让 Flink 作业配置动态更新不再是难事</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/</id>
    <published>2020-02-21T16:00:00.000Z</published>
    <updated>2020-02-25T16:06:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人自己录的视频，讲解 Flink 整和 Nacos，动态更新作业配置，无需重启作业！</p><a id="more"></a><p>我们知道 Flink 作业的配置一般都是通过在作业启动的时候通过参数传递的，或者通过读取配置文件的参数，在作业启动后初始化了之后如果再想更新作业的配置一般有两种解决方法：</p><ul><li><p>改变启动参数或者改变配置文件，重启作业，让作业能够读取到修改后的配置</p></li><li><p>通过读取配置流（需要自定义 Source 读取配置），然后流和流连接起来</p></li></ul><p>这两种解决方法一般是使用的比较多，对于第一种方法，zhisheng 我本人其实是不太建议的，重启作业会带来很多影响，Flink 作业完整的重启流程应该是：当作业停掉的时候需要去做一次 Savepoint（相当于把作业的状态做一次完整的快照），启动的时候又需要将作业从 Savepoint 启动，整个流程如果状态比较大的话，做一次 Savepoint 和从 Savepoint 初始化的时间会比较久，然而流处理的场景下通常数据量都是比较大的，那么在这段时间内，可能会造成不少的数据堆积（可能分钟内就上千万或者更多），当作业启动后再去追这千万量级的数据，对作业来说压力自然会增大。</p><p>对于第二种方法也是一种用的很多的方式，自己也比较推荐，之前自己在社区直播的时候也有讲过类似的方案，但是今天我准备讲解另一种方法 —— 整合配置中心，没看见有人这么用过，我也算是第一个吃螃蟹的人了！说到配置中心，目前国内有 Apollo 和 Nacos，这里先来讲下和 Nacos 的整合，下面的实战操作请看我录制的视频。</p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=90742627&cid=154955963&page=1" allowfullscreen="true"> </iframe><p>代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-nacos">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-nacos</a></p><p>我本人安装的 Nacos 依赖是阿里的，因为自己本地编译了一份源码，所以可能会有这些依赖在自己本地的 .m2 目录中：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>但是有些同学反馈说上面的依赖引入不上，一直下载不了，比如 nacos-core，这里建议去 <a href="https://mvnrepository.com/search?q=nacos-core">https://mvnrepository.com/search?q=nacos-core</a> 看一下第一个，然后引用试试。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人自己录的视频，讲解 Flink 整和 Nacos，动态更新作业配置，无需重启作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.10 新特性研究</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/22/flink-1.10-release/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/22/flink-1.10-release/</id>
    <published>2020-02-21T16:00:00.000Z</published>
    <updated>2020-02-22T13:34:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.10 release 文档描述了一些比较重要的点，比如配置、操作、依赖、1.9 版本和 1.10 版本之间的区别，如果你准备将 Flink 升级到 1.10 版本，建议仔细看完下面的内容。</p><a id="more"></a><h3 id="集群和部署"><a href="#集群和部署" class="headerlink" title="集群和部署"></a>集群和部署</h3><ul><li><p>文件系统需要通过插件的方式加载</p></li><li><p>Flink 客户端根据配置的类加载策略加载，parent-first 和 child-first 两种方式</p></li><li><p>允许在所有的 TaskManager 上均匀地分布任务，需要在 <code>flink-conf.yaml</code> 配置文件中配置 <code>cluster.evenly-spread-out-slots: true</code> 参数</p></li><li><p>高可用存储目录做了修改，在 <code>HA_STORAGE_DIR/HA_CLUSTER_ID</code> 下，<code>HA_STORAGE_DIR</code> 路径通过 <code>high-availability.storageDir</code> 参数配置，<code>HA_CLUSTER_ID</code> 路径通过 <code>high-availability.cluster-id</code> 参数配置</p></li><li><p>当使用 <code>-yarnship</code> 命令参数时，资源目录和 jar 文件会被添加到 classpath 中</p></li><li><p>移除了 <code>--yn/--yarncontainer</code> 命令参数</p></li><li><p>移除了 <code>--yst/--yarnstreaming</code> 命令参数</p></li><li><p>Flink Mesos 会拒绝掉所有的过期请求</p></li><li><p>重构了 Flink 的调度程序，其目标是使调度策略在未来可以定制</p></li><li><p>支持 Java 11，当使用 Java 11 启动 Flink 时，会有些 WARNING 的日志提醒，注意：Cassandra、Hive、HBase 等 connector 没有使用 Java 11 测试过</p></li></ul><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><ul><li>全新的 Task Executor 内存模型，会影响 standalone、YARN、Mesos、K8S 的部署，JobManager 的内存模型没有修改。如果你在没有调整的情况下，重用以前的 Flink 配置，则新的内存模型可能会导致 JVM 的计算内存参数不同，从而导致性能的变化。</li></ul><p>以下选项已经删除，不再起作用：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-02-21-074438.png" alt=""></p><p>以下选项已经替换成其他的选项：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-02-21-074623.png" alt=""></p><ul><li><p>RocksDB State Backend 内存可以控制，用户可以调整 RocksDB 的写/读内存比率 <code>state.backend.rocksdb.memory.write-buffer-ratio</code>（默认情况下 0.5）和为索引/过滤器保留的内存部分 <code>state.backend.rocksdb.memory.high-prio-pool-ratio</code>（默认情况下0.1）</p></li><li><p>细粒度的算子（Operator）资源管理，配置选项 <code>table.exec.resource.external-buffer-memory</code>，<code>table.exec.resource.hash-agg.memory</code>，<code>table.exec.resource.hash-join.memory</code>，和 <code>table.exec.resource.sort.memory</code> 已被弃用</p></li></ul><h3 id="Table-API-和-SQL"><a href="#Table-API-和-SQL" class="headerlink" title="Table API 和 SQL"></a>Table API 和 SQL</h3><ul><li><p>将 ANY 类型重命名为 RAW 类型，该标识符 raw 现在是保留关键字，在用作 SQL 字段或函数名称时必须转义</p></li><li><p>重命名 Table Connector 属性，以便编写 DDL 语句时提供更好的用户体验，比如 Kafka Connector 属性 <code>connector.properties</code> 和 <code>connector.specific-offsets</code>、Elasticsearch Connector 属性 <code>connector.hosts</code></p></li><li><p>之前与临时表和视图进行交互的方法已经被弃用，目前使用 createTemporaryView()</p></li><li><p>移除了 ExternalCatalog API（ExternalCatalog、SchematicDescriptor、MetadataDescriptor、StatisticsDescriptor），建议使用新的 Catalog API</p></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li><p>ConfigOptions 如果无法将配置的值解析成所需要的类型，则会抛出 IllegalArgumentException 异常，之前是会返回默认值</p></li><li><p>增加默认的重启策略延迟时间（fixed-delay 和 failure-rate 已经默认是 1s，之前是 0）</p></li><li><p>简化集群级别的重启策略配置，现在集群级别的重启策略仅由 restart-strategy 配置和是否开启 Checkpoint 确定</p></li><li><p>默认情况下禁用内存映射的 BoundedBlockingSubpartition</p></li><li><p>移除基于未认证的网络流量控制</p></li><li><p>移除 HighAvailabilityOptions 中的 HA_JOB_DELAY 配置</p></li></ul><h3 id="状态（State）"><a href="#状态（State）" class="headerlink" title="状态（State）"></a>状态（State）</h3><ul><li><p>默认开启 TTL 的状态后台清理</p></li><li><p>弃用 <code>StateTtlConfig#Builder#cleanupInBackground()</code></p></li><li><p>使用 RocksDBStateBackend 时，默认将计时器存储在 RocksDB 中，之前是存储在堆内存（Heap）中</p></li><li><p><code>StateTtlConfig#TimeCharacteristic</code> 已经被移除，目前使用 <code>StateTtlConfig#TtlTimeCharacteristic</code></p></li><li><p>新增 <code>MapState#isEmpty()</code> 方法来检查 MapState 是否为空，该方法比使用 <code>mapState.keys().iterator().hasNext()</code> 的速度快 40%</p></li><li><p>RocksDB 升级，发布了自己的 FRocksDB（基于 RocksDB 5.17.2 版本），主要是因为高版本的 RocksDB 在某些情况下性能会下降</p></li><li><p>默认禁用 RocksDB 日志记录，需要启用的话需要利用 RocksDBOptionsFactory 创建 DBOptions 实例，并通过 setInfoLogLevel 方法设置 INFO_LEVEL</p></li><li><p>优化从 RocksDB Savepoint 恢复的机制，以前如果从包含大型 KV 对的 RocksDB Savepoint 恢复时，用户可能会遇到 OOM。现在引入了可配置的内存限制，RocksDBWriteBatchWrapper 默认值为 2MB。RocksDB的WriteBatch 将在达到内存限制之前刷新。可以在 <code>flink-conf.yml</code> 中修改 <code>state.backend.rocksdb.write-batch-size</code> 配置</p></li></ul><h3 id="PyFlink"><a href="#PyFlink" class="headerlink" title="PyFlink"></a>PyFlink</h3><ul><li>不再支持 Python2</li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li>InfluxdbReporter 会跳过 Inf 和 NaN（InfluxDB 不支持的类型，比如 <code>Double.POSITIVE_INFINITY</code>, <code>Double.NEGATIVE_INFINITY</code>, <code>Double.NaN</code>）</li></ul><h3 id="连接器（Connectors）"><a href="#连接器（Connectors）" class="headerlink" title="连接器（Connectors）"></a>连接器（Connectors）</h3><ul><li>改变 Kinesis 连接器的 License</li></ul><h3 id="接口更改"><a href="#接口更改" class="headerlink" title="接口更改"></a>接口更改</h3><ul><li><p><code>ExecutionConfig＃getGlobalJobParameters()</code> 不再返回 null</p></li><li><p>MasterTriggerRestoreHook 中的 triggerCheckpoint 方法必须时非阻塞的</p></li><li><p>HA 服务的客户端/服务器端分离，HighAvailabilityServices 已分离成客户端 ClientHighAvailabilityServices 和集群端 HighAvailabilityServices</p></li><li><p><code>HighAvailabilityServices#getWebMonitorLeaderElectionService()</code> 标记过期</p></li><li><p>LeaderElectionService 接口做了更改</p></li><li><p>弃用 Checkpoint 锁</p></li><li><p>弃用 OptionsFactory 和 ConfigurableOptionsFactory 接口</p></li></ul><p>参考：<a href="https://github.com/apache/flink/blob/master/docs/release-notes/flink-1.10.zh.md">https://github.com/apache/flink/blob/master/docs/release-notes/flink-1.10.zh.md</a></p><hr><p>看了下官方的这份新版本的介绍，感觉还缺少很多新功能的介绍，比如：</p><ul><li>在 1.10 版本中把 Blink 版本的哪些功能整合过来了</li><li>竟然没有写 Flink 对原生 Kubernetes 的集成</li><li>PyFlink 的介绍是认真的吗？</li><li>对 Hive 的生产级别集成，完全没有提及呀</li><li>Table API/SQL 优化点讲得不太多</li></ul><p>可能因为篇幅的问题，还有很多特性都没有讲解出来，得我们自己去找源码学习！</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.10 release 文档描述了一些比较重要的点，比如配置、操作、依赖、1.9 版本和 1.10 版本之间的区别，如果你准备将 Flink 升级到 1.10 版本，建议仔细看完下面的内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink Checkpoint 问题排查实用指南</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/</id>
    <published>2020-02-19T16:00:00.000Z</published>
    <updated>2020-02-20T01:36:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 Flink 中，状态可靠性保证由 Checkpoint 支持，当作业出现 failover 的情况下，Flink 会从最近成功的 Checkpoint 恢复。</p><a id="more"></a><p>作者：邱从贤（山智）<br>转载自：<a href="">https://www.jianshu.com/p/fc100f85a0fb</a></p><p>在实际情况中，我们可能会遇到 Checkpoint 失败，或者 Checkpoint 慢的情况，本文会统一聊一聊 Flink 中 Checkpoint 异常的情况（包括失败和慢），以及可能的原因和排查思路。</p><h3 id="1-Checkpoint-流程简介"><a href="#1-Checkpoint-流程简介" class="headerlink" title="1. Checkpoint 流程简介"></a>1. Checkpoint 流程简介</h3><p>首先我们需要了解 Flink 中 Checkpoint 的整个流程是怎样的，在了解整个流程之后，我们才能在出问题的时候，更好的进行定位分析。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012549.jpg" alt=""></p><p>从上图我们可以知道，Flink 的 Checkpoint 包括如下几个部分：</p><ul><li>JM trigger checkpoint</li><li>Source 收到 trigger checkpoint 的 PRC，自己开始做 snapshot，并往下游发送 barrier</li><li>下游接收 barrier（需要 barrier 都到齐才会开始做 checkpoint）</li><li>Task 开始同步阶段 snapshot</li><li>Task 开始异步阶段 snapshot</li><li>Task snapshot 完成，汇报给 JM</li></ul><p>上面的任何一个步骤不成功，整个 checkpoint 都会失败。</p><h3 id="2-Checkpoint-异常情况排查"><a href="#2-Checkpoint-异常情况排查" class="headerlink" title="2 Checkpoint 异常情况排查"></a>2 Checkpoint 异常情况排查</h3><h4 id="2-1-Checkpoint-失败"><a href="#2-1-Checkpoint-失败" class="headerlink" title="2.1 Checkpoint 失败"></a>2.1 Checkpoint 失败</h4><p>可以在 Checkpoint 界面看到如下图所示，下图中 Checkpoint 10423 失败了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012649.jpg" alt=""></p><p>点击 Checkpoint 10423 的详情，我们可以看到类系下图所示的表格（下图中将 operator 名字截取掉了）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012705.jpg" alt=""></p><p>上图中我们看到三行，表示三个 operator，其中每一列的含义分别如下：</p><ul><li>其中 Acknowledged 一列表示有多少个 subtask 对这个 Checkpoint 进行了 ack，从图中我们可以知道第三个 operator 总共有 5 个 subtask，但是只有 4 个进行了 ack；</li><li>第二列 Latest Acknowledgement 表示该 operator 的所有 subtask 最后 ack 的时间；</li><li>End to End Duration 表示整个 operator 的所有 subtask 中完成 snapshot 的最长时间；</li><li>State Size 表示当前 Checkpoint 的 state 大小 – 主要这里如果是增量 checkpoint 的话，则表示增量大小；</li><li>Buffered During Alignment 表示在 barrier 对齐阶段积攒了多少数据，如果这个数据过大也间接表示对齐比较慢）；</li></ul><p>Checkpoint 失败大致分为两种情况：Checkpoint Decline 和 Checkpoint Expire。</p><h5 id="2-1-1-Checkpoint-Decline"><a href="#2-1-1-Checkpoint-Decline" class="headerlink" title="2.1.1 Checkpoint Decline"></a>2.1.1 Checkpoint Decline</h5><p>我们能从 jobmanager.log 中看到类似下面的日志</p><p>Decline checkpoint 10423 by task 0b60f08bf8984085b59f8d9bc74ce2e1 of job 85d268e6fbc19411185f7e4868a44178. 其中<br>10423 是 checkpointID，0b60f08bf8984085b59f8d9bc74ce2e1 是 execution id，85d268e6fbc19411185f7e4868a44178 是 job id，我们可以在 jobmanager.log 中查找 execution id，找到被调度到哪个 taskmanager 上，类似如下所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2019-09-02 16:26:20,972 INFO  [jobmanager-future-thread-61] org.apache.flink.runtime.executiongraph.ExecutionGraph        - XXXXXXXXXXX (100/289) (87b751b1fd90e32af55f02bb2f9a9892) switched from SCHEDULED to DEPLOYING.</span><br><span class="line">2019-09-02 16:26:20,972 INFO  [jobmanager-future-thread-61] org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying XXXXXXXXXXX (100/289) (attempt #0) to slot container_e24_1566836790522_8088_04_013155_1 on hostnameABCDE</span><br></pre></td></tr></table></figure><p>从上面的日志我们知道该 execution 被调度到 hostnameABCDE 的 container_e24_1566836790522_8088_04_013155_1 slot 上，接下来我们就可以到 container container_e24_1566836790522_8088_04_013155 的 taskmanager.log 中查找 Checkpoint 失败的具体原因了。</p><p>另外对于 Checkpoint Decline 的情况，有一种情况我们在这里单独抽取出来进行介绍：Checkpoint Cancel。</p><p>当前 Flink 中如果较小的 Checkpoint 还没有对齐的情况下，收到了更大的 Checkpoint，则会把较小的 Checkpoint 给取消掉。我们可以看到类似下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$taskNameWithSubTaskAndID: Received checkpoint barrier for checkpoint 20 before completing current checkpoint 19. Skipping current checkpoint.</span><br></pre></td></tr></table></figure><p>这个日志表示，当前 Checkpoint 19 还在对齐阶段，我们收到了 Checkpoint 20 的 barrier。然后会逐级通知到下游的 task checkpoint 19 被取消了，同时也会通知 JM 当前 Checkpoint 被 decline 掉了。</p><p>在下游 task 收到被 cancelBarrier 的时候，会打印类似如下的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">$taskNameWithSubTaskAndID: Checkpoint 19 canceled, aborting alignment.</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">DEBUG</span><br><span class="line">$taskNameWithSubTaskAndID: Checkpoint 19 canceled, skipping alignment.</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">WARN</span><br><span class="line">$taskNameWithSubTaskAndID: Received cancellation barrier for checkpoint 20 before completing current checkpoint 19. Skipping current checkpoint.</span><br></pre></td></tr></table></figure><p>上面三种日志都表示当前 task 接收到上游发送过来的 barrierCancel 消息，从而取消了对应的 Checkpoint。</p><h5 id="2-1-2-Checkpoint-Expire"><a href="#2-1-2-Checkpoint-Expire" class="headerlink" title="2.1.2 Checkpoint Expire"></a>2.1.2 Checkpoint Expire</h5><p>如果 Checkpoint 做的非常慢，超过了 timeout 还没有完成，则整个 Checkpoint 也会失败。当一个 Checkpoint 由于超时而失败是，会在 jobmanager.log 中看到如下的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Checkpoint 1 of job 85d268e6fbc19411185f7e4868a44178  expired before completing.</span><br></pre></td></tr></table></figure><p>表示 Chekpoint 1 由于超时而失败，这个时候可以可以看这个日志后面是否有类似下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Received late message for now expired checkpoint attempt 1 from 0b60f08bf8984085b59f8d9bc74ce2e1 of job 85d268e6fbc19411185f7e4868a44178.</span><br></pre></td></tr></table></figure><p>可以按照 2.1.1 中的方法找到对应的 taskmanager.log 查看具体信息。</p><blockquote><p>下面的日志如果是 DEBUG 的话，我们会在开始处标记 DEBUG</p></blockquote><p>我们按照下面的日志把 TM 端的 snapshot 分为三个阶段，开始做 snapshot 前，同步阶段，异步阶段：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Starting checkpoint (6751) CHECKPOINT on task taskNameWithSubtasks (4/4)</span><br></pre></td></tr></table></figure><p>这个日志表示 TM 端 barrier 对齐后，准备开始做 Checkpoint。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">2019-08-06 13:43:02,613 DEBUG org.apache.flink.runtime.state.AbstractSnapshotStrategy       - DefaultOperatorStateBackend snapshot (FsCheckpointStorageLocation &#123;fileSystem=org.apache.flink.core.fs.SafetyNetWrapperFileSystem@70442baf, checkpointDirectory=xxxxxxxx, sharedStateDirectory=xxxxxxxx, taskOwnedStateDirectory=xxxxxx, metadataFilePath=xxxxxx, reference=(default), fileStateSizeThreshold=1024&#125;, synchronous part) in thread Thread[Async calls on Source: xxxxxx</span><br><span class="line">_source -&gt; Filter (27/70),5,Flink Task Threads] took 0 ms.</span><br></pre></td></tr></table></figure><p>上面的日志表示当前这个 backend 的同步阶段完成，共使用了 0 ms。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">DefaultOperatorStateBackend snapshot (FsCheckpointStorageLocation &#123;fileSystem=org.apache.flink.core.fs.SafetyNetWrapperFileSystem@7908affe, checkpointDirectory=xxxxxx, sharedStateDirectory=xxxxx, taskOwnedStateDirectory=xxxxx,  metadataFilePath=xxxxxx, reference=(default), fileStateSizeThreshold=1024&#125;, asynchronous part) in thread Thread[pool-48-thread-14,5,Flink Task Threads] took 369 ms</span><br></pre></td></tr></table></figure><p>上面的日志表示异步阶段完成，异步阶段使用了 369 ms</p><p>在现有的日志情况下，我们通过上面三个日志，定位 snapshot 是开始晚，同步阶段做的慢，还是异步阶段做的慢。然后再按照情况继续进一步排查问题。</p><h4 id="2-2-Checkpoint-慢"><a href="#2-2-Checkpoint-慢" class="headerlink" title="2.2 Checkpoint 慢"></a>2.2 Checkpoint 慢</h4><p>在 2.1 节中，我们介绍了 Checkpoint 失败的排查思路，本节会分情况介绍 Checkpoint 慢的情况。</p><p>Checkpoint 慢的情况如下：比如 Checkpoint interval 1 分钟，超时 10 分钟，Checkpoint 经常需要做 9 分钟（我们希望 1 分钟左右就能够做完），而且我们预期 state size 不是非常大。</p><p>对于 Checkpoint 慢的情况，我们可以按照下面的顺序逐一检查。</p><h5 id="2-2-0-Source-Trigger-Checkpoint-慢"><a href="#2-2-0-Source-Trigger-Checkpoint-慢" class="headerlink" title="2.2.0 Source Trigger Checkpoint 慢"></a>2.2.0 Source Trigger Checkpoint 慢</h5><p>这个一般发生较少，但是也有可能，因为 source 做 snapshot 并往下游发送 barrier 的时候，需要抢锁（这个现在社区正在进行用 mailBox 的方式替代当前抢锁的方式，详情参考[1])。如果一直抢不到锁的话，则可能导致 Checkpoint 一直得不到机会进行。如果在 Source 所在的 taskmanager.log 中找不到开始做 Checkpoint 的 log，则可以考虑是否属于这种情况，可以通过 jstack 进行进一步确认锁的持有情况。</p><h5 id="2-2-1-使用增量-Checkpoint"><a href="#2-2-1-使用增量-Checkpoint" class="headerlink" title="2.2.1 使用增量 Checkpoint"></a>2.2.1 使用增量 Checkpoint</h5><p>现在 Flink 中 Checkpoint 有两种模式，全量 Checkpoint 和 增量 Checkpoint，其中全量 Checkpoint 会把当前的 state 全部备份一次到持久化存储，而增量 Checkpoint，则只备份上一次 Checkpoint 中不存在的 state，因此增量 Checkpoint 每次上传的内容会相对更好，在速度上会有更大的优势。</p><p>现在 Flink 中仅在 RocksDBStateBackend 中支持增量 Checkpoint，如果你已经使用 RocksDBStateBackend，可以通过开启增量 Checkpoint 来加速，具体的可以参考 [2]。</p><h5 id="2-2-2-作业存在反压或者数据倾斜"><a href="#2-2-2-作业存在反压或者数据倾斜" class="headerlink" title="2.2.2 作业存在反压或者数据倾斜"></a>2.2.2 作业存在反压或者数据倾斜</h5><p>我们知道 task 仅在接受到所有的 barrier 之后才会进行 snapshot，如果作业存在反压，或者有数据倾斜，则会导致全部的 channel 或者某些 channel 的 barrier 发送慢，从而整体影响 Checkpoint 的时间，这两个可以通过如下的页面进行检查：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-013106.jpg" alt=""></p><p>上图中我们选择了一个 task，查看所有 subtask 的反压情况，发现都是 high，表示反压情况严重，这种情况下会导致下游接收 barrier 比较晚。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-013126.jpg" alt=""></p><p>上图中我们选择其中一个 operator，点击所有的 subtask，然后按照 Records Received/Bytes Received/TPS 从大到小进行排序，能看到前面几个 subtask 会比其他的 subtask 要处理的数据多。</p><p>如果存在反压或者数据倾斜的情况，我们需要首先解决反压或者数据倾斜问题之后，再查看 Checkpoint 的时间是否符合预期。</p><h5 id="2-2-2-Barrier-对齐慢"><a href="#2-2-2-Barrier-对齐慢" class="headerlink" title="2.2.2 Barrier 对齐慢"></a>2.2.2 Barrier 对齐慢</h5><p>从前面我们知道 Checkpoint 在 task 端分为 barrier 对齐（收齐所有上游发送过来的 barrier），然后开始同步阶段，再做异步阶段。如果 barrier 一直对不齐的话，就不会开始做 snapshot。</p><p>barrier 对齐之后会有如下日志打印：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Starting checkpoint (6751) CHECKPOINT on task taskNameWithSubtasks (4/4)</span><br></pre></td></tr></table></figure><p>如果 taskmanager.log 中没有这个日志，则表示 barrier 一直没有对齐，接下来我们需要了解哪些上游的 barrier 没有发送下来，如果你使用 At Least Once 的话，可以观察下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Received barrier for checkpoint 96508 from channel 5</span><br></pre></td></tr></table></figure><p>表示该 task 收到了 channel 5 来的 barrier，然后看对应 Checkpoint，再查看还剩哪些上游的 barrier 没有接受到，对于 ExactlyOnce 暂时没有类似的日志，可以考虑自己添加，或者 jmap 查看。</p><h5 id="2-2-3-主线程太忙，导致没机会做-snapshot"><a href="#2-2-3-主线程太忙，导致没机会做-snapshot" class="headerlink" title="2.2.3 主线程太忙，导致没机会做 snapshot"></a>2.2.3 主线程太忙，导致没机会做 snapshot</h5><p>在 task 端，所有的处理都是单线程的，数据处理和 barrier 处理都由主线程处理，如果主线程在处理太慢（比如使用 RocksDBBackend，state 操作慢导致整体处理慢），导致 barrier 处理的慢，也会影响整体 Checkpoint 的进度，在这一步我们需要能够查看某个 PID 对应 hotmethod，这里推荐两个方法：</p><ul><li>多次连续 jstack，查看一直处于 RUNNABLE 状态的线程有哪些；</li><li>使用工具 AsyncProfile dump 一份火焰图，查看占用 CPU 最多的栈；</li></ul><p>如果有其他更方便的方法当然更好，也欢迎推荐。</p><h5 id="2-2-4-同步阶段做的慢"><a href="#2-2-4-同步阶段做的慢" class="headerlink" title="2.2.4 同步阶段做的慢"></a>2.2.4 同步阶段做的慢</h5><p>同步阶段一般不会太慢，但是如果我们通过日志发现同步阶段比较慢的话，对于非 RocksDBBackend 我们可以考虑查看是否开启了异步 snapshot，如果开启了异步 snapshot 还是慢，需要看整个 JVM 在干嘛，也可以使用前一节中的工具。对于 RocksDBBackend 来说，我们可以用 iostate 查看磁盘的压力如何，另外可以查看 tm 端 RocksDB 的 log 的日志如何，查看其中 SNAPSHOT 的时间总共开销多少。</p><p>RocksDB 开始 snapshot 的日志如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019/09/10-14:22:55.734684 7fef66ffd700 [utilities/checkpoint/checkpoint_impl.cc:83] Started the snapshot process -- creating snapshot in directory /tmp/flink-io-87c360ce-0b98-48f4-9629-2cf0528d5d53/XXXXXXXXXXX/chk-92729</span><br></pre></td></tr></table></figure><p>snapshot 结束的日志如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019/09/10-14:22:56.001275 7fef66ffd700 [utilities/checkpoint/checkpoint_impl.cc:145] Snapshot DONE. All is good</span><br></pre></td></tr></table></figure><p>#####2.2.6 异步阶段做的慢</p><p>对于异步阶段来说，tm 端主要将 state 备份到持久化存储上，对于非 RocksDBBackend 来说，主要瓶颈来自于网络，这个阶段可以考虑观察网络的 metric，或者对应机器上能够观察到网络流量的情况（比如 iftop)。</p><p>对于 RocksDB 来说，则需要从本地读取文件，写入到远程的持久化存储上，所以不仅需要考虑网络的瓶颈，还需要考虑本地磁盘的性能。另外对于 RocksDBBackend 来说，如果觉得网络流量不是瓶颈，但是上传比较慢的话，还可以尝试考虑开启多线程上传功能[3]。</p><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h3><p>在第二部分内容中，我们介绍了官方编译的包的情况下排查一些 Checkpoint 异常情况的主要场景，以及相应的排查方法，如果排查了上面所有的情况，还是没有发现瓶颈所在，则可以考虑添加更详细的日志，逐步将范围缩小，然后最终定位原因。</p><p>上文提到的一些 DEBUG 日志，如果 flink dist 包是自己编译的话，则建议将 Checkpoint 整个步骤内的一些 DEBUG 改为 INFO，能够通过日志了解整个 Checkpoint 的整体阶段，什么时候完成了什么阶段，也在 Checkpoint 异常的时候，快速知道每个阶段都消耗了多少时间。</p><h3 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h3><p>[1]、<a href="https://issues.apache.org/jira/browse/FLINK-12477">Change threading-model in StreamTask to a mailbox-based approach</a><br>[2]、<a href="https://mp.weixin.qq.com/s/rIgrAscMIJLPpfKytmp4Mw">增量 checkpoint 原理介绍</a><br>[3]、<a href="https://issues.apache.org/jira/browse/FLINK-11008">RocksDBStateBackend 多线程上传 State</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 Flink 中，状态可靠性保证由 Checkpoint 支持，当作业出现 failover 的情况下，Flink 会从最近成功的 Checkpoint 恢复。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
